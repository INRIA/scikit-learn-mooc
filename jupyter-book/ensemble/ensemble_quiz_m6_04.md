# âœ… Quiz M6.04

```{admonition} Question
Gradient boosting are usually composed of (in comparison to random forest):

- a) shallow trees
- b) deep trees
- c) using a subset of features
- d) using all features
```

+++

```{admonition} Question
Which of the hyperparameter(s) do not exist in random forest but exists in gradient boosting:

- a) number of estimators
- b) maximum depth
- c) learning rate
```

+++

```{admonition} Question
Which of the following options are correct about the benefits of ensemble models?

- a) Better generalization performance
- b) Reduced sensitivity to hyper-parameter tuning of individual predictors
- c) Better interpretability
```
