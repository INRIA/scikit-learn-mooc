
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Evaluation of your predictive model &#8212; Scikit-learn tutorial</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Feature importance" href="dev_features_importance.html" />
    <link rel="prev" title="Ensemble learning: when many are better that the one" href="ensemble.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/scikit-learn-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scikit-learn tutorial</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Tabular data exploration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01_tabular_data_exploration.html">
   Loading data into machine learning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Fitting a scikit-learn model on numerical data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="02_basic_preprocessing.html">
   First model with scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_basic_preprocessing_exercise_01.html">
   Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_basic_preprocessing_exercise_01_solution.html">
   Solution for Exercise 01
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Fitting a scikit-learn model on numerical data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables.html">
   Working with both numerical &amp; categorical variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables.html#fitting-a-more-powerful-model">
   Fitting a more powerful model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_01.html">
   Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_01_solution.html">
   Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_02.html">
   Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_02_solution.html">
   Solution for Exercise 03
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Parameter tuning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning.html">
   Introduction to scikit-learn: basic model hyper-parameters tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_01.html">
   Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_01_solution.html">
   Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_02.html">
   Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_02_solution.html">
   Exercise 02
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html">
   Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html#main-take-away">
   Main take away
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Decision Trees
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="trees.html">
   Decision tree in depth
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Ensemble models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble.html">
   Ensemble learning: when many are better that the one
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Metrics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Evaluation of your predictive model
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Interpretation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html">
   Feature importance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html#take-away">
   Take Away
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/python_scripts/metrics.py"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.py</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/INRIA/scikit-learn-mooc/master?urlpath=tree/python_scripts/metrics.py"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification">
   Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-as-a-baseline">
     Accuracy as a baseline
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix-and-derived-metrics">
     Confusion matrix and derived metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-issue-of-class-imbalance">
     The issue of class imbalance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation-and-different-probability-thresholds">
     Evaluation and different probability thresholds
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#link-between-confusion-matrix-precision-recall-curve-and-roc-curve">
     Link between confusion matrix, precision-recall curve and ROC curve
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression">
   Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#baseline-model">
     Baseline model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="evaluation-of-your-predictive-model">
<h1>Evaluation of your predictive model<a class="headerlink" href="#evaluation-of-your-predictive-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Machine-learning models rely on optimizing an objective function, by seeking
its minimum or maximum. It is important to understand that this objective
function is usually decoupled from the evaluation metric that we want to
optimize in practice. The objective function serves as a proxy for the
evaluation metric.
FIXME: add information about a loss function depending of the notebooks
presented before the notebook about metrics.</p>
<p>While other notebooks will give insight about machine-learning algorithms and
their associated objective functions, in this notebook we will focus on the
metrics used to evaluate the performance of a predictive model.</p>
<p>Evaluation metric selection will mainly depend on the model chosen to
solve our data science problem.</p>
</div>
<div class="section" id="classification">
<h2>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h2>
<p>We can recall that in a classification setting, the target <code class="docutils literal notranslate"><span class="pre">y</span></code> is categorical
rather than continuous. We will use the blood transfusion dataset that will
be fetched from OpenML.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;blood-transfusion-service-center&quot;</span><span class="p">,</span>
    <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># Make columns and classes more human-readable</span>
<span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Recency&quot;</span><span class="p">,</span> <span class="s2">&quot;Frequency&quot;</span><span class="p">,</span> <span class="s2">&quot;Monetary&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;donated&quot;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;2&quot;</span> <span class="k">else</span> <span class="s2">&quot;not donated&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;not donated&#39;, &#39;donated&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>We can see that the target <code class="docutils literal notranslate"><span class="pre">y</span></code> contains 2 categories corresponding to whether
or not a subject gave blood or not. We will use a logistic regression
classifier to predict this outcome.</p>
<p>First, we split the data into a training and a testing set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Once our data are split, we can learn a logistic regression classifier using
only the training data, keeping the testing data for evaluation of the
model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression()
</pre></div>
</div>
</div>
</div>
<p>Now that our classifier is trained, we can provide some information about a
subject and the classifier can predict whether or not the subject will donate
blood.</p>
<p>Let’s create a synthetic sample for a new potential
donor: he/she donated blood 6 months ago and has given a total of 1000 c.c.
of blood, twice in the past. He/she gave blood for the first time 20
months ago.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_donor</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">20</span><span class="p">]]</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_donor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;not donated&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>With this information, our classifier predicts that this synthetic subject
is more likely to not donate blood again. However, we cannot check if the
prediction is correct or not (we do not know the true target value). That’s
the purpose of the testing set. First, we predict whether or not a
subject will give blood with the help of the trained classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;not donated&#39;, &#39;not donated&#39;, &#39;not donated&#39;, &#39;not donated&#39;,
       &#39;donated&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="section" id="accuracy-as-a-baseline">
<h3>Accuracy as a baseline<a class="headerlink" href="#accuracy-as-a-baseline" title="Permalink to this headline">¶</a></h3>
<p>Now that we have these predictions, we can compare them with the true
predictions (sometimes called ground-truth) which we did not use up to now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test</span> <span class="o">==</span> <span class="n">y_pred</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>258     True
521    False
14     False
31     False
505     True
       ...  
665     True
100    False
422     True
615     True
743     True
Name: Class, Length: 374, dtype: bool
</pre></div>
</div>
</div>
</div>
<p>In the comparison above, a <code class="docutils literal notranslate"><span class="pre">True</span></code> value means that the value predicted by our
classifier is identical to the real <code class="docutils literal notranslate"><span class="pre">prediction</span></code> while a <code class="docutils literal notranslate"><span class="pre">False</span></code> means that
our classifier made a mistake. One way to get an overall statistic that tells
us how good the performance of our classifier is, is to compute the number of
times our classifier was right and divide it by the number of samples in our
set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7780748663101604
</pre></div>
</div>
</div>
</div>
<p>This measure is also known as the accuracy. Here, our classifier is 78%
accurate at classifying if a subject will give blood. <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> provides
a function that computes this metric in the module <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7780748663101604
</pre></div>
</div>
</div>
</div>
<p>Scikit-learn also has a method named <code class="docutils literal notranslate"><span class="pre">score</span></code>, built into
<code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>, which computes the accuracy score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7780748663101604
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="confusion-matrix-and-derived-metrics">
<h3>Confusion matrix and derived metrics<a class="headerlink" href="#confusion-matrix-and-derived-metrics" title="Permalink to this headline">¶</a></h3>
<p>The comparison that we did above and the accuracy that we calculated did not
take into account the type of error our classifier was making. Accuracy
is an aggregate of the errors made by the classifier. We may be interested
in finer granularity - to know independently what the error is for each of
the two following cases:</p>
<ul class="simple">
<li><p>we predicted that a person will give blood but she/he did not;</p></li>
<li><p>we predicted that a person will not give blood but she/he did.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>

<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9181e32610&gt;
</pre></div>
</div>
<img alt="../_images/metrics_21_1.png" src="../_images/metrics_21_1.png" />
</div>
</div>
<p>The in-diagonal numbers are related to predictions that were correct
while off-diagonal numbers are related to incorrect predictions
(misclassifications). We now know the four types of correct and erroneous
predictions:</p>
<ul class="simple">
<li><p>the top left corner are true positives (TP) and corresponds to people
who gave blood and was predicted as such by the classifier;</p></li>
<li><p>the bottom right corner are true negatives (TN) and correspond to
a people who did not give blood and was predicted as such by the
classifier;</p></li>
<li><p>the top right corner are false negatives (FN) and correspond to
people who gave blood but was predicted to not have given blood;</p></li>
<li><p>the bottom left corner are false positives (FP) and correspond to
people who did not give blood but was predicted to have given blood.</p></li>
</ul>
<p>Once we have split this information, we can compute statistics tp
highlight the performance of our classifier in a particular setting. For
instance, we could be interested in the fraction of people who really gave
blood when the classifier predicted so or the fraction of people predicted
to have given blood out of the total population that actually did so.</p>
<p>The former statistic, known as the precision, is defined as TP / (TP + FP)
and represents how likely the person actually gave blood when the classifier
predicted that they did.
The latter statistic, known as the recall, defined as TP / (TP + FN) and
assesses how well the classifier is able to correctly identify people who
did give blood.
We could, similar to accuracy, manually compute these values
but scikit-learn provides functions to compute these statistics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Precision score: </span><span class="si">{</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;donated&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Recall score: </span><span class="si">{</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;donated&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precision score: 0.6875
Recall score: 0.12359550561797752
</pre></div>
</div>
</div>
</div>
<p>These results are in line with what was seen in the confusion matrix.
Looking at the left column, more than half of the “donated” predictions were
correct, leading
to a precision above 0.5. However, our classifier mislabeled a lot of people
who gave blood as “not donated”, leading to a very low recall of around 0.1.</p>
<p>The precision and recall can be combined in a single score called the F1
score (which is the harmonic mean of precision and recall).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s1">&#39;donated&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.20952380952380953
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-issue-of-class-imbalance">
<h3>The issue of class imbalance<a class="headerlink" href="#the-issue-of-class-imbalance" title="Permalink to this headline">¶</a></h3>
<p>At this stage, we could ask ourself a reasonable question. While the accuracy
did not look bad (i.e. 77%), the F1 score is relatively low (i.e. 21%).</p>
<p>As we mentioned, precision and recall only focuses on samples predicted to
be positive, while
accuracy takes both into account. In addition,
we did not look at the ratio of classes (labels).
We could check this ratio in the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">class_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
<span class="n">class_counts</span> <span class="o">/=</span> <span class="n">class_counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">class_counts</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>not donated    0.762032
donated        0.237968
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can observe that the positive class, <code class="docutils literal notranslate"><span class="pre">'donated'</span></code>, comprises only 24% of
the of the samples. The good accuracy of our classifier is then linked
to its ability to predict correctly the negative class <code class="docutils literal notranslate"><span class="pre">'not</span> <span class="pre">donated'</span></code>
which may or may not be relevant, depending on the application. We can
illustrate the issue using a dummy classifier as a baseline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>

<span class="n">dummy_classifier</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">constant</span><span class="o">=</span><span class="s2">&quot;not donated&quot;</span>
<span class="p">)</span>
<span class="n">dummy_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7620320855614974
</pre></div>
</div>
</div>
</div>
<p>With the dummy classifier, which always predicts the negative class
<code class="docutils literal notranslate"><span class="pre">'not</span> <span class="pre">donated'</span></code>,
we obtain an accuracy score of 76%. Therefore, it means that this classifier,
without learning anything from the data <code class="docutils literal notranslate"><span class="pre">X</span></code>, is capable of predicting as
accurately as our logistic regression model.</p>
<p>The problem illustrated above is also known as the class imbalance problem.
When the classes are imbalanced, accuracy should not be used. In this case,
one should either use
the precision, recall, or F1 score as presented above or the balanced
accuracy score instead of accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">balanced_accuracy_score</span>

<span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5530258229844274
</pre></div>
</div>
</div>
</div>
<p>The balanced accuracy is equivalent to accuracy in the context of
balanced classes. It is defined as the average recall obtained on each class.</p>
</div>
<div class="section" id="evaluation-and-different-probability-thresholds">
<h3>Evaluation and different probability thresholds<a class="headerlink" href="#evaluation-and-different-probability-thresholds" title="Permalink to this headline">¶</a></h3>
<p>All statistics that we presented up to now rely on <code class="docutils literal notranslate"><span class="pre">classifier.predict</span></code> which
outputs the most likely label. We haven’t made use use of the probability
associated with this prediction, which gives the confidence of the
classifier in this prediction. By default, the prediction of a classifier
corresponds to a threshold of 0.5 probability in a binary classification
problem. We can quickly check this relationship with the classifier that
we trained.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_proba</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">classes_</span>
<span class="p">)</span>
<span class="n">y_proba</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>donated</th>
      <th>not donated</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.271820</td>
      <td>0.728180</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.451764</td>
      <td>0.548236</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.445211</td>
      <td>0.554789</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.441577</td>
      <td>0.558423</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.870583</td>
      <td>0.129417</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;not donated&#39;, &#39;not donated&#39;, &#39;not donated&#39;, &#39;not donated&#39;,
       &#39;donated&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Since probabilities sum to 1 we can get the class with the highest</span>
<span class="c1"># probability without using the threshold 0.5.</span>
<span class="n">equivalence_pred_proba</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">y_proba</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="o">==</span> <span class="n">y_pred</span>
<span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">equivalence_pred_proba</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>The default decision threshold (0.5) might not be the best threshold that
leads to optimal performance of our classifier. In this case, one can vary
the decision threshold, and therefore the underlying prediction, and compute
the same statistics presented earlier. Usually, the two metrics recall and
precision are computed and plotted on a graph. Each metric plotted on a
graph axis and each point on
the graph corresponds to a specific decision threshold. Let’s start by
computing the precision-recall curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pos_label</span> <span class="o">=</span> <span class="s2">&quot;donated&quot;</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">average_precision</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Average Precision: </span><span class="si">{</span><span class="n">average_precision</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall</span><span class="se">\n</span><span class="s2"> (Positive label: </span><span class="si">{</span><span class="n">pos_label</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision</span><span class="se">\n</span><span class="s2"> (Positive label: </span><span class="si">{</span><span class="n">pos_label</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># # FIXME: to be used when solved in scikit-learn</span>
<span class="c1"># from sklearn.metrics import plot_precision_recall_curve</span>

<span class="c1"># disp = plot_precision_recall_curve(</span>
<span class="c1">#     classifier, X_test, y_test, pos_label=&#39;donated&#39;,</span>
<span class="c1"># )</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f917f3bd550&gt;
</pre></div>
</div>
<img alt="../_images/metrics_37_1.png" src="../_images/metrics_37_1.png" />
</div>
</div>
<p>On this curve, each blue dot corresponds to a level of probability
which we used as a decision threshold. We can see that by varying this
decision threshold, we get different precision vs. recall values.</p>
<p>A perfect classifier would have a precision of 1 for all recall
values. A metric characterizing the curve is linked to the area under the
curve (AUC) and is named average precision. With an ideal classifier, the
average precision would be 1.</p>
<p>The precision and recall metric focuses on the positive class however, one
might be interested in the compromise between accurately discriminating the
positive class and accurately discriminating the negative classes. The
statistics used for this are sensitivity and specificity. Sensitivity is just
another name for recall. However, specificity measures the proportion of
correctly classified samples in the negative class defined as:
TN / (TN + FP). Similar to the precision-recall curve, sensitivity and
specificity are generally plotted as a curve called the receiver operating
characteristic (ROC) curve. Below is such a curve:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>
<span class="c1"># FIXME: roc_auc_score has a bug and we need to give the inverse probability</span>
<span class="c1"># vector. Should be changed when the following is merged and released:</span>
<span class="c1"># https://github.com/scikit-learn/scikit-learn/pull/17594</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ROC-AUC: </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:green&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Chance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;1 - Specificity</span><span class="se">\n</span><span class="s2"> (Positive label: </span><span class="si">{</span><span class="n">pos_label</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity</span><span class="se">\n</span><span class="s2"> (Positive label: </span><span class="si">{</span><span class="n">pos_label</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># # FIXME: to be used when solved in scikit-learn</span>
<span class="c1"># from sklearn.metrics import plot_roc_curve</span>

<span class="c1"># plot_roc_curve(classifier, X_test, y_test, pos_label=&#39;donated&#39;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f917ee11810&gt;
</pre></div>
</div>
<img alt="../_images/metrics_39_1.png" src="../_images/metrics_39_1.png" />
</div>
</div>
<p>This curve was built using the same principle as the precision-recall
curve: we vary the probability threshold for determining “hard” prediction
and compute the metrics. As with the precision-recall curve, we can
compute the area under the ROC (ROC-AUC) to characterize the performance of
our classifier. However, it is important to observer that the lower bound
of the ROC-AUC is 0.5. Indeed, we show the performance of a dummy
classifier (the green dashed line) to show that the even worst performance
obtained will always be above this line.</p>
</div>
<div class="section" id="link-between-confusion-matrix-precision-recall-curve-and-roc-curve">
<h3>Link between confusion matrix, precision-recall curve and ROC curve<a class="headerlink" href="#link-between-confusion-matrix-precision-recall-curve-and-roc-curve" title="Permalink to this headline">¶</a></h3>
<p>TODO: ipywidgets to play with interactive curve</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_pr_curve</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="p">,</span>
                  <span class="n">probability_threshold</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">average_precision</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Average Precision: </span><span class="si">{</span><span class="n">average_precision</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">threshold_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span>
        <span class="n">threshold</span><span class="p">,</span> <span class="n">probability_threshold</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">recall</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span> <span class="n">precision</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="n">recall</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">precision</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">recall</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">precision</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span> <span class="n">precision</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_roc_curve</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="p">,</span>
                   <span class="n">probability_threshold</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ROC-AUC: </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:green&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Chance&quot;</span><span class="p">)</span>
    <span class="n">threshold_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span>
        <span class="n">threshold</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">probability_threshold</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">threshold_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span> <span class="o">-</span> <span class="n">threshold_idx</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">fpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="n">fpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span> <span class="n">fpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">tpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">fpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">tpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]],</span>
        <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;1 - Specificity&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_confusion_matrix_with_threshold</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="p">,</span>
                                         <span class="n">probability_threshold</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

    <span class="n">class_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">classes_</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">[:,</span> <span class="n">class_idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">probability_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span>
        <span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">y_pred</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">im_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>

    <span class="n">text_</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">cmap_min</span><span class="p">,</span> <span class="n">cmap_max</span> <span class="o">=</span> <span class="n">im_</span><span class="o">.</span><span class="n">cmap</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">im_</span><span class="o">.</span><span class="n">cmap</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>

    <span class="n">text_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

    <span class="c1"># print text with appropriate color depending on background</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">cm</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="mf">2.0</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)):</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">cmap_max</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="n">cmap_min</span>

        <span class="n">text_cm</span> <span class="o">=</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="s1">&#39;.2g&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cm</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
            <span class="n">text_d</span> <span class="o">=</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_d</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_cm</span><span class="p">):</span>
                <span class="n">text_cm</span> <span class="o">=</span> <span class="n">text_d</span>

        <span class="n">text_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
            <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">text_cm</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span>
        <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">xticks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span>
        <span class="n">yticks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span>
        <span class="n">xticklabels</span><span class="o">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">classes_</span><span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="n">class_idx</span><span class="p">)),</span> <span class="n">class_idx</span><span class="p">]],</span>
        <span class="n">yticklabels</span><span class="o">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">classes_</span><span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="n">class_idx</span><span class="p">)),</span> <span class="n">class_idx</span><span class="p">]],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;True label&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Predicted label&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_pr_roc</span><span class="p">(</span><span class="n">threshold</span><span class="p">):</span>
    <span class="c1"># FIXME: we could optimize the plotting by only updating the the</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plot_pr_curve</span><span class="p">(</span>
        <span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s2">&quot;donated&quot;</span><span class="p">,</span>
        <span class="n">probability_threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">plot_roc_curve</span><span class="p">(</span>
        <span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s2">&quot;donated&quot;</span><span class="p">,</span>
        <span class="n">probability_threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">plot_confusion_matrix_with_threshold</span><span class="p">(</span>
        <span class="n">classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s2">&quot;donated&quot;</span><span class="p">,</span>
        <span class="n">probability_threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Overall performance with positive class &#39;donated&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_pr_roc_interactive</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">FloatSlider</span>
    <span class="n">slider</span> <span class="o">=</span> <span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">interactive</span><span class="p">(</span><span class="n">plot_pr_roc</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">slider</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_pr_roc_interactive</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "565c1644db4b40d4af9302111d0823d5", "version_major": 2, "version_minor": 0}
</script></div>
</div>
</div>
</div>
<div class="section" id="regression">
<h2>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h2>
<p>Unlike in classification problems, the target <code class="docutils literal notranslate"><span class="pre">y</span></code> is a continuous
variable in regression problems. Therefore, classification metrics cannot
be used to evaluate the performance of regression models. Instead, there
exists a set of metrics dedicated to regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/christophM/interpretable-ml-book/&quot;</span>
     <span class="s2">&quot;master/data/bike.csv&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="c1"># rename the columns with human-readable names</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;yr&quot;</span><span class="p">:</span> <span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="s2">&quot;mnth&quot;</span><span class="p">:</span> <span class="s2">&quot;month&quot;</span><span class="p">,</span> <span class="s2">&quot;temp&quot;</span><span class="p">:</span> <span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="s2">&quot;hum&quot;</span><span class="p">:</span> <span class="s2">&quot;humidity&quot;</span><span class="p">,</span>
    <span class="s2">&quot;cnt&quot;</span><span class="p">:</span> <span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="s2">&quot;days_since_2011&quot;</span><span class="p">:</span> <span class="s2">&quot;days since 2011&quot;</span>
<span class="p">})</span>
<span class="c1"># convert the categorical columns with a proper category data type</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;O&quot;</span><span class="p">:</span>
        <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span>

<span class="c1"># separate the target from the original data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;count&quot;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;count&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>year</th>
      <th>month</th>
      <th>holiday</th>
      <th>weekday</th>
      <th>workingday</th>
      <th>weathersit</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>days since 2011</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SPRING</td>
      <td>2011</td>
      <td>JAN</td>
      <td>NO HOLIDAY</td>
      <td>SAT</td>
      <td>NO WORKING DAY</td>
      <td>MISTY</td>
      <td>8.175849</td>
      <td>80.5833</td>
      <td>10.749882</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SPRING</td>
      <td>2011</td>
      <td>JAN</td>
      <td>NO HOLIDAY</td>
      <td>SUN</td>
      <td>NO WORKING DAY</td>
      <td>MISTY</td>
      <td>9.083466</td>
      <td>69.6087</td>
      <td>16.652113</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SPRING</td>
      <td>2011</td>
      <td>JAN</td>
      <td>NO HOLIDAY</td>
      <td>MON</td>
      <td>WORKING DAY</td>
      <td>GOOD</td>
      <td>1.229108</td>
      <td>43.7273</td>
      <td>16.636703</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SPRING</td>
      <td>2011</td>
      <td>JAN</td>
      <td>NO HOLIDAY</td>
      <td>TUE</td>
      <td>WORKING DAY</td>
      <td>GOOD</td>
      <td>1.400000</td>
      <td>59.0435</td>
      <td>10.739832</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SPRING</td>
      <td>2011</td>
      <td>JAN</td>
      <td>NO HOLIDAY</td>
      <td>WED</td>
      <td>WORKING DAY</td>
      <td>GOOD</td>
      <td>2.666979</td>
      <td>43.6957</td>
      <td>12.522300</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of bike rentals&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Target distribution&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Target distribution&#39;)
</pre></div>
</div>
<img alt="../_images/metrics_50_1.png" src="../_images/metrics_50_1.png" />
</div>
</div>
<p>Our problem can be formulated as follows: we would like to infer the number
of bike rentals in a day using information about the day. The number of bike
rentals is a number that can vary in the interval [0, max_number_of_bikes).
As in the previous section, we will train a
model and evaluate its performance while introducing different
regression metrics.</p>
<p>First, we split the data into training and a testing sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="baseline-model">
<h3>Baseline model<a class="headerlink" href="#baseline-model" title="Permalink to this headline">¶</a></h3>
<p>We will use a random forest as a model. However, we first need to check the
type of data that we are dealing with:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 548 entries, 452 to 684
Data columns (total 11 columns):
 #   Column           Non-Null Count  Dtype   
---  ------           --------------  -----   
 0   season           548 non-null    category
 1   year             548 non-null    int64   
 2   month            548 non-null    category
 3   holiday          548 non-null    category
 4   weekday          548 non-null    category
 5   workingday       548 non-null    category
 6   weathersit       548 non-null    category
 7   temperature      548 non-null    float64 
 8   humidity         548 non-null    float64 
 9   windspeed        548 non-null    float64 
 10  days since 2011  548 non-null    int64   
dtypes: category(6), float64(3), int64(2)
memory usage: 30.1 KB
</pre></div>
</div>
</div>
</div>
<p>While some features are numeric, some have been tagged as <code class="docutils literal notranslate"><span class="pre">category</span></code>. These
features need to be encoded such that our random forest can
deal with them. The simplest solution is to use an <code class="docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code>.
Regarding, the numerical features, we don’t need to do anything. Thus, we
will create preprocessing steps to take care of the encoding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_selector</span> <span class="k">as</span> <span class="n">selector</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>

<span class="n">categorical_selector</span> <span class="o">=</span> <span class="n">selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">)</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">OrdinalEncoder</span><span class="p">(),</span> <span class="n">categorical_selector</span><span class="p">),</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s2">&quot;passthrough&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">X_train_preprocessed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">(</span>
        <span class="n">categorical_selector</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">+</span>
        <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
         <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">categorical_selector</span><span class="p">(</span><span class="n">X_train</span><span class="p">)]</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">X_train_preprocessed</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>month</th>
      <th>holiday</th>
      <th>weekday</th>
      <th>workingday</th>
      <th>weathersit</th>
      <th>year</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>days since 2011</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2012.0</td>
      <td>14.755849</td>
      <td>48.1250</td>
      <td>19.541957</td>
      <td>452.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2011.0</td>
      <td>7.549151</td>
      <td>77.5833</td>
      <td>5.625206</td>
      <td>337.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.0</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2012.0</td>
      <td>22.785000</td>
      <td>71.6667</td>
      <td>11.584032</td>
      <td>509.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2011.0</td>
      <td>14.207500</td>
      <td>37.9167</td>
      <td>24.667189</td>
      <td>77.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2012.0</td>
      <td>7.196651</td>
      <td>29.0000</td>
      <td>12.541864</td>
      <td>451.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Just to have some insight about the preprocessing, we preprocess
the training data show the result. We can observe that the original strings
are now encoded with numbers. We can now create our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="n">regressor</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;columntransformer&#39;,
                 ColumnTransformer(remainder=&#39;passthrough&#39;,
                                   transformers=[(&#39;ordinalencoder&#39;,
                                                  OrdinalEncoder(),
                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f917eaae150&gt;)])),
                (&#39;randomforestregressor&#39;, RandomForestRegressor())])
</pre></div>
</div>
</div>
</div>
<p>As for scikit-learn classifiers, scikit-learn regressors have a <code class="docutils literal notranslate"><span class="pre">score</span></code>
method that computes the
:math:<code class="docutils literal notranslate"><span class="pre">R^2</span></code> score (also known as the coefficient of determination):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">regressor</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8978321600691443
</pre></div>
</div>
</div>
</div>
<p>The :math:<code class="docutils literal notranslate"><span class="pre">R^2</span></code> score represents the proportion of variance of the target
that is explained by the independent variables in the model. The best score
possible
is 1 but there is no lower bound. However, a model that predicts the
expected value of the target would get a score of 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyRegressor</span>

<span class="n">dummy_regressor</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">dummy_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-8.48919596840858e-08
</pre></div>
</div>
</div>
</div>
<p>The :math:<code class="docutils literal notranslate"><span class="pre">R^2</span></code> score gives insight into the goodness of fit of the
model. However, this score cannot be compared from one dataset to another and
the value obtained does not have a meaningful interpretation relative the
original unit of the target. If we wanted to get an interpretable score, we
would be interested in the median or mean absolute error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Mean absolute error: </span><span class="si">{</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean absolute error: 499
</pre></div>
</div>
</div>
</div>
<p>By computing the mean absolute error, we can interpret that our model is
predicting on average 507 bike rentals away from the truth. A disadvantage
of this metric is that the mean can be
impacted by large error. For some applications, we might not want these
large errors to have such a big influence on our metric. In this case we can
use the median absolute error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">median_absolute_error</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Median absolute error: </span><span class="si">{</span><span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Median absolute error: 385
</pre></div>
</div>
</div>
</div>
<p>This metric tells us that, our model makes a median error of 405 bikes.
FIXME: <strong>not sure how to introduce the <code class="docutils literal notranslate"><span class="pre">mean_squared_error</span></code>.</strong></p>
<p>In addition of metrics, we can visually represent the results by plotting
the predicted values versus the true values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_predicted_vs_actual</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">max_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">y_true</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">()])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Perfect fit&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True values&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted values&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;square&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>


<span class="n">plot_predicted_vs_actual</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/metrics_69_0.png" src="../_images/metrics_69_0.png" />
</div>
</div>
<p>On this plot, correct predictions would lie on the diagonal line. This plot
allows us to detect if the model makes errors in a consistent way, i.e.
has some bias.</p>
<p>Let’s take an example using the house prices in Ames.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;house_prices&quot;</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;LotFrontage&quot;</span><span class="p">,</span> <span class="s2">&quot;GarageYrBlt&quot;</span><span class="p">,</span> <span class="s2">&quot;MasVnrArea&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will fit a ridge regressor on the data and plot the prediction versus the
actual values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">RidgeCV</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">plot_predicted_vs_actual</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;House prices in Ames&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/metrics_73_0.png" src="../_images/metrics_73_0.png" />
</div>
</div>
<p>On this plot, we see that for the large True price values, our model tends to
under-estimate the price of the house. Typically, this issue arises when
the target to predict does not follow a normal distribution. In these cases
the model would benefit from target transformation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">QuantileTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">TransformedTargetRegressor</span>

<span class="n">model_transformed_target</span> <span class="o">=</span> <span class="n">TransformedTargetRegressor</span><span class="p">(</span>
    <span class="n">regressor</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">transformer</span><span class="o">=</span><span class="n">QuantileTransformer</span><span class="p">(</span>
        <span class="n">n_quantiles</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">output_distribution</span><span class="o">=</span><span class="s2">&quot;normal&quot;</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="n">model_transformed_target</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_transformed_target</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">plot_predicted_vs_actual</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;House prices in Ames&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/metrics_75_0.png" src="../_images/metrics_75_0.png" />
</div>
</div>
<p>Thus, once we transformed the target, we see that we corrected some of the
high values.</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this notebook, we presented the metrics and plots useful to evaluate and
get insights about models. We both focus on regression and classification
problems.</p>
</div>
</div>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"36c396a3c95d4d56adca41d692391772": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "565c1644db4b40d4af9302111d0823d5": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_91e2c49cb1664cb28cfa333fbbed776e", "IPY_MODEL_5fa46d428a654d51897a7697ed2729ce"], "layout": "IPY_MODEL_56bafa36197346a094becc05044e36f5"}}, "56bafa36197346a094becc05044e36f5": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5fa46d428a654d51897a7697ed2729ce": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_d9c661f78f664aa7a4ace23d4f3734c0", "msg_id": "", "outputs": [{"data": {"image/png": "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\n", "text/plain": "<Figure size 1512x432 with 3 Axes>"}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}]}}, "9015de7799c84a0296e3b1e3bf9b3cbf": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "91e2c49cb1664cb28cfa333fbbed776e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "threshold", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_36c396a3c95d4d56adca41d692391772", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.01, "style": "IPY_MODEL_9015de7799c84a0296e3b1e3bf9b3cbf", "value": 0.5}}, "d9c661f78f664aa7a4ace23d4f3734c0": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./python_scripts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ensemble.html" title="previous page">Ensemble learning: when many are better that the one</a>
    <a class='right-next' id="next-link" href="dev_features_importance.html" title="next page">Feature importance</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By scikit-learn developers<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>