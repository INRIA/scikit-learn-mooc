# âœ… Quiz

```{admonition} Question
How could we prevent overfitting within a tree model?

- a) with a weight regularization
- b) by increasing max_depth
- c) by decreasing max_depth
- d) with early stopping
```

```{admonition} Question
Tree are build:

- a) incrementally by splitting leaves
- b) by refining the rules of each nodes
- c) by refining the prediction of each leaf
```

```{admonition} Question
In a decision tree, to choose a split, we have to:

- a) randomly choose a feature
- b) randomly choose a value
- c) maximize an equation
- d) maximize nb_features equations
```

```{admonition} Question
In regression setting, what represent a leaf in a decision tree:

- a) a value
- b) a value distribution
- c) a class
- d) probabilities of each class
```

```{admonition} Question
In classification setting, what represent a leaf in a decision tree:

- a) a value
- b) a value distribution
- c) a class
- d) probabilities of each class
```

TODO: hmmm we have not talked about clustering (maybe mentioned in the ML
concepts quickly) or dimension reduction, so remove this one?

```{admonition} Question
Decision tree could be used for:

- a) regression
- b) classification
- c) clustering
- d) dimension reduction
```
