{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model with scikit-learn\n",
    "\n",
    "## Basic preprocessing and model fitting\n",
    "\n",
    "In this notebook, we present how to build predictive models on tabular\n",
    "datasets, with only numerical features.\n",
    "\n",
    "In particular we will highlight:\n",
    "* the scikit-learn API : `.fit`/`.predict`/`.score`\n",
    "* how to evaluate the performance of a model with a train-test split\n",
    "\n",
    "## Loading the dataset\n",
    "\n",
    "We will use the same dataset \"adult_census\" described in the previous notebook.\n",
    "For more details about the dataset see <http://www.openml.org/d/1590>.\n",
    "\n",
    "Numerical data is the most natural type of data used in machine\n",
    "learning and can (almost) directly be fed into predictive models. We\n",
    "will load a the subset of the original data with only the numerical\n",
    "columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/adult-census-numeric.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first records of this data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = df[target_name]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now separate out the data that we will use to predict from the\n",
    "prediction target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data = df.drop(columns=[target_name, ])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this data to fit a linear classification model to predict\n",
    "the income class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The dataset contains {data.shape[0]} samples and \"\n",
    "    f\"{data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We will build a classification model using the \"K Nearest Neighbor\"\n",
    "strategy. The `fit` method is called to train the model from the input\n",
    "(features) and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let'us to use our model to make some predictions on the first five\n",
    "records of the held out test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = model.predict(data)\n",
    "target_predicted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare these predictions to the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better assessment, we can compute the average success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target == target_predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, can this evaluation be trusted, or is it too good to be true?\n",
    "\n",
    "When building a machine learning model, it is important evaluate the\n",
    "trained model on data that was not used to fit the model, as\n",
    "generalization is more than memorization. It is harder to conclude on\n",
    "instances never seen than on those already seen.\n",
    "\n",
    "Correct evaluation is easily done by leaving out a subset of the data\n",
    "when training the model and using it after for model evaluation. The\n",
    "data used to fit a model is called training data while the one used to\n",
    "assess a model is called testing data.\n",
    "\n",
    "We can load more data, which was actually left-out from the original\n",
    "data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../datasets/adult-census-numeric-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this new data, we separate out input features and the target to\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = df_test[target_name]\n",
    "data_test = df_test.drop(columns=[target_name, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The testing dataset contains {data_test.shape[0]} samples and \"\n",
    "    f\"{data_test.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Note that scikit-learn provides a helper function `train_test_split`\n",
    "which can be used to split the dataset into a training and a testing\n",
    "set. It will also ensure that the data are shuffled randomly before\n",
    "splitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantitatively evaluate our model, we can use the method `score`. It will\n",
    "compute the classification accuracy when dealing with a classification\n",
    "problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The test accuracy using a {model.__class__.__name__} is \"\n",
    "      f\"{model.score(data_test, target_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the model predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_predicted = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute the average accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target_test == target_test_predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare with the accuracy obtained by wrongly evaluating the model\n",
    "on the training set, we find that this evaluation was indeed optimistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have:\n",
    "* fit a **nearest neighbor** model on training dataset\n",
    "* evaluated its performance on the testing data\n",
    "* presented the scikit-learn API `.fit` (to train a model), `.predict` (to\n",
    "  make predictions) and `.score` (to evaluate a model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
