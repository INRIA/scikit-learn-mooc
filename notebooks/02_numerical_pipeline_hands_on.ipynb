{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with numerical data\n",
    "\n",
    "In the previous notebook, we trained a k-nearest neighbors model on\n",
    "some data.\n",
    "\n",
    "However, we oversimplified the procedure by loading a dataset that contained\n",
    "exclusively numerical data. Besides, we used datasets which were already\n",
    "split into train-test sets.\n",
    "\n",
    "In this notebook, we aim at:\n",
    "\n",
    "* identifying numerical data in a heterogeneous dataset;\n",
    "* selecting the subset of columns corresponding to numerical data;\n",
    "* using a scikit-learn helper to separate data into train-test sets;\n",
    "* training and evaluating a more complex scikit-learn model.\n",
    "\n",
    "We will start by loading the adult census dataset used during the data\n",
    "exploration.\n",
    "\n",
    "## Loading the entire dataset\n",
    "\n",
    "As in the previous notebook, we rely on pandas to open the CSV file into\n",
    "a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step separates the target from the data. We performed the same\n",
    "procedure in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = adult_census.drop(columns=\"class\"), adult_census[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Here and later, we use the name <tt class=\"docutils literal\">data</tt> and <tt class=\"docutils literal\">target</tt> to be explicit. In\n",
    "scikit-learn, documentation <tt class=\"docutils literal\">data</tt> is commonly named <tt class=\"docutils literal\">X</tt> and <tt class=\"docutils literal\">target</tt> is\n",
    "commonly called <tt class=\"docutils literal\">y</tt>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can focus on the data we want to use to train our\n",
    "predictive model.\n",
    "\n",
    "## Identify numerical data\n",
    "\n",
    "Numerical data are represented with numbers. They are linked to measurable\n",
    "(quantitative) data, such as age or the number of hours a person works a\n",
    "week.\n",
    "\n",
    "Predictive models are natively designed to work with numerical data.\n",
    "Moreover, numerical data usually requires very little work before getting\n",
    "started with training.\n",
    "\n",
    "The first task here will be to identify numerical data in our dataset.\n",
    "\n",
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Numerical data are represented with numbers, but numbers are not always\n",
    "representing numerical data. Categories could already be encoded with\n",
    "numbers and you will need to identify these features.</p>\n",
    "</div>\n",
    "\n",
    "Thus, we can check the data type for each of the column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have only two data types. We can make sure by checking the unique\n",
    "data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the only two types in the dataset are integer and object.\n",
    "We can look at the first few lines of the dataframe to understand the\n",
    "meaning of the `object` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `object` data type corresponds to columns containing strings.\n",
    "As we saw in the exploration section, these columns contain categories and we\n",
    "will see later how to handle those. We can select the columns containing\n",
    "integers and check their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"age\", \"education-num\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"fnlwgt\"]\n",
    "data[numerical_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we limited the dataset to numerical columns only,\n",
    "we can analyse these numbers to figure out what they represent.\n",
    "Discarding `\"fnlwgt\"` for the moment, we can identify two types of usage.\n",
    "\n",
    "The first column, `\"age\"`, is self-explanatory. We can note that the values\n",
    "are continuous, meaning they can take up any number in a given range. Let's\n",
    "find out what this range is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the age varies between 17 and 90 years.\n",
    "\n",
    "We could extend our analysis and we will find that `\"capital-gain\"`,\n",
    "`\"capital-loss\"`, `\"hours-per-week\"` and `\"fnlwgt\"` are also representing\n",
    "quantitative data.\n",
    "\n",
    "However, the column `\"education-num\"` is different. It corresponds to the\n",
    "educational stage that is not necessarily the number of years studied, and\n",
    "thus not a quantitative measurement. This feature is a categorical feature\n",
    "already encoded with discrete numerical values. To see this specificity, we\n",
    "will look at the count for each educational stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"education-num\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is indeed a nominal categorical feature. We exclude it from\n",
    "our analysis since particular attention is required when dealing with\n",
    "categorical features. This topic will be discussed in depth in the subsequent\n",
    "notebook.\n",
    "\n",
    "In addition, we decide to ignore the column `\"fnlwgt\"`. This decision is not\n",
    "linked with the feature being numerical or categorical. Indeed, this feature\n",
    "is derived from a combination other features, as mentioned in the description\n",
    "of the dataset. Thus, we will only focus on the original data collected\n",
    "during the survey.\n",
    "\n",
    "Now, we can select the subset of numerical columns and store them inside a\n",
    "new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "data_numeric = data[numerical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split the dataset\n",
    "\n",
    "In the previous notebook, we loaded two separate datasets: a training one and\n",
    "a testing one. However, as mentioned earlier, having separate datasets like\n",
    "that is unusual: most of the time, we have a single one, which we will\n",
    "subdivide.\n",
    "\n",
    "We also mentioned that scikit-learn provides the helper function\n",
    "`sklearn.model_selection.train_test_split` which is used to automatically\n",
    "split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_numeric, target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\"><tt class=\"docutils literal\">random_state</tt> parameter allows to get a deterministic results even if we\n",
    "use some random process (i.e. data shuffling).</p>\n",
    "</div>\n",
    "\n",
    "In the previous notebook, we used a k-nearest neighbors predictor. While this\n",
    "model is really intuitive to understand, it is not widely used.\n",
    "Here, we will make a predictive model belonging to the linear models family.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">In short, these models find a set of weights to combine each column in the\n",
    "data matrix to predict the target. For instance, the model can come up with\n",
    "rules such as <tt class=\"docutils literal\">0.1 * age + 3.3 * <span class=\"pre\">hours-per-week</span> - 15.1 &gt; 0.5</tt> means that\n",
    "<tt class=\"docutils literal\"><span class=\"pre\">high-income</span></tt> is predicted.</p>\n",
    "</div>\n",
    "\n",
    "Thus, as we are trying to predict a qualitative property,\n",
    "we will use a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the statistical performance of the model using the test set\n",
    "which we left out until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(data_test, target_test)\n",
    "print(f\"Accuracy of logistic regression: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Be aware you should use cross-validation instead of <tt class=\"docutils literal\">train_test_split</tt> in\n",
    "practice. We used a single split, to highlight the scikit-learn API and the\n",
    "methods <tt class=\"docutils literal\">fit</tt>, <tt class=\"docutils literal\">predict</tt>, and <tt class=\"docutils literal\">score</tt>. In the module \"Select the best model\"\n",
    "we will go into details regarding cross-validation.</p>\n",
    "</div>\n",
    "\n",
    "Now the real question is: is this statitical performance relevant of a good\n",
    "predictive model? Find out by solving the next exercise!.\n",
    "\n",
    "In this notebook, we learned:\n",
    "\n",
    "* identify numerical data in a heterogeneous dataset;\n",
    "* select the subset of columns corresponding to numerical data;\n",
    "* use scikit-learn helper to separate data into train-test sets;\n",
    "* train and evaluate a more complex scikit-learn model."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}