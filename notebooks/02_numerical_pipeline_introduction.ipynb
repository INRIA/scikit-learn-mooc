{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model with scikit-learn\n",
    "\n",
    "In this notebook, we present how to build predictive models on tabular\n",
    "datasets, with only numerical features.\n",
    "\n",
    "In particular we will highlight:\n",
    "\n",
    "* the scikit-learn API : `.fit(X, y)`/`.predict(X)`/`.score(X, y)`;\n",
    "* how to evaluate the performance of a model with a train-test split.\n",
    "\n",
    "## Loading the dataset with Pandas\n",
    "\n",
    "We will use the same dataset \"adult_census\" described in the previous\n",
    "notebook. For more details about the dataset see\n",
    "<http://www.openml.org/d/1590>.\n",
    "\n",
    "Numerical data is the most natural type of data used in machine learning and\n",
    "can (almost) directly be fed into predictive models. We will load a the\n",
    "subset of the original data with only the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/adult-census-numeric.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first records of this dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this CSV file contains all information: the target that we would\n",
    "like to predict (i.e. `\"class\"`) and the data that we want to use to train\n",
    "our predictive model (i.e. the remaining columns). The first step is to\n",
    "separate columns to get on one side the target and on the other side the\n",
    "data.\n",
    "\n",
    "## Separate the data and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = df[target_name]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=[target_name, ])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now linger on the variables, also denominated features, that we will\n",
    "use to build our predictive model. In addition, we can as well check how many\n",
    "samples are available in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset contains {data.shape[0]} samples and \"\n",
    "      f\"{data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model and make predictions\n",
    "\n",
    "We will build a classification model using the \"K-nearest neighbors\"\n",
    "strategy. The `fit` method is called to train the model from the input\n",
    "(features) and target data.\n",
    "\n",
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">We use a K-nearest neighbors here. However, be aware that it is seldom useful\n",
    "in practice. We use it because it is an intuitive algorithm. In the next\n",
    "notebook, we will introduce better models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our model to make some predictions using the same dataset. In a\n",
    "sake of simplicity, we will look at the five first predicted targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = model.predict(data)\n",
    "target_predicted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we can compare these predictions to the actual data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and we could even check if the predictions agree with the real targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:5] == target_predicted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of correct prediction: \"\n",
    "      f\"{(target[:5] == target_predicted[:5]).sum()} / 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that our model does a mistake when predicting for the first\n",
    "sample.\n",
    "\n",
    "To get a better assessment, we can compute the average success rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target == target_predicted).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, can this evaluation be trusted, or is it too good to be true?\n",
    "\n",
    "## Train-test data split\n",
    "\n",
    "When building a machine learning model, it is important evaluate the trained\n",
    "model on data that was not used to fit the model, as generalization is more\n",
    "than memorization. It is harder to conclude on instances never seen than on\n",
    "those already seen.\n",
    "\n",
    "Correct evaluation is easily done by leaving out a subset of the data when\n",
    "training the model and using it after for model evaluation. The data used to\n",
    "fit a model is called training data while the one used to assess a model is\n",
    "called testing data.\n",
    "\n",
    "We can load more data, which was actually left-out from the original data\n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../datasets/adult-census-numeric-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this new data, we separate out input features and the target to predict,\n",
    "as in the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = df_test[target_name]\n",
    "data_test = df_test.drop(columns=[target_name, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of features and samples available in this new set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The testing dataset contains {data_test.shape[0]} samples and \"\n",
    "      f\"{data_test.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that scikit-learn provides a helper function `train_test_split` which\n",
    "can be used to split the dataset into a training and a testing set. It will\n",
    "also ensure that the data are shuffled randomly before splitting the data.\n",
    "\n",
    "Instead of computing the prediction and computing manually the average\n",
    "success rate, we can use the method `score`. When dealing with classifiers\n",
    "this method return this performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(data_test, target_test)\n",
    "model_name = model.__class__.__name__\n",
    "\n",
    "print(f\"The test accuracy using a {model_name} is \"\n",
    "      f\"{accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare with the accuracy obtained by wrongly evaluating the model\n",
    "on the training set, we find that this evaluation was indeed optimistic\n",
    "compared to the score obtained on an held-out test set.\n",
    "\n",
    "It shows the importance to always test the performance of predictive models\n",
    "on a different set than the one used to train these models. We will come\n",
    "back more into details regarding how predictive models should be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have:\n",
    "\n",
    "* fit a **k-nearest neighbors** model on training dataset;\n",
    "* evaluated its performance on the testing data;\n",
    "* presented the scikit-learn API `.fit(X, y)` (to train a model),\n",
    "  `.predict(X)` (to make predictions) and `.score(X, y)`\n",
    "  (to evaluate a model)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
