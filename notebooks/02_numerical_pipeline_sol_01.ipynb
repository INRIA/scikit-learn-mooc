{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ƒ Solution for Exercise 01\n",
    "\n",
    "The goal of this exercise is to compare the performance of our classifier\n",
    "(81% accuracy) to some baseline classifiers that would ignore the input data\n",
    "and instead make constant predictions.\n",
    "\n",
    "- What would be the score of a model that always predicts `' >50K'`?\n",
    "- What would be the score of a model that always predicts `' <= 50K'`?\n",
    "- Is 81% or 82% accuracy a good score for this problem?\n",
    "\n",
    "Use a `DummyClassifier` and do a train-test split to evaluate\n",
    "its accuracy on the test set. This\n",
    "[link](https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators)\n",
    "shows a few examples of how to evaluate the performance of these baseline\n",
    "models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first split our dataset to have the target separated from the data\n",
    "used to train our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = df[target_name]\n",
    "data = df.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by selecting only the numerical columns as seen in the previous\n",
    "notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "data_numeric = data[numerical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the data and target into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_numeric_train, data_numeric_test, target_train, target_test = \\\n",
    "    train_test_split(data_numeric, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a dummy classifier which will always predict the\n",
    "high revenue class class, i.e. `\" >50K\"`, and check the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "class_to_predict = \" >50K\"\n",
    "high_revenue_clf = DummyClassifier(strategy=\"constant\",\n",
    "                                   constant=class_to_predict)\n",
    "high_revenue_clf.fit(data_numeric_train, target_train)\n",
    "score = high_revenue_clf.score(data_numeric_test, target_test)\n",
    "print(f\"Accuracy of a model predicting only high revenue: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the score is below 0.5 which might be surprising at\n",
    "first. We will now check the performance of a model which always predict the\n",
    "low revenue class, i.e. `\" <=50K\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_predict = \" <=50K\"\n",
    "low_revenue_clf = DummyClassifier(strategy=\"constant\",\n",
    "                                  constant=class_to_predict)\n",
    "low_revenue_clf.fit(data_numeric_train, target_train)\n",
    "score = low_revenue_clf.score(data_numeric_test, target_test)\n",
    "print(f\"Accuracy of a model predicting only low revenue: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this model has an accuracy higher than 0.5. This is due to\n",
    "the fact that we have 3/4 of the target belonging to low-revenue class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, any predictive model giving results below this dummy classifier\n",
    "will not be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target == \" <=50K\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we could have the strategy `\"most_frequent\"` to predict the\n",
    "class that appears the most in the training target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_revenue_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "most_freq_revenue_clf.fit(data_numeric_train, target_train)\n",
    "score = most_freq_revenue_clf.score(data_numeric_test, target_test)\n",
    "print(f\"Accuracy of a model predicting the most frequent class: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 81% accuracy is significantly better than 76% which is the score of a\n",
    "baseline model that would always predict the most frequent class which is the\n",
    "low revenue class: `\" <=50K\"`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
