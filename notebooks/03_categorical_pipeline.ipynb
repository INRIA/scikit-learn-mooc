{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding of categorical variables\n",
    "\n",
    "In this notebook, we will present typical ways to deal with **categorical\n",
    "variables**, namely **ordinal encoding** and **one-hot encoding**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the entire adult dataset containing both numerical and\n",
    "categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "\n",
    "target_name = \"class\"\n",
    "target = df[target_name]\n",
    "\n",
    "data = df.drop(columns=[target_name, \"fnlwgt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Identify categorical variables\n",
    "\n",
    "As we have seen in the previous section, a numerical variable is a continuous\n",
    "quantity represented by a real or integer number. These variables can be\n",
    "naturally handled by machine learning algorithms that are typically composed\n",
    "of a sequence of arithmetic instructions such as additions and\n",
    "multiplications.\n",
    "\n",
    "In contrast, categorical variables have discrete values, typically\n",
    "represented by string labels taken from a finite list of possible choices.\n",
    "For instance, the variable `native-country` in our dataset is a categorical\n",
    "variable because it encodes the data using a finite list of possible\n",
    "countries (along with the `?` symbol when this information is missing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"native-country\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might question how could we easily recognize categorical columns. One\n",
    "useful tip is to look at the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the \"native-country\" column data type, we observe it is of\n",
    "`object` data type. The reason is that categories are represented with\n",
    "string.\n",
    "\n",
    "Sometimes, categorical columns could also be encoded with integer. In this\n",
    "case, looking at the data type will not be enough. In the exploration and in\n",
    "the previous notebook, we saw that the column `\"education-num\"` is such a\n",
    "column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"education-num\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering categorical columns, we should include this columns.\n",
    "However, we also saw that `\"education-num\"` and `\"education\"` columns\n",
    "represent exactly the same information. Therefore, we can use one of the two\n",
    "columns. So, we can make the choice to consider only `object` dtype columns.\n",
    "\n",
    "## Select features based on their data type\n",
    "\n",
    "In the previous notebook, we manually defined the numerical columns. We could\n",
    "to the same here. However, since that we can select columns based on a\n",
    "specific dtypes, we can use a scikit-learn helper allowing to select the\n",
    "column based on their data types. It is called `make_column_selector`. We\n",
    "will illustrate how to use this helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the selector by passing the data type to include or exclude.\n",
    "Once the selector created, we can pass the input dataset and the name of\n",
    "the selected columns will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categorical = data[categorical_columns]\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset is composed of {data_categorical.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this section, we will present different strategies to\n",
    "encode categorical data into numerical data which can be used by a\n",
    "machine-learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding ordinal categories\n",
    "\n",
    "The most intuitive strategy is to encode each category with a different\n",
    "number. The `OrdinalEncoder` will transform the data in such manner.\n",
    "We will start by encoding a single column to understand how the encoding\n",
    "works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "education_column = data_categorical[[\"education\"]]\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "education_encoded = encoder.fit_transform(education_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually check the encoding obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    education_encoded[:10], columns=education_column.columns)\n",
    "ax = sns.heatmap(df, annot=True, cmap=\"tab20\", cbar=False)\n",
    "ax.set_ylabel(\"Sample index\")\n",
    "_ = ax.set_title(\"Ordinal encoding of 'education' column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each category in `\"education\"` has been replaced by a numeric\n",
    "values. Now, we can check the encoding applied on all categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The dataset encoded contains {data_encoded.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the categories have been encoded for each feature (column)\n",
    "independently. We can also note that the number of features before and after\n",
    "the encoding is the same.\n",
    "\n",
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">This encoding was used by the persons who published the dataset to transform\n",
    "the <tt class=\"docutils literal\">\"education\"</tt> feature into the <tt class=\"docutils literal\"><span class=\"pre\">\"education-num\"</span></tt> feature for instance.</p>\n",
    "</div>\n",
    "\n",
    "However, one has to be careful when using this encoding strategy. Using this\n",
    "integer representation can lead the downstream models to make the assumption\n",
    "that the categories are ordered: 0 is smaller than 1 which is smaller than 2,\n",
    "etc.\n",
    "\n",
    "By default, `OrdinalEncoder` uses a lexicographical strategy to map string\n",
    "category labels to integers. This strategy is completely arbitrary and often\n",
    "be meaningless. For instance suppose the dataset has a categorical variable\n",
    "named \"size\" with categories such as \"S\", \"M\", \"L\", \"XL\". We would like the\n",
    "integer representation to respect the meaning of the sizes by mapping them to\n",
    "increasing integers such as 0, 1, 2, 3. However lexicographical strategy used\n",
    "by default would map the labels \"S\", \"M\", \"L\", \"XL\" to 2, 1, 0, 3.\n",
    "\n",
    "The `OrdinalEncoder` class accepts a `categories` constructor argument to\n",
    "pass in the correct ordering explicitly.\n",
    "\n",
    "If a categorical variable does not carry any meaningful order information\n",
    "then this encoding might be misleading to downstream statistical models and\n",
    "you might consider using one-hot encoding instead (see below).\n",
    "\n",
    "<div class=\"admonition important alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Important</p>\n",
    "<p class=\"last\">Note however that the impact of violating this ordering assumption is really\n",
    "dependent on the downstream models (for instance linear models are much more\n",
    "sensitive than models built from a ensemble of decision trees).</p>\n",
    "</div>\n",
    "\n",
    "## Encoding nominal categories (without assuming any order)\n",
    "\n",
    "`OneHotEncoder` is an alternative encoder that can prevent the dowstream\n",
    "models to make a false assumption about the ordering of categories. For a\n",
    "given feature, it will create as many new columns as there are possible\n",
    "categories. For a given sample, the value of the column corresponding to the\n",
    "category will be set to `1` while all the columns of the other categories\n",
    "will be set to `0`.\n",
    "\n",
    "We will start by encoding a single feature (e.g. `\"education\"`) to illustrate\n",
    "how the encoding works.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">We will pass the argument <tt class=\"docutils literal\">sparse=False</tt> to the <tt class=\"docutils literal\">OneHotEncoder</tt> which will\n",
    "avoid obtaining a sparse matrix, which is less efficient but easier to\n",
    "inspect results for didactic purposes.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "education_encoded = encoder.fit_transform(education_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous section, we will visually check the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    education_encoded[:10],\n",
    "    columns=encoder.get_feature_names(education_column.columns))\n",
    "ax = sns.heatmap(df, annot=True, cmap=\"RdBu\", cbar=False)\n",
    "ax.set_ylabel(\"Sample index\")\n",
    "_ = ax.set_title(\"Ordinal encoding of 'education' column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we observed that each category in education becomes a column and the\n",
    "data resulting from the encoding is indicating whether or not the sample\n",
    "belong to this category.\n",
    "\n",
    "Let's apply this encoding on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The dataset is composed of {data_categorical.shape[1]} features\")\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The dataset encoded contains {data_encoded.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this NumPy array in a dataframe with informative column names as\n",
    "provided by the encoder object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_encoded = encoder.get_feature_names(data_categorical.columns)\n",
    "pd.DataFrame(data_encoded, columns=columns_encoded).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how the \"workclass\" variable of the first 3 records has been encoded\n",
    "and compare this to the original string representation.\n",
    "\n",
    "The number of features after the encoding is more than 10 times larger than\n",
    "in the original data because some variables such as `occupation` and\n",
    "`native-country` have many possible categories.\n",
    "\n",
    "## Evaluate our predictive pipeline\n",
    "\n",
    "We can now integrate this encoder inside a machine learning pipeline like we\n",
    "did with numerical data: let's train a linear classifier on the encoded data\n",
    "and check the performance of this machine learning pipeline using\n",
    "cross-validation.\n",
    "\n",
    "Before to create the pipeline, we have to linger on the `native-country`.\n",
    "Let's recall some statistics regarding this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"native-country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `Holand-Netherlands` category is occuring rarely. This will\n",
    "be a problem during cross-validation: if the sample is in the test set then\n",
    "the classifier would not have seen the category during training and will not\n",
    "be able to encode it.\n",
    "\n",
    "In scikit-learn, there is two solutions to bypass this issue:\n",
    "\n",
    "* list all the possible categories and provide it to the `categories`;\n",
    "* set the parameter `handle_unknown=\"ignore\"`.\n",
    "\n",
    "Here, we will use the former strategy because we are going to use it as well\n",
    "for the ordinal encoder later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [data_categorical[column].unique()\n",
    "              for column in data_categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(\n",
    "    OneHotEncoder(categories=categories, drop=\"if_binary\"),\n",
    "    LogisticRegression(max_iter=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check the model's performance only using the categorical\n",
    "columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, data_categorical, target)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The accuracy is: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this representation of the categorical variables of the data\n",
    "is slightly more predictive of the revenue than the numerical variables that\n",
    "we used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook we have:\n",
    "* seen two common strategies for encoding categorical features : **ordinal\n",
    "  encoding** and **one-hot encoding**;\n",
    "* used a pipeline to process **both numerical and categorical** features\n",
    "  before fitting a logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
