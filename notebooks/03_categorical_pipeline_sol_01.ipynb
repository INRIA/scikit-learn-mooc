{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ƒ Solution for Exercise 01\n",
    "\n",
    "The goal of this exercise is to evaluate the impact of using an arbitrary\n",
    "integer encoding for categorical variables along with a linear\n",
    "classification model such as Logistic Regression.\n",
    "\n",
    "To do so, let's try to use `OrdinalEncoder` to preprocess the categorical\n",
    "variables. This preprocessor is assembled in a pipeline with\n",
    "`LogisticRegression`. The performance of the pipeline can be evaluated as\n",
    "usual by cross-validation and then compared to the score obtained when using\n",
    "`OneHotEncoder` or to some other baseline score.\n",
    "\n",
    "Because `OrdinalEncoder` can raise errors if it sees an unknown category at\n",
    "prediction time, we need to pre-compute the list of all possible categories\n",
    "ahead of time:\n",
    "\n",
    "```python\n",
    "categories = [data[column].unique()\n",
    "              for column in data[categorical_columns]]\n",
    "OrdinalEncoder(categories=categories)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = df[target_name]\n",
    "data = df.drop(columns=[target_name, \"fnlwgt\", \"education-num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the categorical based on the `object` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "data_categorical = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the lecture notebook, one of the column has rare categories.\n",
    "Thus, we can make sure to not run into trouble in the cross-validation by\n",
    "specifying the known categories in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    data[column].unique() for column in data[categorical_columns]]\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make our predictive pipeline by encoding categories with an\n",
    "ordinal encoder before to feed a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(\n",
    "    OrdinalEncoder(categories=categories),\n",
    "    LogisticRegression(max_iter=500))\n",
    "scores = cross_val_score(model, data_categorical, target)\n",
    "print(f\"The different scores obtained are: \\n{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The accuracy is: {scores.mean():.3f} +- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an arbitrary mapping from string labels to integers as done here causes\n",
    "the linear model to make bad assumptions on the relative ordering of\n",
    "categories.\n",
    "\n",
    "This prevents the model from learning anything predictive enough and the\n",
    "cross-validated score is even lower that the baseline we obtained by ignoring\n",
    "the input data and just always predict the most frequent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "scores = cross_val_score(DummyClassifier(strategy=\"most_frequent\"),\n",
    "                         data_categorical, target)\n",
    "print(f\"The different scores obtained are: \\n{scores}\")\n",
    "print(f\"The accuracy is: {scores.mean():.3f} +- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparison, a categorical encoding that does not assume any ordering in\n",
    "the categories can lead to a significantly higher score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "model = make_pipeline(\n",
    "    OneHotEncoder(categories=categories, drop=\"if_binary\"),\n",
    "    LogisticRegression(max_iter=500))\n",
    "scores = cross_val_score(model, data_categorical, target)\n",
    "print(f\"The different scores obtained are: \\n{scores}\")\n",
    "print(f\"The accuracy is: {scores.mean():.3f} +- {scores.std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
