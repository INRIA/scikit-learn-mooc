{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to hyperparameter tuning\n",
    "\n",
    "The process of learning a predictive model is driven by a set of internal\n",
    "parameters and a set of training data. These internal parameters are called\n",
    "hyperparameters and are specific for each family of models. In addition, a\n",
    "specific set of hyperparameters are optimal for a specific dataset and thus\n",
    "they need to be optimized. In this notebook we will use the words\n",
    "\"hyperparameters\" and \"parameters\" interchangeably.\n",
    "\n",
    "This notebook shows the influence of changing model hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reload the adult census dataset and ignore some of the columns\n",
    "as previously done in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = df[target_name]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=[target_name, \"fnlwgt\", \"education-num\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is loaded, we split it into a training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the preprocessing pipeline to transform differently\n",
    "the numerical and categorical data, identically to the previous notebook.\n",
    "We will use an ordinal encoder for the categories because we will use an\n",
    "histogram gradient-boosting as predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "categories = [\n",
    "    data[column].unique() for column in data[categorical_columns]]\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(categories=categories)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat-preprocessor', categorical_preprocessor, categorical_columns)],\n",
    "    remainder='passthrough', sparse_threshold=0)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use a tree-based classifier (i.e. histogram gradient-boosting) to\n",
    "predict whether or not a person earns more than 50,000 dollars a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# for the moment this line is required to import HistGradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\",\n",
    "     HistGradientBoostingClassifier(random_state=42))])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df_train, target_train)\n",
    "\n",
    "print(\n",
    "    f\"The test accuracy score of the gradient boosting pipeline is: \"\n",
    "    f\"{model.score(df_test, target_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we created an histogram gradient-boosting classifier\n",
    "using the default parameters by omitting to explicitely set these parameters.\n",
    "\n",
    "However, there is no reason that these parameters are optimal for our\n",
    "dataset. For instance, we can try to set the `learning_rate` parameter and\n",
    "see how it changes the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\",\n",
    "     HistGradientBoostingClassifier(random_state=42, learning_rate=1e-3))\n",
    "])\n",
    "model.fit(df_train, target_train)\n",
    "print(\n",
    "    f\"The test accuracy score of the gradient boosting pipeline is: \"\n",
    "    f\"{model.score(df_test, target_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\",\n",
    "     HistGradientBoostingClassifier(random_state=42, learning_rate=10))\n",
    "])\n",
    "model.fit(df_train, target_train)\n",
    "print(\n",
    "    f\"The test accuracy score of the gradient boosting pipeline is: \"\n",
    "    f\"{model.score(df_test, target_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quizz\n",
    "\n",
    "1. What is the default value of the `learning_rate` parameter of the\n",
    "`HistGradientBoostingClassifier` class? ([link to the API documentation](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html))\n",
    "\n",
    "2. Decrease progressively value of `learning_rate`: can you find a value that\n",
    "yields an accuracy higher than with the default learning rate?\n",
    "\n",
    "3. Fix `learning_rate` to 0.05 and try setting the value of `max_leaf_nodes`\n",
    "to the minimum value of 2. Does it improve the accuracy?\n",
    "\n",
    "4. Try to progressively increase the value of `max_leaf_nodes` to 256 by\n",
    "taking powers of 2. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a model's parameter\n",
    "\n",
    "Actually scikit-learn estimators have a `set_params` method that allows you\n",
    "to change the parameter of a model after it has been created. For example, we\n",
    "can set the `learning_rate=1e-3` and check that we get the same score as\n",
    "previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model.set_params(classifier__learning_rate=1e-3)\n",
    "model.fit(df_train, target_train)\n",
    "print(\n",
    "    f\"The test accuracy score of the gradient boosting pipeline is: \"\n",
    "    f\"{model.score(df_test, target_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model of interest is a `Pipeline`, the parameter names are of the\n",
    "form `<model_name>__<parameter_name>` (note the double underscore in the\n",
    "middle). In our case, `classifier` comes from the `Pipeline` definition and\n",
    "`learning_rate` is the parameter name of `HistGradientBoostingClassifier`.\n",
    "\n",
    "In general, you can use the `get_params` method on scikit-learn models to\n",
    "list all the parameters with their values. For example, if you want to\n",
    "get all the parameter names, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.get_params():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_params()` returns a `dict` whose keys are the parameter names and whose\n",
    "values are the parameter values. If you want to get the value of a single\n",
    "parameter, for example `classifier__learning_rate`, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()['classifier__learning_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have seen:\n",
    "\n",
    "- how hyperparameters can affect the performance of a model;\n",
    "- how to use `get_params` and `set_params` to get the parameters of a model\n",
    "  and set them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
