{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcdd Exercise M4.02\n",
    "\n",
    "In a previous notebook we introduced the use of performance metrics to\n",
    "evaluate a clustering model when we have access to labeled data, namely the\n",
    "V-measure and Adjusted Rand Index (ARI). In this exercise you will get\n",
    "familiar with another supervised metric for clustering, known as Adjusted\n",
    "Mutual Information (AMI).\n",
    "\n",
    "To illustrate the different concepts, we retain some of the features from the\n",
    "penguins dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Flipper Length (mm)\",\n",
    "    \"Body Mass (g)\",\n",
    "    \"Sex\",\n",
    "    \"Species\",\n",
    "]\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")[columns_to_keep].dropna()\n",
    "species = penguins[\"Species\"].str.split(\" \").str[0]\n",
    "penguins = penguins.drop(columns=[\"Species\"])\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that the silhouette score presented a maximum when `n_clusters=6`\n",
    "when using all of the features above (not the species). Our hypothesis was\n",
    "that those clusters correspond to the 3 species of penguins present in the\n",
    "dataset (Adelie, Chinstrap, and Gentoo) further splitted by Sex (2 clusters\n",
    "for each species).\n",
    "\n",
    "Repeat the same pipeline consisting of a `OneHotEncoder` with\n",
    "`drop=\"if_binary\"` for the \"Sex\" column, a `StandardScaler` for the other\n",
    "columns. The final estimator should be `KMeans` with `n_clusters=6`. You can\n",
    "set the `random_state` for reproducibility, but that should not change the\n",
    "interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make two `sns.scatterplot` of \"Culmen Length (mm)\" versus \"Flipper Length\n",
    "(mm)\", side-by-side. On one of them, the `hue` should be the \"species and sex\"\n",
    "coming from the known information in the dataset, and the `hue` in the other\n",
    "should be the cluster labels.\n",
    "\n",
    "Only the colors may differ, as the ordering of the labels is arbitrary (both\n",
    "for the k-means cluster and the \"true\" labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a visual intuition of the agreement between the clusters found by\n",
    "k-means and the combination of the \"Species\" and \"Sex\" labels. We can further\n",
    "quantify it using the Adjusted Mutual Information (AMI) score.\n",
    "\n",
    "Use\n",
    "[`sklearn.metrics.adjusted_mutual_info_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html)\n",
    "to compare both sets of labels. The AMI returns a value of 1 when the two\n",
    "partitions are identical (ie perfectly matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a\n",
    "[`sklearn.preprocessing.LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "to `fit_transform` the \"true\" labels (coming from combinations of species and\n",
    "sex). What would be the accuracy if we tried to use it to measure the\n",
    "agreement between both sets of labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permute the cluster labels using `np.random.permutation`, then compute both\n",
    "the AMI and the accuracy when comparing the true and permuted labels. Are they\n",
    "sensitive to relabeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMI is designed to return a value near zero (it can be negative) when the\n",
    "clustering is no better than random.\n",
    "\n",
    "To understand how AMI corrects for chance, compare the true labels with a\n",
    "completely random labeling using `np.random.randint` to generate as many\n",
    "labels as rows in the dataset, each containing a value between 0 and 5 (to\n",
    "match the number of clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can conclude by comparing AMI to other metrics:\n",
    "\n",
    "- Adjusted Rand Index (ARI): Also corrects for chance, but it counts pairs of\n",
    "  points, in other words, how many pairs that are together in the true labels\n",
    "  are also together in the clusters. It is combinatorial, not based on\n",
    "  information-theory as AMI.\n",
    "- V-measure: Based on homogeneity (do clusters contain mostly one class?) and\n",
    "  completeness (are all members of a class grouped together?), but it does not\n",
    "  correct for chance. If you run a random clustering, V-measure might still\n",
    "  give a misleadingly non-zero score, unlike AMI or ARI."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}