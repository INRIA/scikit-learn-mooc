{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering\n",
    "\n",
    "So far we have only addressed supervised learning models, namely regression\n",
    "and classification. In this module we introduce unsupervised learning for the\n",
    "first time.\n",
    "\n",
    "In this notebook we explore the k-means algorithm, which seeks to group data\n",
    "based on the pairwise distances between data points. To illustrate the\n",
    "different concepts, we will extract some numerical features from the penguins\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Species\",\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Flipper Length (mm)\",\n",
    "    \"Body Mass (g)\",\n",
    "    \"Sex\",\n",
    "]\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")[columns_to_keep].dropna()\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that this datasets contains data about 3 different species of\n",
    "penguins, but we will not explicitly rely on this information and instead\n",
    "treat the problem as an unsupervised data analysis task. The goal is to\n",
    "assess whether K-means can help us discover meaningful clusters in the data.\n",
    "\n",
    "Let's hide this column for now. We will only use it at the end of the notebook:\n",
    "species = penguins[\"Species\"]\n",
    "penguins = penguins.drop(columns=[\"Species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take a first look at the structure of the numerical features using a\n",
    "pairplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "_ = sns.pairplot(penguins, height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On these plots, we more or less easily visually recognize 2 to 3 clusters\n",
    "depending on the feature pairs.\n",
    "\n",
    "We suspect that the clusters overlap because female penguins are generally\n",
    "smaller than male penguins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(penguins, hue=\"Sex\", height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us focus on female individuals to visually assess if the clusters are\n",
    "better separated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_penguins = penguins.query(\"Sex == 'FEMALE'\")\n",
    "_ = sns.pairplot(female_penguins, height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we can see, the clusters look better separated on this subset of the\n",
    "dataset.\n",
    "\n",
    "In particular we can see that if we only consider:\n",
    "- **Culmen Length** and **Body Mass**, we can distinguish 3 clusters;\n",
    "- **Culmen Depth** and **Body Mass**, we can distinguish 2 clusters.\n",
    "\n",
    "Let's try to apply the k-means algorithm on the first pairs of columns to see\n",
    "whether we can find the clusters that we visually identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_cl_vs_bm = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans_labels_cd_vs_bm = kmeans_cl_vs_bm.fit_predict(\n",
    "    female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]]\n",
    ")\n",
    "kmeans_labels_cd_vs_bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `fit_predict` method returns the cluster labels for each data point coded\n",
    "with an arbitrary integer between 0 and `n_clusters - 1`.\n",
    "\n",
    "Let's add consolidate these labels in the original dataframe and visualize the\n",
    "clusters:\n",
    "\n",
    "clustered_female_peng = female_penguins.copy()\n",
    "clustered_female_peng[\"K-means label\"] = kmeans_labels_cd_vs_bm\n",
    "ax = sns.scatterplot(\n",
    "    data=clustered_female_peng,\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Body Mass (g)\",\n",
    "    hue=\"K-means label\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The result is disappointing: the 3 clusters found by k-means  do not match\n",
    "what would have naively expected from the scatter plot.\n",
    "\n",
    "What could explain this?\n",
    "\n",
    "Clusters are defined by the distance between data points, and the `KMeans`\n",
    "algorithm tries to minimize the distance between data points and their\n",
    "cluster centroid. But as we can see on the axis of the scatter plot, the\n",
    "values of \"Culmen Length (mm)\" and \"Body Mass (g)\" are not on the same scale.\n",
    "\n",
    "If we use the original units, the distances between data points are almost\n",
    "entirely dominated by the \"Body Mass (g)\" feature,  which has numerical\n",
    "values expressed on a scale that is much larger than the \"Culmen Length (mm)\"\n",
    "feature.\n",
    "\n",
    "We can visualize this by plotting the data by disabling the automated visual\n",
    "scaling of the axes by manually setting the same numerical limits for both\n",
    "axes:\n",
    "min_numerical_value = 0\n",
    "max_numerical_value = clustered_female_peng[\"Body Mass (g)\"].max() * 1.1\n",
    "ax = sns.scatterplot(\n",
    "    data=clustered_female_peng,\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Body Mass (g)\",\n",
    "    hue=\"K-means label\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.set(\n",
    "    xlim=(min_numerical_value, max_numerical_value),\n",
    "    ylim=(min_numerical_value, max_numerical_value),\n",
    "    aspect=\"equal\",\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Under this new perspective, the k-means clustering results make more sense:\n",
    "the \"Culmen Length\" is not taken into account because the numerical values\n",
    "expressed in mm are much smaller than the \"Body Mass\" values expressed in\n",
    "grams.\n",
    "\n",
    "To mitigate this problem, we can instead define a pipeline to use always\n",
    "standardize the values of the numerical features before applying the\n",
    "clustering algorithm. This way, all features will have the same scale and\n",
    "contribute more or less equally to the distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_kmeans_cl_vs_bm = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KMeans(n_clusters=3, random_state=0),\n",
    ")\n",
    "scaled_kmeans_labels_cd_vs_bm = scaled_kmeans_cl_vs_bm.fit_predict(\n",
    "    female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]]\n",
    ")\n",
    "clustered_female_peng = female_penguins.copy()\n",
    "clustered_female_peng[\"K-means label\"] = scaled_kmeans_labels_cd_vs_bm\n",
    "ax = sns.scatterplot(\n",
    "    data=clustered_female_peng,\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Body Mass (g)\",\n",
    "    hue=\"K-means label\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "Now the results of the k-means cluster better match our visual intuition on this pair of features.\n",
    "\n",
    "Let's do a similar analysis on the second pair of features, namely\n",
    "\"Culmen Depth (mm)\" and \"Body Mass (g)\". To do so we refactor the code above in a utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans_clusters_on_2d_data(\n",
    "    clustering_model,\n",
    "    data,\n",
    "    first_feature_name,\n",
    "    second_feature_name,\n",
    "):\n",
    "    labels = clustering_model.fit_predict(\n",
    "        data[[first_feature_name, second_feature_name]]\n",
    "    )\n",
    "    clustered_data = data.copy()\n",
    "    clustered_data[\"K-means label\"] = labels\n",
    "    ax = sns.scatterplot(\n",
    "        data=clustered_data,\n",
    "        x=first_feature_name,\n",
    "        y=second_feature_name,\n",
    "        hue=\"K-means label\",\n",
    "        palette=\"deep\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "plot_kmeans_clusters_on_2d_data(\n",
    "    make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KMeans(n_clusters=2, random_state=0),\n",
    "    ),\n",
    "    female_penguins,\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Body Mass (g)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here again the clusters are well separated and the k-means algorithm\n",
    "identified clusters that match our visual intuition.\n",
    "\n",
    "We can also try to apply the k-means algorithm with a larger value for\n",
    "`n_clusters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kmeans_clusters_on_2d_data(\n",
    "    make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KMeans(n_clusters=6, random_state=0),\n",
    "    ),\n",
    "    female_penguins,\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Body Mass (g)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When we select a large value of `n_clusters`, we observe that k-means will\n",
    "build as many groups as requested even if the resulting groups are not well\n",
    "separated.\n",
    "\n",
    "Let's now see we can use this intuition on cluster separation to identify\n",
    "suitable valuers for the number of clusters based on heuristic methods\n",
    "introduced earlier in the course.\n",
    "\n",
    "Let's start by plotting the evolution of the WCSS (Within-Cluster Sum of\n",
    "Squares) metric as a function of the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wcss = []\n",
    "n_clusters_values = range(1, 11)\n",
    "\n",
    "for n_clusters in n_clusters_values:\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KMeans(n_clusters=n_clusters, random_state=0),\n",
    "    )\n",
    "    cluster_labels = model.fit_predict(\n",
    "        female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]]\n",
    "    )\n",
    "    wcss.append(model.named_steps[\"kmeans\"].inertia_)\n",
    "\n",
    "plt.plot(n_clusters_values, wcss, marker=\"o\")\n",
    "plt.xlabel(\"Number of clusters (n_clusters)\")\n",
    "plt.ylabel(\"WCSS (or inertia)\")\n",
    "_ = plt.title(\"Elbow method using WCSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As expected the WCSS value decreases as the number of clusters increases and\n",
    "we can observe a so-called \"elbow\" in the curve (the point with maximum\n",
    "curvature) around `n_clusters=3`. This matches the number of cluster found by\n",
    "our visual intuition when looking at this 2D scatter plots.\n",
    "\n",
    "However, the elbow method is not always easy to read.\n",
    "\n",
    "Let's try to use the silhouette score instead. Note that this method requires\n",
    "access to the preprocessed features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def plot_silhouette_scores(\n",
    "    data,\n",
    "    clustering_model=None,\n",
    "    preprocessor=None,\n",
    "    n_clusters_values=range(2, 11),\n",
    "):\n",
    "    if clustering_model is None:\n",
    "        clustering_model = KMeans(random_state=0)\n",
    "\n",
    "    if preprocessor is None:\n",
    "        preprocessor = StandardScaler()\n",
    "\n",
    "    preprocessed_data = preprocessor.fit_transform(data)\n",
    "\n",
    "    silhouette_scores = []\n",
    "    for n_clusters in n_clusters_values:\n",
    "        clustering_model.set_params(n_clusters=n_clusters)\n",
    "        cluster_labels = clustering_model.fit_predict(preprocessed_data)\n",
    "        score = silhouette_score(preprocessed_data, cluster_labels)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    plt.plot(n_clusters_values, silhouette_scores, marker=\"o\")\n",
    "    plt.xlabel(\"Number of clusters (n_clusters)\")\n",
    "    plt.ylabel(\"Silhouette score\")\n",
    "    _ = plt.title(\"Silhouette scores for different n_clusters\")\n",
    "\n",
    "\n",
    "plot_silhouette_scores(\n",
    "    female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The silhouette score reaches a maximum when `n_clusters=3`, which confirms\n",
    "our visual intuition on this 2D dataset.\n",
    "\n",
    "We can also notice that the silhouette score is also very high for\n",
    "`n_clusters=2` and has an intermediate value for `n_clusters=4`. It's\n",
    "possible that those two values would also yield qualitatively meaningful\n",
    "clusters, but this probably not the case for `n_clusters=5` or larger.\n",
    "\n",
    "Let's compare this to the results obtained on the second pair of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_silhouette_scores(\n",
    "    female_penguins[[\"Culmen Depth (mm)\", \"Body Mass (g)\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this feature set, the plot clearly shows that the silhouette score\n",
    "reaches a maximum when `n_clusters=2`, which matches our visual intuition\n",
    "from the scatter plot of this 2D feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can now try to apply the k-means algorithm on the full dataset, i.e. on\n",
    "all numerical features and all the rows, to see whether k-means can discover\n",
    "meaningful clusters in the data automatically.\n",
    "\n",
    "We also include the `Sex` feature in the clustering model to see whether\n",
    "it can help the algorithm to find better clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(drop=\"if_binary\"),\n",
    "        make_column_selector(dtype_exclude=\"number\"),\n",
    "    ),\n",
    "    (\n",
    "        StandardScaler(),\n",
    "        make_column_selector(dtype_include=\"number\"),\n",
    "    ),\n",
    ")\n",
    "plot_silhouette_scores(penguins, preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the silhouette scores, it seems that k-means would prefer to cluster\n",
    "those features into either 2 or 6 clusters.\n",
    "\n",
    "Let's try to visualize the clusters obtained with `n_clusters=6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    KMeans(n_clusters=6, random_state=0),\n",
    ")\n",
    "cluster_labels = model.fit_predict(penguins)\n",
    "_ = sns.pairplot(\n",
    "    penguins.assign(cluster_label=cluster_labels),\n",
    "    hue=\"cluster_label\",\n",
    "    palette=\"deep\",\n",
    "    height=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since this is high-dimensional data (5D), the pairplot (computed only for the\n",
    "4 numerical features) only offers a limited perspective on the clusters. But\n",
    "they do seem meaningful, and in particular we can notice that they could\n",
    "potentially correspond to the 3 species of penguins present in the dataset\n",
    "(Adelie, Chinstrap, and Gentoo) further splitted by Sex (2 clusters for each\n",
    "species, one for males and one for females).\n",
    "\n",
    "Let's try to confirm this hypothesis by looking at the original\n",
    "\"Species\" labels combined with the \"Sex\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_and_sex_labels = species + \" \" + penguins[\"Sex\"]\n",
    "species_and_sex_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(\n",
    "    penguins.assign(species_and_sex=species_and_sex_labels),\n",
    "    hue=\"species_and_sex\",\n",
    "    palette=\"deep\",\n",
    "    height=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This plot seems to be very similar to the pairplot we obtained with the 6\n",
    "clusters found by k-means on our preprocessed data. Note that the colors are\n",
    "different, because the ordering of the labels is arbitrary (both for the\n",
    "k-means cluster and the manually assigned labels). But the way of grouping\n",
    "the data points look similar.\n",
    "\n",
    "Let's quantify the agreement between the clusters found by k-means and the\n",
    "combination of the \"Species\" and \"Sex\" labels using the [Normalized Mutual\n",
    "Information](https://scikit-learn.org/stable/modules/clustering.html#mutual-info-score)\n",
    "(NMI) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "nmi = normalized_mutual_info_score(\n",
    "    species_and_sex_labels,\n",
    "    cluster_labels,\n",
    ")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This value is very close to 1.0, which indicates a very strong agreement.\n",
    "\n",
    "The conclusion is that we relate the clusters found by running k-means on\n",
    "those preprocessed features to a meaningful (human) way to partition the\n",
    "penguins records.\n",
    "\n",
    "Note however that this is not always the case. For **k-means to yield\n",
    "meaningful results, the data must be have an approximately balanced, convex\n",
    "and isotropic cluster structure** after preprocessing. That is, the clusters\n",
    "must have a spherical shape in the feature space and approximately the same\n",
    "size.\n",
    "\n",
    "We cannot stress enough that the choice of the features and preprocessing\n",
    "steps are crucial: if we had not standardized the numerical data, or we had\n",
    "not included the \"Sex\" feature or if we had scaled its one-hot encoding by a\n",
    "factor of 10, we would probably not have been able to discover interpretable\n",
    "clusters.\n",
    "\n",
    "Furthermore, **many natural datasets would not satisfy the k-means\n",
    "assumptions** even after non-trivial preprocessing. In those cases, we can\n",
    "either try alternatives to k-means that favor different cluster shapes (for\n",
    "instance HDBSCAN or Gaussian Mixture Models) or we can try to isolate\n",
    "row-wise or column-wise subsets of the data that are more likely to exhibit a\n",
    "cluster structure. Or sometimes, we can decide to partition the data with\n",
    "k-means with a large number of clusters, even if they are not interpretable\n",
    "and use the distance to centroids as preprocessing for another task. It all\n",
    "depends on the specific application domain and the downstream use of the\n",
    "resulting clusters.\n",
    "\n",
    "Finally, notice that we used extra supervised information to quantitatively\n",
    "assess the quality of the match between the clusters found by k-means and our\n",
    "interpretation. In practice, this is often impossible, as we do not have\n",
    "access to human assigned labels for each row in the data. Or, if we have, we\n",
    "might want to use them to train the clustering model, but instead we would\n",
    "rather use them as the target variable to train a supervised classifier."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}