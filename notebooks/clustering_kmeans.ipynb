{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering\n",
    "\n",
    "So far we have only addressed supervised learning models, namely regression\n",
    "and classification. In this module we introduce unsupervised learning for the\n",
    "first time.\n",
    "\n",
    "In this notebook we explore the k-means algorithm, which seeks to group data\n",
    "based on the pairwise distances between data points. To illustrate the\n",
    "different concepts, we retain some of the features from the penguins dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Flipper Length (mm)\",\n",
    "    \"Body Mass (g)\",\n",
    "    \"Sex\",\n",
    "    \"Species\",\n",
    "]\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")[columns_to_keep].dropna()\n",
    "penguins[\"Species\"] = penguins[\"Species\"].str.split(\" \").str[0]\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that this datasets contains data about 3 different species of\n",
    "penguins, but let's not rely on such information for the moment. Instead we\n",
    "can address the task using clustering. This could be the case, for example,\n",
    "when analyzing newly collected penguin data in the wild where species haven't\n",
    "yet been identified, or when the goal is to detect natural groupings such as\n",
    "subpopulations, hybrids, or other variations. It\u2019s also useful as a data\n",
    "exploration tool: before committing to a classifier, clustering can help\n",
    "assess whether the chosen features separate the data well.\n",
    "\n",
    "Let's hide this column for now. We will only use it at the end of this\n",
    "notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = penguins[\"Species\"]\n",
    "penguins = penguins.drop(columns=[\"Species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take a first look at the structure of the available features using a\n",
    "`pairplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "_ = sns.pairplot(penguins, hue=\"Sex\", height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On these plots, we visually recognize 2 to 3 clusters depending on the feature\n",
    "pairs. We can also notice that female penguins are generally smaller than male\n",
    "penguins.\n",
    "\n",
    "Let us focus on female individuals to visually assess if that subset of data\n",
    "leads to better separated clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_penguins = penguins.query(\"Sex == 'FEMALE'\")\n",
    "_ = sns.pairplot(female_penguins, height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Intuitively, a good cluster should be compact (with points close to each\n",
    "other), and well-separated from other clusters, which is indeed the case for\n",
    "this subset of the data.\n",
    "\n",
    "In particular we can see that if we only consider:\n",
    "- **Culmen Length** and **Body Mass**, we can distinguish 3 clusters;\n",
    "- **Culmen Depth** and **Body Mass**, we can distinguish 2 clusters.\n",
    "\n",
    "Let's try to apply the k-means algorithm on the first pairs of columns to see\n",
    "whether we can find the clusters that we visually identified. The\n",
    "hyperparameter `n_clusters` sets the numbers of clusters and the\n",
    "`random_state` controls the centroid initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels_cl_vs_bm = kmeans.fit_predict(\n",
    "    female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]]\n",
    ")\n",
    "labels_cl_vs_bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">Here we used the <tt class=\"docutils literal\">fit_predict</tt> method, which does both steps at once: it\n",
    "learns from the data just as using <tt class=\"docutils literal\">fit</tt>, and immediately returns cluster\n",
    "labels for each data point using <tt class=\"docutils literal\">predict</tt>. Cluster labels are coded with an\n",
    "arbitrary integer between 0 and <tt class=\"docutils literal\">n_clusters - 1</tt>.</p>\n",
    "</div>\n",
    "\n",
    "Let's consolidate these labels in the original dataframe and visualize the\n",
    "clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=female_penguins.assign(kmeans_labels=labels_cl_vs_bm),\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Body Mass (g)\",\n",
    "    hue=\"kmeans_labels\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The result is disappointing: the 3 clusters found by k-means do not match\n",
    "what we would have naively expected from the scatter plot.\n",
    "\n",
    "What could explain this?\n",
    "\n",
    "Clusters are defined by the distance between data points, and the `KMeans`\n",
    "algorithm tries to minimize the distance between data points and their\n",
    "cluster centroid. But as we can see on the axis of the scatter plot, the\n",
    "values of \"Culmen Length (mm)\" and \"Body Mass (g)\" are not on the same scale.\n",
    "\n",
    "We can visualize this by manually setting the same scale to both axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 0\n",
    "max_value = female_penguins[\"Body Mass (g)\"].max() * 1.1\n",
    "ax = sns.scatterplot(\n",
    "    data=female_penguins.assign(kmeans_labels=labels_cl_vs_bm),\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Body Mass (g)\",\n",
    "    hue=\"kmeans_labels\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.set(\n",
    "    xlim=(min_value, max_value),\n",
    "    ylim=(min_value, max_value),\n",
    "    aspect=\"equal\",\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We thus confirm that, when using in the original units, the distances between\n",
    "data points are almost entirely dominated by the \"Body Mass (g)\" feature,\n",
    "which has much larger numerical values than the \"Culmen Length (mm)\" feature.\n",
    "\n",
    "To mitigate this problem, we can instead define a pipeline to scale the\n",
    "numerical features before clustering. This way, all features contribute\n",
    "similarly to the distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_kmeans = make_pipeline(\n",
    "    StandardScaler(), KMeans(n_clusters=3, random_state=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "Notice that scaling features by their standard deviation using\n",
    "`StandardScaler` is just one way to achieve this. Other options include\n",
    "`RobustScaler`, `MinMaxScaler`, and several others, which work similarly but\n",
    "may behave differently depending on the data. For more details, refer to the\n",
    "[preprocessing data](\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html) section in the\n",
    "scikit-learn user guide.\n",
    "\n",
    "To avoid repeating the code for plotting, we can define a helper\n",
    "function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans_clusters_on_2d_data(\n",
    "    clustering_model,\n",
    "    data,\n",
    "    first_feature_name,\n",
    "    second_feature_name,\n",
    "):\n",
    "    labels = clustering_model.fit_predict(\n",
    "        data[[first_feature_name, second_feature_name]]\n",
    "    )\n",
    "    ax = sns.scatterplot(\n",
    "        data=data.assign(kmeans_labels=labels),\n",
    "        x=first_feature_name,\n",
    "        y=second_feature_name,\n",
    "        hue=\"kmeans_labels\",\n",
    "        palette=\"deep\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "plot_kmeans_clusters_on_2d_data(\n",
    "    scaled_kmeans, female_penguins, \"Culmen Length (mm)\", \"Body Mass (g)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now the results of the k-means cluster better match our visual intuition on\n",
    "this pair of features.\n",
    "\n",
    "Let's do a similar analysis on the second pair of features, namely \"Culmen\n",
    "Depth (mm)\" and \"Body Mass (g)\". To do so, let's refactor the code above as a\n",
    "utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_kmeans = make_pipeline(\n",
    "    StandardScaler(), KMeans(n_clusters=2, random_state=0)\n",
    ")\n",
    "\n",
    "plot_kmeans_clusters_on_2d_data(\n",
    "    scaled_kmeans, female_penguins, \"Culmen Depth (mm)\", \"Body Mass (g)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here again the clusters are well separated and the k-means algorithm\n",
    "identified clusters that match our visual intuition.\n",
    "\n",
    "We can also try to apply the k-means algorithm with a larger value for\n",
    "`n_clusters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_kmeans = make_pipeline(\n",
    "    StandardScaler(), KMeans(n_clusters=6, random_state=0)\n",
    ")\n",
    "\n",
    "plot_kmeans_clusters_on_2d_data(\n",
    "    scaled_kmeans, female_penguins, \"Culmen Length (mm)\", \"Body Mass (g)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When we select a large value of `n_clusters`, we observe that k-means builds\n",
    "as many groups as requested even if the resulting clusters are not well\n",
    "separated.\n",
    "\n",
    "Let's now see if we can identify suitable values for the number of clusters\n",
    "based on some heuristics. We start by plotting the evolution of the WCSS\n",
    "(Within-Cluster Sum of Squares) metric as a function of the number of\n",
    "clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wcss = []\n",
    "n_clusters_values = range(1, 11)\n",
    "\n",
    "for n_clusters in n_clusters_values:\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KMeans(n_clusters=n_clusters, random_state=0),\n",
    "    )\n",
    "    cluster_labels = model.fit_predict(\n",
    "        female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]]\n",
    "    )\n",
    "    wcss.append(model.named_steps[\"kmeans\"].inertia_)\n",
    "\n",
    "plt.plot(n_clusters_values, wcss, marker=\"o\")\n",
    "plt.xlabel(\"Number of clusters (n_clusters)\")\n",
    "plt.ylabel(\"WCSS (or inertia)\")\n",
    "_ = plt.title(\"Elbow method using WCSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can observe the so-called \"elbow\" in the curve (the point with maximum\n",
    "curvature) around `n_clusters=3`. This matches our visual intuition coming\n",
    "from the \"Culmen Length\" vs \"Body Mass\" scatter plot.\n",
    "\n",
    "However, the WCSS value decreases monotonically as the number of clusters\n",
    "increases, and then we may be overlooking important information. Let's now\n",
    "plot the silhouette score instead. Notice that this method requires access to\n",
    "the preprocessed features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def plot_silhouette_scores(\n",
    "    data,\n",
    "    clustering_model=None,\n",
    "    preprocessor=None,\n",
    "    n_clusters_values=range(2, 11),\n",
    "    title_details=\"all features\",\n",
    "):\n",
    "    if clustering_model is None:\n",
    "        clustering_model = KMeans(random_state=0)\n",
    "\n",
    "    if preprocessor is None:\n",
    "        preprocessor = StandardScaler()\n",
    "\n",
    "    preprocessed_data = preprocessor.fit_transform(data)\n",
    "\n",
    "    silhouette_scores = []\n",
    "    for n_clusters in n_clusters_values:\n",
    "        clustering_model.set_params(n_clusters=n_clusters)\n",
    "        cluster_labels = clustering_model.fit_predict(preprocessed_data)\n",
    "        score = silhouette_score(preprocessed_data, cluster_labels)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    plt.plot(n_clusters_values, silhouette_scores, marker=\"o\")\n",
    "    plt.xlabel(\"Number of clusters (n_clusters)\")\n",
    "    plt.ylabel(\"Silhouette score\")\n",
    "    _ = plt.title(\"Silhouette scores using\\n\" + title_details)\n",
    "\n",
    "\n",
    "plot_silhouette_scores(\n",
    "    female_penguins[[\"Culmen Length (mm)\", \"Body Mass (g)\"]],\n",
    "    title_details=\"Culmen Length and Body Mass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The silhouette score reaches a maximum when `n_clusters=3`, which confirms our\n",
    "visual intuition on this 2D dataset.\n",
    "\n",
    "We can also notice that the silhouette score is similarly high for\n",
    "`n_clusters=2`, and has an intermediate value for `n_clusters=4`. It is\n",
    "possible that those two values would also yield qualitatively meaningful\n",
    "clusters, but that is less the case for `n_clusters=5` or more.\n",
    "\n",
    "Let's compare this to the results obtained on the second pair of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_silhouette_scores(\n",
    "    female_penguins[[\"Culmen Depth (mm)\", \"Body Mass (g)\"]],\n",
    "    title_details=\"Culmen Depth and Body Mass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The plot reaches a clear maximum silhouette score when `n_clusters=2`, which\n",
    "matches our intuition for those two features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can now try to apply the k-means algorithm on the full dataset, i.e. on all\n",
    "numerical features and all rows, regardless of the \"Sex\" feature, to see\n",
    "whether k-means can discover meaningful clusters in the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(drop=\"if_binary\"),\n",
    "        make_column_selector(dtype_exclude=\"number\"),\n",
    "    ),\n",
    "    (\n",
    "        StandardScaler(),\n",
    "        make_column_selector(dtype_include=\"number\"),\n",
    "    ),\n",
    ")\n",
    "plot_silhouette_scores(penguins, preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the silhouette scores, it seems that k-means would prefer to cluster\n",
    "those features into either 2 or 6 clusters.\n",
    "\n",
    "Let's try to visualize the clusters obtained with `n_clusters=6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    KMeans(n_clusters=6, random_state=0),\n",
    ")\n",
    "cluster_labels = model.fit_predict(penguins)\n",
    "_ = sns.pairplot(\n",
    "    penguins.assign(cluster_label=cluster_labels),\n",
    "    hue=\"cluster_label\",\n",
    "    palette=\"deep\",\n",
    "    height=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since this is high-dimensional data (5D), the pairplot (computed only for the\n",
    "4 numerical features) only offers a limited perspective on the clusters.\n",
    "Despite this limitation, the clusters do appear meaningful, and in particular\n",
    "we can notice that they potentially correspond to the 3 species of penguins\n",
    "present in the dataset (Adelie, Chinstrap, and Gentoo) further splitted by Sex\n",
    "(2 clusters for each species, one for males and one for females).\n",
    "\n",
    "Let's try to confirm this hypothesis by looking at the original \"Species\"\n",
    "labels combined with the \"Sex\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_and_sex_labels = species + \" \" + penguins[\"Sex\"]\n",
    "species_and_sex_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(\n",
    "    penguins.assign(species_and_sex=species_and_sex_labels),\n",
    "    hue=\"species_and_sex\",\n",
    "    palette=\"deep\",\n",
    "    height=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This plot seems to be very similar to the pairplot we obtained with the 6\n",
    "clusters found by k-means on our preprocessed data, i.e. in both cases plots\n",
    "that display 3 clusters can be further divided into a group of proportionally\n",
    "smaller penguins. Only the colors may differ, as the ordering of the labels is\n",
    "arbitrary (both for the k-means cluster and the manually assigned labels).\n",
    "\n",
    "The conclusion is that we relate the clusters found by running k-means on\n",
    "those preprocessed features to a meaningful (human) way to partition the\n",
    "penguins records. Notice however that this may not always be the case.\n",
    "\n",
    "We cannot stress enough that the choice of the features and preprocessing\n",
    "steps are crucial: if we had not standardized the numerical data, or we had\n",
    "not included the \"Sex\" feature, or if we had scaled its one-hot encoding by a\n",
    "factor of 10, we would probably not have been able to discover interpretable\n",
    "clusters.\n",
    "\n",
    "Furthermore, **many natural datasets would not satisfy the k-means\n",
    "assumptions** even after non-trivial preprocessing. We will see how to deal\n",
    "with more general cases later in this module."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}