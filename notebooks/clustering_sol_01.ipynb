{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcc3 Solution for Exercise M4.01\n",
    "\n",
    "In this exercise we investigate the stability of the k-means algorithm. For\n",
    "such purpose, we use the RFM Dataset. RFM is a method used for analyzing\n",
    "customer value and the acronym RFM stands for the three dimensions:\n",
    "\n",
    "- Recency: How recently did the customer purchase;\n",
    "- Frequency: How often do they purchase;\n",
    "- Monetary Value: How much do they spend.\n",
    "\n",
    "It is commonly used in marketing and has received particular attention in\n",
    "retail and professional services industries as well. Here we subsample the\n",
    "dataset to ease the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/rfm_segmentation.csv\")\n",
    "data = data.sample(n=2000, random_state=0).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the data using a seaborn `pairplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "_ = sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As k-means clustering relies on computing distances between samples, in\n",
    "general we need to scale our data before training the clustering model.\n",
    "\n",
    "Modify the color of the `pairplot` to represent the cluster labels as\n",
    "predicted by `KMeans` without any scaling. Try different values for\n",
    "`n_clusters`, for instance, `n_clusters_values=[2, 3, 4]`. Do all features\n",
    "contribute equally to forming the clusters in their original scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters_values = [2, 3, 4]\n",
    "\n",
    "for n_clusters in n_clusters_values:\n",
    "    model = KMeans(n_clusters=n_clusters)\n",
    "    clustered_data = data.copy()\n",
    "    clustered_data[\"cluster label\"] = model.fit_predict(data)\n",
    "    grid = sns.pairplot(clustered_data, hue=\"cluster label\", palette=\"tab10\")\n",
    "    grid.figure.suptitle(f\"n_clusters={n_clusters}\", y=1.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "Without scaling \"monetary\" has a dominant impact when forming clusters,\n",
    "regardless of the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline composed by a `StandardScaler` followed by a `KMeans` step\n",
    "as the final predictor. Set the `random_state` of `KMeans` for\n",
    "reproducibility. Then, make a plot of the WCSS or inertia for `n_clusters`\n",
    "varying from 1 to 10. You can use the following helper function for such\n",
    "purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def plot_n_clusters_scores(\n",
    "    model,\n",
    "    data,\n",
    "    score_type=\"inertia\",\n",
    "    n_clusters_values=None,\n",
    "    alpha=1.0,\n",
    "    title=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots clustering scores (inertia or silhouette) for a range of n_clusters.\n",
    "\n",
    "    Parameters:\n",
    "        model: A pipeline whose last step has a `n_clusters` hyperparameter.\n",
    "        data: The input data to cluster.\n",
    "        score_type: \"inertia\" or \"silhouette\" to decide which score to compute.\n",
    "        alpha: Transparency of the plot line, useful when several plots overlap.\n",
    "        title: Optional title to set; default title used if None.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if n_clusters_values is None:\n",
    "        if score_type == \"inertia\":\n",
    "            n_clusters_values = range(1, 11)\n",
    "        else:\n",
    "            n_clusters_values = range(2, 11)\n",
    "\n",
    "    for n_clusters in n_clusters_values:\n",
    "        model[-1].set_params(n_clusters=n_clusters)\n",
    "        if score_type == \"inertia\":\n",
    "            ylabel = \"WCSS (inertia)\"\n",
    "            model.fit(data)\n",
    "            scores.append(model[-1].inertia_)\n",
    "        elif score_type == \"silhouette\":\n",
    "            ylabel = \"Silhouette score\"\n",
    "            cluster_labels = model.fit_predict(data)\n",
    "            data_transformed = model[:-1].transform(data)\n",
    "            score = silhouette_score(data_transformed, cluster_labels)\n",
    "            scores.append(score)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"score_type must be either 'inertia' or 'silhouette'\"\n",
    "            )\n",
    "\n",
    "    plt.plot(n_clusters_values, scores, color=\"tab:blue\", alpha=alpha)\n",
    "    plt.xlabel(\"Number of clusters (n_clusters)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    _ = plt.title(title or f\"{ylabel} for varying n_clusters\", y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = make_pipeline(StandardScaler(), KMeans())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "plot_n_clusters_scores(model, data, score_type=\"inertia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "The WCSS plot may or may not present a well-defined elbow, depending of the\n",
    "random initialization of the centroids in k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can find one or more stable candidates for `n_clusters` using\n",
    "the elbow method when resampling the dataset. For such purpose:\n",
    "- Generate randomly resampled data consisting of 50% of the data by using\n",
    "  `train_test_split` with `train_size=0.5`. Changing the `random_state` to do\n",
    "  the split leads to different samples.\n",
    "- Use the `plot_n_clusters_scores` function inside a `for` loop to make\n",
    "  multiple overlapping plots of the inertia, each time using a different\n",
    "  resampling. 10 resampling iterations should be enough to draw conclusions.\n",
    "- You can choose to set the `random_state` value of the `KMeans` step, but be\n",
    "  aware that even if we fix `random_state=0` in all resampling iterations,\n",
    "  k-means will still choose different initial centroids for different data\n",
    "  samples, so fixing it or not should not change the conclusions w.r.t. to\n",
    "  stability to resampling.\n",
    "\n",
    "Is the elbow (optimal number of clusters) stable when resampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for random_state in range(1, 11):\n",
    "    data_subsample, _ = train_test_split(\n",
    "        data, train_size=0.5, random_state=random_state\n",
    "    )\n",
    "    plot_n_clusters_scores(\n",
    "        model,\n",
    "        data_subsample,\n",
    "        score_type=\"inertia\",\n",
    "        alpha=0.2,\n",
    "        title=\"Stability of inertia across resamplings\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The inertia changes drastically as a function of the subsamples, it is then\n",
    "not possible to systematically define an optimal number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `KMeans` uses a smart selection of the initial centroids called\n",
    "\"k-means++\". Instead of picking points completely at random, it tries several\n",
    "candidate centroids at each step and picks the best ones based on an\n",
    "estimation of how much they would help reduce the overall inertia. This method\n",
    "improves the chances of finding better cluster centroids and speeds up\n",
    "convergence compared to random initialization.\n",
    "\n",
    "Because \"k-means++\" already does a good job of finding suitable centroids, a\n",
    "single initialization is typically sufficient for most cases. That is why the\n",
    "parameter `n_init` in scikit-learn (which controls the number of times the\n",
    "algorithm is run with different centroid initializations) is set to 1 by\n",
    "default when `init=\"k-means++\"`. Nevertheless, there may be cases (as when\n",
    "data is unevenly distributed) where increasing `n_init` may help ensuring a\n",
    "global minimal inertia.\n",
    "\n",
    "Repeat the previous example but setting `n_init=5`. Remember to fix the\n",
    "`random_state` for the `KMeans` initialization to only estimate the\n",
    "variability related to the resampling of the data. Are the resulting inertia\n",
    "curves more stable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "model = make_pipeline(StandardScaler(), KMeans(n_init=5, random_state=0))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "for random_state in range(1, 11):\n",
    "    data_subsample, _ = train_test_split(\n",
    "        data, train_size=0.5, random_state=random_state\n",
    "    )\n",
    "    plot_n_clusters_scores(\n",
    "        model,\n",
    "        data_subsample,\n",
    "        score_type=\"inertia\",\n",
    "        alpha=0.2,\n",
    "        title=\"Stability of inertia with\\nn_init=5 and StandardScaler\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The inertia is now stable, but an elbow is not clearly defined and then it is\n",
    "not possible to define an optimal number of clusters from this heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment, but this time determine if the optimal number of\n",
    "clusters (with `StandarScaler` and `n_init=5`) is stable across subsamplings\n",
    "in terms of the `silhouette_score`. Be aware that computing the silhouette\n",
    "score is more computationally costly than computing the inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "for random_state in range(1, 11):\n",
    "    data_subsample, _ = train_test_split(\n",
    "        data, train_size=0.5, random_state=random_state\n",
    "    )\n",
    "    plot_n_clusters_scores(\n",
    "        model,\n",
    "        data_subsample,\n",
    "        score_type=\"silhouette\",\n",
    "        alpha=0.2,\n",
    "        title=(\n",
    "            \"Stability of silhouette score\\nwith n_init=5 and StandardScaler\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The silhouette score also varies as a function of the resampling, even after\n",
    "setting `n_init=5`. It may seem that the optimal number of clusters is\n",
    "sometimes 2, 4, 5 or 6 depending on the sampling. We can conclude that in this\n",
    "case, what makes challenging to find the optimal number of clusters is not\n",
    "related to the metric, but possibly to the data itself, or to the modeling\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once again repeat the experiment to determine the stability of the optimal\n",
    "number of clusters. This time, instead of using a `StandardScaler`, use a\n",
    "`QuantileTransformer` with default parameters as the preprocessing step in\n",
    "the pipeline. Contrary to `StandardScaler`, `QuantileTransformer` is a\n",
    "nonlinear transformation that maps the features with a long tail\n",
    "distributions to a uniform distribution, which is the case for the\n",
    "\"frequency\" and \"monetary\" features in the RFM dataset.\n",
    "\n",
    "For the `KMeans` step, keep `n_init=5`.\n",
    "\n",
    "What happens in terms of silhouette score? Does this make it possible to\n",
    "identify stable and qualitatively interesting clusters in this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "model = make_pipeline(QuantileTransformer(), KMeans(n_init=5, random_state=0))\n",
    "for random_state in range(1, 11):\n",
    "    data_subsample, _ = train_test_split(\n",
    "        data, train_size=0.5, random_state=random_state\n",
    "    )\n",
    "    plot_n_clusters_scores(\n",
    "        model,\n",
    "        data_subsample,\n",
    "        score_type=\"silhouette\",\n",
    "        alpha=0.2,\n",
    "        title=(\n",
    "            \"Stability of silhouette score\\nwith n_init=5 and\"\n",
    "            \" QuantileTransformer\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "The silhouette score is a bit more stable under resampling. Moreover, the\n",
    "optimal number of clusters seems to be 2, as it provides the highest score.\n",
    "However 4 or 6 clusters may still make sense if the clustering has specific\n",
    "use cases or domain relevance.\n",
    "\n",
    "Notice that you should still be cautious as the relatively low values of the\n",
    "silhouette scores suggest that clusters are not well separated or not dense\n",
    "enough. To verify this, we can plot the labels when setting `n_clusters=6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "n_clusters = 6\n",
    "model = make_pipeline(\n",
    "    QuantileTransformer(),\n",
    "    KMeans(n_init=5, n_clusters=n_clusters, random_state=0),\n",
    ").set_output(transform=\"pandas\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cluster_labels = model.fit_predict(data)\n",
    "\n",
    "_ = sns.pairplot(\n",
    "    model[:-1].transform(data).assign(cluster_labels=cluster_labels),\n",
    "    hue=\"cluster_labels\",\n",
    "    palette=\"tab10\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "Since we have 3 dimensions, we can try to visualize the cluster labels using\n",
    "a 3D projection directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={\"projection\": \"3d\"})\n",
    "ax.view_init(azim=80)\n",
    "\n",
    "cmap = ListedColormap(plt.get_cmap(\"tab10\").colors[:n_clusters])\n",
    "scatter = ax.scatter(\n",
    "    *model[:-1].transform(data).values.T,\n",
    "    c=cluster_labels,\n",
    "    cmap=cmap,\n",
    "    s=50,\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.set_box_aspect(None, zoom=0.84)\n",
    "ax.set_xlabel(f\"Transformed {data.columns[0]}\", labelpad=15)\n",
    "ax.set_ylabel(f\"Transformed {data.columns[1]}\", labelpad=15)\n",
    "ax.set_zlabel(f\"Transformed {data.columns[2]}\", labelpad=15)\n",
    "ax.set_title(\"Clusters in quantile-transformed space\", y=0.99)\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "The general impression from this study is that k-means fails to find\n",
    "well-separated clusters in this dataset regardless of the preprocessing\n",
    "method used.\n",
    "\n",
    "We can observe that the quantile-transformed data has a structure of layered\n",
    "planes because of the discrete integer levels for the lowest values of the\n",
    "\"Frequency\" feature which are overrepresented in the dataset.\n",
    "\n",
    "One could try more advanced kinds of preprocessing, or even, clustering\n",
    "algorithms that favor different kinds of shapes, however, by looking at the\n",
    "pairplot above we can draw the following conclusions:\n",
    "- The discrete layers visible for the lowest values of the \"frequency\"\n",
    "  feature are not that interesting to treat as clusters by themselves because\n",
    "  they do not relate to visible structure involving the other two features;\n",
    "- If we ignore the \"frequency\" feature, we can observe no significant cluster\n",
    "  structure in the \"recency\" and \"monetary\" 2D space.\n",
    "\n",
    "In conclusion, the data does not have a clear cluster structure, and this\n",
    "explains why we could not find strong and stable values for the silhouette\n",
    "score under resampling."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}