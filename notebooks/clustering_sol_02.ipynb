{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcc3 Solution for Exercise M4.02\n",
    "\n",
    "In a previous notebook we introduced the use of performance metrics to\n",
    "evaluate a clustering model when we have access to labeled data, namely the\n",
    "V-measure and Adjusted Rand Index (ARI). In this exercise you will get\n",
    "familiar with another supervised metric for clustering, known as Adjusted\n",
    "Mutual Information (AMI).\n",
    "\n",
    "To illustrate the different concepts, we retain some of the features from the\n",
    "penguins dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Flipper Length (mm)\",\n",
    "    \"Body Mass (g)\",\n",
    "    \"Sex\",\n",
    "    \"Species\",\n",
    "]\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")[columns_to_keep].dropna()\n",
    "species = penguins[\"Species\"].str.split(\" \").str[0]\n",
    "penguins = penguins.drop(columns=[\"Species\"])\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that the silhouette score presented a maximum when `n_clusters=6`\n",
    "when using all of the features above (not the species). Our hypothesis was\n",
    "that those clusters correspond to the 3 species of penguins present in the\n",
    "dataset (Adelie, Chinstrap, and Gentoo) further splitted by Sex (2 clusters\n",
    "for each species).\n",
    "\n",
    "Repeat the same pipeline consisting of a `OneHotEncoder` with\n",
    "`drop=\"if_binary\"` for the \"Sex\" column, a `StandardScaler` for the other\n",
    "columns. The final estimator should be `KMeans` with `n_clusters=6`. You can\n",
    "set the `random_state` for reproducibility, but that should not change the\n",
    "interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(drop=\"if_binary\"),\n",
    "        make_column_selector(dtype_exclude=\"number\"),\n",
    "    ),\n",
    "    (\n",
    "        StandardScaler(),\n",
    "        make_column_selector(dtype_include=\"number\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    KMeans(n_clusters=6, random_state=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make two `sns.scatterplot` of \"Culmen Length (mm)\" versus \"Flipper Length\n",
    "(mm)\", side-by-side. On one of them, the `hue` should be the \"species and sex\"\n",
    "coming from the known information in the dataset, and the `hue` in the other\n",
    "should be the cluster labels.\n",
    "\n",
    "Only the colors may differ, as the ordering of the labels is arbitrary (both\n",
    "for the k-means cluster and the \"true\" labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "species_and_sex_labels = species + \" \" + penguins[\"Sex\"]\n",
    "cluster_labels = model.fit_predict(penguins)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(14, 7))\n",
    "sns.scatterplot(\n",
    "    penguins.assign(species_and_sex=species_and_sex_labels),\n",
    "    hue=\"species_and_sex\",\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Flipper Length (mm)\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    "    ax=ax1,\n",
    "    legend=None,\n",
    ")\n",
    "ax1.set_title(\"Species and sex\")\n",
    "sns.scatterplot(\n",
    "    penguins.assign(kmeans_labels=cluster_labels),\n",
    "    hue=\"kmeans_labels\",\n",
    "    x=\"Culmen Length (mm)\",\n",
    "    y=\"Flipper Length (mm)\",\n",
    "    palette=\"deep\",\n",
    "    alpha=0.7,\n",
    "    ax=ax2,\n",
    "    legend=None,\n",
    ")\n",
    "_ = ax2.set_title(\"K-means labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a visual intuition of the agreement between the clusters found by\n",
    "k-means and the combination of the \"Species\" and \"Sex\" labels. We can further\n",
    "quantify it using the Adjusted Mutual Information (AMI) score.\n",
    "\n",
    "Use\n",
    "[`sklearn.metrics.adjusted_mutual_info_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html)\n",
    "to compare both sets of labels. The AMI returns a value of 1 when the two\n",
    "partitions are identical (ie perfectly matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "ami = adjusted_mutual_info_score(\n",
    "    species_and_sex_labels,\n",
    "    cluster_labels,\n",
    ")\n",
    "print(f\"Adjusted Mutual Information (AMI): {ami:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "This value is very close to 1.0, which indicates a very strong agreement.\n",
    "This confirms our visual intuition that the 6 clusters found by k-means\n",
    "nearly exactly correspond to the species crossed with the sex of the\n",
    "penguins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a\n",
    "[`sklearn.preprocessing.LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "to `fit_transform` the \"true\" labels (coming from combinations of species and\n",
    "sex). What would be the accuracy if we tried to use it to measure the\n",
    "agreement between both sets of labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true_labels = LabelEncoder().fit_transform(species_and_sex_labels)\n",
    "\n",
    "cluster_labels = model.fit_predict(penguins)\n",
    "acc = accuracy_score(true_labels, cluster_labels)\n",
    "print(f\"Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "The accuracy is misleadingly low. It is not a valid metric for clustering\n",
    "unless you map labels explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permute the cluster labels using `np.random.permutation`, then compute both\n",
    "the AMI and the accuracy when comparing the true and permuted labels. Are they\n",
    "sensitive to relabeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "unique_labels = np.unique(cluster_labels)\n",
    "permutation = rng.permutation(unique_labels)\n",
    "permuted_labels = np.zeros_like(cluster_labels)\n",
    "\n",
    "for original, new in zip(unique_labels, permutation):\n",
    "    permuted_labels[cluster_labels == original] = new\n",
    "\n",
    "permuted_ami = adjusted_mutual_info_score(true_labels, permuted_labels)\n",
    "permuted_acc = accuracy_score(true_labels, permuted_labels)\n",
    "\n",
    "print(f\"AMI (permuted): {permuted_ami:.3f}\")\n",
    "print(f\"Accuracy (permuted): {permuted_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "AMI stays the same because the cluster structure has not changed, only the\n",
    "labels' names: AMI is invariant to a random permutation of the labels.\n",
    "\n",
    "The accuracy changes because it is only meaningful when the ordering of the\n",
    "clustering labels have been mapped correctly to ordering the human labels\n",
    "which has very little chance of happening when randomly permuting the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMI is designed to return a value near zero (it can be negative) when the\n",
    "clustering is no better than random.\n",
    "\n",
    "To understand how AMI corrects for chance, compare the true labels with a\n",
    "completely random labeling using `np.random.randint` to generate as many\n",
    "labels as rows in the dataset, each containing a value between 0 and 5 (to\n",
    "match the number of clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "for _ in range(10):\n",
    "    random_labels = rng.randint(0, len(unique_labels), size=len(species))\n",
    "    ami_random = adjusted_mutual_info_score(true_labels, random_labels)\n",
    "    print(f\"AMI (random labels): {ami_random:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "We observe either positive or negative values but always very close to zero\n",
    "depending the particular random labels generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can conclude by comparing AMI to other metrics:\n",
    "\n",
    "- Adjusted Rand Index (ARI): Also corrects for chance, but it counts pairs of\n",
    "  points, in other words, how many pairs that are together in the true labels\n",
    "  are also together in the clusters. It is combinatorial, not based on\n",
    "  information-theory as AMI.\n",
    "- V-measure: Based on homogeneity (do clusters contain mostly one class?) and\n",
    "  completeness (are all members of a class grouped together?), but it does not\n",
    "  correct for chance. If you run a random clustering, V-measure might still\n",
    "  give a misleadingly non-zero score, unlike AMI or ARI."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}