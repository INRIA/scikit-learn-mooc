{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering performance metrics in the presence of labels\n",
    "\n",
    "In this notebook we briefly introduce how to deal with text data. Then we\n",
    "introduce the use of performance metrics to evaluate a clustering model when\n",
    "we have access to labeled data. Our goal is to evaluate whether the cluster\n",
    "structure favored by k-means on the preprocessed text aligns with the\n",
    "editorial categories assigned by BBC News editors.\n",
    "\n",
    "## Feature engineering for text data\n",
    "\n",
    "Previously, we saw how categorical features can be converted into numbers\n",
    "using techniques like one-hot encoding, where each category is assigned a\n",
    "unique position in a vector. We can apply a similar idea to text: treat each\n",
    "unique word as a feature (a column), and represent each document as a vector\n",
    "(a row) indicating the word counts in it. This encoding process is known as\n",
    "\"vectorization\". Here is a quick example using `CountVectorizer` to turn a few\n",
    "short phrases into a numerical table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\n",
    "    \"This is a simple phrase\",\n",
    "    \"This phrase is shorter\",\n",
    "    \"The previous phrase is shorter than the first phrase\",\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(docs)\n",
    "\n",
    "pd.DataFrame(\n",
    "    X_vectorized.toarray(), columns=vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe in particular that the words \"the\" and \"phrase\" are counted twice in\n",
    "the last document (the third row in the dataframe). This preprocessor creates\n",
    "as many features as unique words occurring in the data, therefore the\n",
    "dimension of the feature space can become very large.\n",
    "\n",
    "Readers interested can visit the [scikit-learn example on comparing\n",
    "vectorization\n",
    "strategies](https://scikit-learn.org/stable/auto_examples/text/plot_hashing_vs_dict_vectorizer.html)\n",
    "for more information.\n",
    "\n",
    "Now let us use the BBC News dataset to show how text documents can be cluster\n",
    "by topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/bbc_news.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 1,250 samples divided into 5 different categories:\n",
    "\"business\", \"entertainment\", \"sport\", \"politics\" and \"tech\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by preprocessing the text data using `StringEncoder`, that encodes\n",
    "text similarly to `CountVectorizer` and then reduces the dimension of the\n",
    "feature space while trying to preserve the relative distance between pairs of\n",
    "documents.\n",
    "\n",
    "This encoder is well suited to cluster text using `KMeans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import StringEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StringEncoder(), KMeans(n_clusters=3, random_state=0))\n",
    "cluster_labels = model.fit_predict(data[\"text\"])\n",
    "pd.Series(cluster_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline has grouped the documents into 3 clusters, even though the\n",
    "dataset contains 5 categories assigned by BBC editors. We chose this on\n",
    "purpose, to show that k-means always produces a number of clusters that\n",
    "matches the `n_clusters` parameter, regardless of what's in the data.\n",
    "\n",
    "## Supervised metrics for clustering evaluation\n",
    "\n",
    "Even though clustering is an unsupervised learning method, we have access to\n",
    "labels for the categories that were assigned by the BBC editors, allowing us\n",
    "to evaluate how well the cluster labels found by k-means match those human\n",
    "assigned labels.\n",
    "\n",
    "We could try to use classification metrics such as the accuracy. However, the\n",
    "integer identifiers of the clustering labels are arbitrarily ordered and\n",
    "`n_clusters` does not need to match the number of predefined categories (as\n",
    "we just did in the code above). More importantly, we don't assume a\n",
    "predefined mapping between cluster labels and editorial categories, and we\n",
    "don't need one to quantify their agreement. This is where supervised\n",
    "clustering metrics come in.\n",
    "\n",
    "In this notebook, we'll use two metrics: V-measure and Adjusted Rand Index\n",
    "(ARI). The V-measure quantifies alignment of the clustering assignment with\n",
    "the BBC category assignment used as reference by evaluating two properties:\n",
    "- homogeneity: each cluster contains only members of a single category;\n",
    "- completeness: all members of a given category are assigned to the same\n",
    "  cluster.\n",
    "\n",
    "V-measure ranges from 0 to 1, where 1 indicates perfect match between the\n",
    "clustering labels and the reference labels, both in terms of homogeneity and\n",
    "completeness.\n",
    "\n",
    "The Adjusted Rand Index (ARI) also measures the similarity between the\n",
    "predicted clusters and editor-assigned labels: it compares pairs of articles\n",
    "to see whether if they are in the same cluster in both the predicted and\n",
    "editor-assigned labels. High ARI means that articles from the same category\n",
    "are grouped together, and articles from different categories are separated.\n",
    "ARI ranges from -1 (worse than random clustering) to 1 (perfect clustering),\n",
    "with 0 indicating a model that assigns cluster labels at random: this metric\n",
    "is therefore \"adjusted for chance\", which is not the case for V-measure.\n",
    "Both V-measure and ARI follow a \"higher is better\" convention.\n",
    "\n",
    "Read more in the User Guide for\n",
    "[V-measure](https://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure)\n",
    "and the [Rand\n",
    "index](https://scikit-learn.org/stable/modules/clustering.html#rand-index).\n",
    "\n",
    "Let's use these metrics to evaluate the clustering labels found by k-means\n",
    "with different values of `n_clusters` by plotting the validation curves\n",
    "for both of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ValidationCurveDisplay\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, train_size=0.75, random_state=0)\n",
    "data_encoded = StringEncoder().fit_transform(data[\"text\"])\n",
    "n_clusters_values = range(2, 11)\n",
    "scoring_names = {\n",
    "    \"V-measure\": \"v_measure_score\",\n",
    "    \"ARI\": \"adjusted_rand_score\",\n",
    "}\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, figsize=(6, 8), sharex=True, constrained_layout=True\n",
    ")\n",
    "for (scoring_name, scoring), ax in zip(scoring_names.items(), axes):\n",
    "    ValidationCurveDisplay.from_estimator(\n",
    "        KMeans(n_init=5, random_state=0),\n",
    "        data_encoded,\n",
    "        data[\"category\"],\n",
    "        param_name=\"n_clusters\",\n",
    "        param_range=n_clusters_values,\n",
    "        scoring=scoring,\n",
    "        std_display_style=\"errorbar\",\n",
    "        cv=cv,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=(-0.1, 1.1),\n",
    "        xlabel=None,\n",
    "        ylabel=scoring_name,\n",
    "    )\n",
    "ax.set_xlabel(\"Number of clusters (n_clusters)\")\n",
    "_ = plt.suptitle(\n",
    "    \"Supervised evaluation of clusters\\nfor varying n_clusters\", y=1.08\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that both V-measure and ARI are much better than chance. Even more\n",
    "they reach their maximum value when `n_clusters=5`. This is not surprising\n",
    "because this is the number of human-assigned categories in the dataset and\n",
    "both metrics quantify alignment with those labels.\n",
    "\n",
    "The relatively good metrics values observed for `n_clusters=5` reflects both\n",
    "good editorial labels (as the categories are well-defined and internally\n",
    "consistent) as well as a clustering pipeline that can reasonably extract the\n",
    "structure in the data that matches the human intuition.\n",
    "\n",
    "Note that the metrics measured on training or validation data are very\n",
    "similar, meaning that k-means with small number of clusters is unlikely to\n",
    "overfit noise from the training data.\n",
    "\n",
    "But the question may arise, if we didn't have access to labels at all, would\n",
    "the silhouette score also lead us to chose `n_clusters=5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_clusters_values = list(range(2, 11)) + [20, 30, 40, 50, 60, 70]\n",
    "all_scores = []\n",
    "for random_state in range(1, 11):\n",
    "    data_train, data_test = train_test_split(\n",
    "        data_encoded, train_size=0.5, random_state=random_state\n",
    "    )\n",
    "    scores = []\n",
    "    for n_clusters in n_clusters_values:\n",
    "        model = KMeans(n_clusters=n_clusters, n_init=5, random_state=0)\n",
    "        cluster_labels = model.fit(data_train).predict(data_test)\n",
    "        score = silhouette_score(data_test, cluster_labels)\n",
    "        scores.append(score)\n",
    "\n",
    "    all_scores.append(scores)\n",
    "    plt.plot(n_clusters_values, scores, color=\"tab:blue\", alpha=0.2)\n",
    "    plt.xlabel(\"Number of clusters (n_clusters)\")\n",
    "    plt.ylabel(\"Silhouette score\")\n",
    "\n",
    "all_scores = np.array(all_scores)\n",
    "plt.plot(\n",
    "    n_clusters_values,\n",
    "    all_scores.mean(axis=0),\n",
    "    color=\"black\",\n",
    "    alpha=1,\n",
    "    label=\"Mean silhouette score\",\n",
    ")\n",
    "plt.legend()\n",
    "_ = plt.title(\"Silhouette score for varying n_clusters\", y=1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The silhouette score analysis favors larger values for `n_clusters` (between\n",
    "20 and 40) than the 5 categories chosen by the BBC editors.\n",
    "\n",
    "The finer-grained clusters found by k-means for `n_clusters=30` could\n",
    "potentially match sub-clusters of the 5 BBC categories. However, categorizing\n",
    "news articles in too fine-grained topics would make the navigation on their\n",
    "website too confusing. Therefore for this application, it can be meaningful\n",
    "to select a number of clusters that is smaller than the number of clusters\n",
    "that maximizes the silhouette score.\n",
    "\n",
    "We can also, observe that the silhouette curves are not very stable under\n",
    "resampling and that the maximum silhouette score is not very high, which\n",
    "indicates that the clusters are not very well separated from each other: this\n",
    "could be explained by the fact that some documents could meaningfully belong\n",
    "to more than one topical category: for instance, a news article about a tech\n",
    "company being acquired by another could belong to both \"tech\" and \"business\"\n",
    "categories.\n",
    "\n",
    "Finally, notice that we used supervised information to quantitatively assess\n",
    "the quality of the match between the clusters found by k-means and our\n",
    "categorization. In practice, this is often impossible, as we do not have\n",
    "access to human assigned labels for each row in the data. Or, if we have, we\n",
    "might want to use them as the target variable to train a supervised\n",
    "classifier instead of training an unsupervised clustering model."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}