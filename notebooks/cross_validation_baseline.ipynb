{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing results with baseline and chance level\n",
    "\n",
    "In this notebook, we present how to compare the generalization performance of a\n",
    "model to a minimal baseline.\n",
    "\n",
    "Indeed, in the previous notebook, we compared the testing error by\n",
    "taking into account the target distribution. A good practice is to compare\n",
    "the testing error with a dummy baseline and the chance level. In\n",
    "regression, we could use the `DummyRegressor` and predict the mean target\n",
    "without using the data. The chance level can be determined by permuting the\n",
    "labels and check the difference of result.\n",
    "\n",
    "Therefore, we will conduct experiment to get the score of a model and the two\n",
    "baselines. We will start by loading the California housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all evaluations, we will use a `ShuffleSplit` cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by running the cross-validation for the decision tree\n",
    "regressor which is our model of interest. Besides, we will store the\n",
    "testing error in a pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "result_regressor = cross_validate(regressor, data, target,\n",
    "                                  cv=cv, scoring=\"neg_mean_absolute_error\",\n",
    "                                  n_jobs=2)\n",
    "\n",
    "errors_regressor = pd.Series(-result_regressor[\"test_score\"],\n",
    "                             name=\"Regressor error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will evaluate our first baseline. This baseline is called a dummy\n",
    "regressor. This dummy regressor will always predict the mean target computed\n",
    "on the training. Therefore, the dummy regressor will never use any\n",
    "information regarding the data `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = DummyRegressor()\n",
    "result_dummy = cross_validate(dummy, data, target,\n",
    "                              cv=cv, scoring=\"neg_mean_absolute_error\",\n",
    "                              n_jobs=2)\n",
    "errors_dummy = pd.Series(-result_dummy[\"test_score\"], name=\"Dummy error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will evaluate the generalization performance of the second baseline.\n",
    "This baseline will provide the generalization performance of the chance level.\n",
    "Indeed, we will train a decision tree on some training data and evaluate the\n",
    "same tree on data where the target vector has been randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "score, permutation_score, pvalue = permutation_test_score(\n",
    "    regressor, data, target, cv=cv, scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2, n_permutations=30)\n",
    "errors_permutation = pd.Series(-permutation_score, name=\"Permuted error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the testing errors for the two baselines and the\n",
    "actual regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_errors = pd.concat([errors_regressor, errors_dummy, errors_permutation],\n",
    "                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_errors.plot.hist(bins=50, density=True, edgecolor=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.xlabel(\"Mean absolute error (k$)\")\n",
    "_ = plt.title(\"Distribution of the testing errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even if the generalization performance of our model is far from\n",
    "being good, it is better than the two baselines. Besides, we see that the\n",
    "dummy regressor is better than a chance level regressor.\n",
    "\n",
    "In practice, using a dummy regressor might be sufficient as a baseline.\n",
    "Indeed, to obtain a reliable estimate the permutation of the target should\n",
    "be repeated and thus this method is costly. However, it gives the true\n",
    "chance level."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}