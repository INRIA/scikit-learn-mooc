{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ƒ Solution fo Exercise 01\n",
    "\n",
    "The aim of this exercise is to make the following experiments:\n",
    "\n",
    "* train and test a support vector machine classifier through\n",
    "  cross-validation;\n",
    "* study the effect of the parameter gamma of this classifier using a\n",
    "  validation curve;\n",
    "* study if it would be useful in term of classification if we could add new\n",
    "  samples in the dataset using a learning curve.\n",
    "\n",
    "To make these experiments we will first load the blood transfusion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/blood_transfusion.csv\")\n",
    "X, y = data.drop(columns=\"Class\"), data[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a machine learning pipeline which will standardize the data and then\n",
    "use a support vector machine with an RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the previous model by cross-validation with a\n",
    "`ShuffleSplit` scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(random_state=0)\n",
    "cv_results = cross_validate(model, X, y, cv=cv, n_jobs=-1)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Accuracy score of our model:\\n\"\n",
    "    f\"{cv_results['test_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter gamma is one of the parameter controlling under-/over-fitting\n",
    "in support vector machine with an RBF kernel. Compute the validation curve\n",
    "to evaluate the effect of the parameter gamma. You can make vary the value\n",
    "of the parameter gamma between `10e-3` and `10e2` by generating samples on\n",
    "log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "gammas = np.logspace(-3, 2, num=30)\n",
    "param_name = \"svc__gamma\"\n",
    "train_scores, test_scores = validation_curve(\n",
    "    model, X, y, param_name=param_name, param_range=gammas, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the validation curve for the train and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "for name, scores in zip(\n",
    "    [\"Empirical score\", \"Generalization score\"], [train_scores, test_scores]\n",
    "):\n",
    "    ax.plot(\n",
    "        gammas, scores.mean(axis=1), linestyle=\"-.\", label=name,\n",
    "        alpha=0.8)\n",
    "    ax.fill_between(\n",
    "        gammas, scores.mean(axis=1) - scores.std(axis=1),\n",
    "        scores.mean(axis=1) + scores.std(axis=1),\n",
    "        alpha=0.5, label=f\"std. dev. {name.lower()}\")\n",
    "\n",
    "ax.set_xticks(gammas)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Value of hyperparameter $\\gamma$\")\n",
    "ax.set_ylabel(\"Accuracy score\")\n",
    "ax.set_title(\"Validation score of support vector machine\")\n",
    "_ = plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the curve, we can clearly identify the over-fitting regime of\n",
    "the SVC classifier: when `gamma > 1`. The best setting is around `gamma = 1`\n",
    "while for `gamma < 1`, it is not very clear that the classifier is\n",
    "under-fitting but the generalization score is worse than for `gamma = 1`.\n",
    "\n",
    "Now, you can make an analysis to check if adding new samples to the dataset\n",
    "could help our model to better generalize. Compute the learning curve by\n",
    "computing the train and test score for different training dataset size.\n",
    "Plot the train and test score in respect with the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1, num=10)\n",
    "results = learning_curve(\n",
    "    model, X, y, train_sizes=train_sizes, cv=cv, n_jobs=-1)\n",
    "train_size, train_scores, test_scores = results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "for name, scores in zip(\n",
    "    [\"Empirical score\", \"Generalization score\"], [train_scores, test_scores]\n",
    "):\n",
    "    ax.plot(\n",
    "        train_sizes, scores.mean(axis=1), linestyle=\"-.\", label=name,\n",
    "        alpha=0.8)\n",
    "    ax.fill_between(\n",
    "        train_sizes, scores.mean(axis=1) - scores.std(axis=1),\n",
    "        scores.mean(axis=1) + scores.std(axis=1),\n",
    "        alpha=0.5, label=f\"std. dev. {name.lower()}\")\n",
    "\n",
    "ax.set_xticks(train_sizes)\n",
    "ax.set_xlabel(\"Number of samples in the training set\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Learning curve for support vector machine\")\n",
    "_ = plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that adding new samples in the dataset does not improve the\n",
    "generalization score. We can only conclude that the standard deviation of\n",
    "the empirical error is decreasing when adding more samples which is not a\n",
    "surprise."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
