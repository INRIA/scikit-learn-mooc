{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sufficient-first",
   "metadata": {},
   "source": [
    "# Stratification\n",
    "Let's start with the concept of stratification by giving an example where\n",
    "we can get into trouble if we are not careful. Let's load the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data, target = load_iris(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-cornell",
   "metadata": {},
   "source": [
    "At this point, we create a basic machine-learning model: a logistic\n",
    "regression. We expect this model to work quite well on the iris dataset since\n",
    "this is a toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-germany",
   "metadata": {},
   "source": [
    "Once we created our model, we will use the cross-validation framework to\n",
    "evaluate it. We will use the `KFold` cross-validation strategy.\n",
    "We will define a dataset with nine samples and repeat the cross-validation\n",
    "three times (i.e. `n_splits`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data_random = np.random.randn(9, 1)\n",
    "cv = KFold(n_splits=3)\n",
    "for train_index, test_index in cv.split(data_random):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-officer",
   "metadata": {},
   "source": [
    "By defining three splits, we will use three samples for testing and six for\n",
    "training each time. `KFold` does not shuffle by default. It means that it\n",
    "will select the three first samples for the testing set at the first split,\n",
    "then the three next three samples for the second split, and the three next\n",
    "for the last split. In the end, all samples have been used in testing at\n",
    "least once among the different splits.\n",
    "\n",
    "Now, let's apply this strategy to check the statistical performance of our\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "results = cross_validate(model, data, target, cv=cv)\n",
    "test_score = results[\"test_score\"]\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} +/- {test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-quilt",
   "metadata": {},
   "source": [
    "It is a real surprise that our model cannot correctly classify any sample in\n",
    "any cross-validation split. We will now check our target's value to\n",
    "understand the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = target.plot()\n",
    "ax.set_xlabel(\"Sample index\")\n",
    "ax.set_ylabel(\"Class\")\n",
    "ax.set_yticks(target.unique())\n",
    "_ = ax.set_title(\"Class value in target y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-strength",
   "metadata": {},
   "source": [
    "We see that the target vector `target` is ordered. It will have some\n",
    "unexpected consequences when using the `KFold` cross-validation. To\n",
    "illustrate the consequences, we will show the class count in each fold of the\n",
    "cross-validation in the train and test set.\n",
    "\n",
    "For this matter, we'll create a function (as we will reuse it), which given a\n",
    "cross-validation object and the data `data` and `target`, is returning a\n",
    "dataframe with the class counts by folds and by split sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compute_class_count_cv(cv, data, target):\n",
    "    class_probability = []\n",
    "    for cv_idx, (train_index, test_index) in enumerate(cv.split(data, target)):\n",
    "        # Compute the class probability for the training set\n",
    "        train_class = Counter(target[train_index])\n",
    "        class_probability += [\n",
    "            [\"Train set\", f\"CV #{cv_idx}\", klass, proportion]\n",
    "            for klass, proportion in train_class.items()\n",
    "        ]\n",
    "        # Compute the class probability for the test set\n",
    "        test_class = Counter(target[test_index])\n",
    "        class_probability += [\n",
    "            [\"Test set\", f\"CV #{cv_idx}\", klass, proportion]\n",
    "            for klass, proportion in test_class.items()\n",
    "        ]\n",
    "\n",
    "    class_probability = pd.DataFrame(\n",
    "        class_probability, columns=[\"Set\", \"CV\", \"Class\", \"Count\"])\n",
    "    return class_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-point",
   "metadata": {},
   "source": [
    "Let's compute the statistics using the `KFold` cross-validation, and\n",
    "plot these information in a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_class_count = compute_class_count_cv(cv, data, target)\n",
    "kfold_class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(kfold_class_count, col=\"Set\")\n",
    "g.map_dataframe(\n",
    "    sns.barplot, x=\"Class\", y=\"Count\", hue=\"CV\", palette=\"tab10\")\n",
    "g.set_axis_labels(\"Class\", \"Count\")\n",
    "g.add_legend()\n",
    "_ = g.fig.suptitle(\"Class count with K-fold cross-validation\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-beatles",
   "metadata": {},
   "source": [
    "We can confirm that in each fold, only two of the three classes are present\n",
    "in the training set and all samples of the remaining class is used as a test\n",
    "set. So our model is unable to predict this class that was unseen during the\n",
    "training stage.\n",
    "\n",
    "One possibility to solve the issue is to shuffle the data before splitting\n",
    "the data into three groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "results = cross_validate(model, data, target, cv=cv)\n",
    "test_score = results[\"test_score\"]\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} +/- {test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-wheat",
   "metadata": {},
   "source": [
    "We get results that are closer to what we would expect with an accuracy above\n",
    "90%. Now that we solved our first issue, it would be interesting to check if\n",
    "the class frequency in the training and testing set is equal to our original\n",
    "set's class frequency. It would ensure that we are training and testing our\n",
    "model with a class distribution that we will encounter in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_shuffled_class_count = compute_class_count_cv(cv, data, target)\n",
    "\n",
    "g = sns.FacetGrid(kfold_shuffled_class_count, col=\"Set\")\n",
    "g.map_dataframe(\n",
    "    sns.barplot, x=\"Class\", y=\"Count\", hue=\"CV\", palette=\"tab10\")\n",
    "g.set_axis_labels(\"Class\", \"Count\")\n",
    "g.add_legend()\n",
    "_ = g.fig.suptitle(\n",
    "    \"Class count with shuffled K-fold cross-validation\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-feedback",
   "metadata": {},
   "source": [
    "We see that neither the training and testing sets have the same class\n",
    "frequencies as our original dataset because the count for each class is\n",
    "varying a little.\n",
    "\n",
    "However, one might want to split our data by preserving the original class\n",
    "frequencies: we want to **stratify** our data by class. In scikit-learn, some\n",
    "cross-validation strategies implement the stratification; they contain\n",
    "`Stratified` in their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(model, data, target, cv=cv)\n",
    "test_score = results[\"test_score\"]\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} +/- {test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold_class_count = compute_class_count_cv(cv, data, target)\n",
    "\n",
    "g = sns.FacetGrid(stratified_kfold_class_count, col=\"Set\")\n",
    "g.map_dataframe(\n",
    "    sns.barplot, x=\"Class\", y=\"Count\", hue=\"CV\", palette=\"tab10\")\n",
    "g.set_axis_labels(\"Class\", \"Count\")\n",
    "g.add_legend()\n",
    "_ = g.fig.suptitle(\n",
    "    \"Class count with stratifiedK-fold cross-validation\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-preparation",
   "metadata": {},
   "source": [
    "In this case, we observe that the class counts are very close both in the\n",
    "train set and the test set. The difference is due to the small number of\n",
    "samples in the iris dataset.\n",
    "\n",
    "In conclusion, this is a good practice to use stratification within the\n",
    "cross-validation framework when dealing with a classification problem."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
