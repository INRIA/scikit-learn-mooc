{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non i.i.d. data\n",
    "\n",
    "In machine learning, it is quite common to assume that the data are i.i.d,\n",
    "meaning that the generative process does not have any memory of past samples\n",
    "to generate new samples.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">i.i.d is the acronym of \"independent and identically distributed\"\n",
    "(as in \"independent and identically distributed random variables\").</p>\n",
    "</div>\n",
    "\n",
    "This assumption is usually violated when dealing with time series. A sample\n",
    "depends on past information.\n",
    "\n",
    "We will take an example to highlight such issues with non-i.i.d. data in the\n",
    "previous cross-validation strategies presented. We are going to load\n",
    "financial quotations from some energy companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "symbols = {\"TOT\": \"Total\", \"XOM\": \"Exxon\", \"CVX\": \"Chevron\",\n",
    "           \"COP\": \"ConocoPhillips\", \"VLO\": \"Valero Energy\"}\n",
    "template_name = (\"../datasets/financial-data/{}.csv\")\n",
    "\n",
    "quotes = {}\n",
    "for symbol in symbols:\n",
    "    data = pd.read_csv(\n",
    "        template_name.format(symbol), index_col=0, parse_dates=True\n",
    "    )\n",
    "    quotes[symbols[symbol]] = data[\"open\"]\n",
    "quotes = pd.DataFrame(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by plotting the different financial quotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "quotes.plot()\n",
    "plt.ylabel(\"Quote value\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "_ = plt.title(\"Stock values over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the experiment asked during the exercise. Instead of using\n",
    "random data, we will use real quotations this time. While it was obvious that\n",
    "a predictive model could not work in practice on random data, this is the\n",
    "same on these real data. So here, we want to predict the quotation of Chevron\n",
    "using all other energy companies' quotes.\n",
    "\n",
    "To make explanatory plots, we will use a single split in addition to the\n",
    "cross-validation that you used in the introductory exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = quotes.drop(columns=[\"Chevron\"]), quotes[\"Chevron\"]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a decision tree regressor that we expect to overfit and thus not\n",
    "generalize to unseen data. We will use a `ShuffleSplit` cross-validation to\n",
    "check the generalization performance of our model.\n",
    "\n",
    "Let's first define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the cross-validation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_score = cross_val_score(regressor, data_train, target_train, cv=cv,\n",
    "                             n_jobs=2)\n",
    "print(f\"The mean R2 is: \"\n",
    "      f\"{test_score.mean():.2f} +/- {test_score.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, we get outstanding generalization performance. We will investigate\n",
    "and find the reason for such good results with a model that is expected to\n",
    "fail. We previously mentioned that `ShuffleSplit` is an iterative\n",
    "cross-validation scheme that shuffles data and split. We will simplify this\n",
    "procedure with a single split and plot the prediction. We can use\n",
    "`train_test_split` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(data_train, target_train)\n",
    "target_predicted = regressor.predict(data_test)\n",
    "# Affect the index of `target_predicted` to ease the plotting\n",
    "target_predicted = pd.Series(target_predicted, index=target_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the generalization performance of our model on this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "test_score = r2_score(target_test, target_predicted)\n",
    "print(f\"The R2 on this single split is: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we obtain good results in terms of $R^2$.\n",
    "We will plot the training, testing and prediction samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.plot(label=\"Training\")\n",
    "target_test.plot(label=\"Testing\")\n",
    "target_predicted.plot(label=\"Prediction\")\n",
    "\n",
    "plt.ylabel(\"Quote value\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "_ = plt.title(\"Model predictions using a ShuffleSplit strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this context, it seems that the model predictions are following the\n",
    "testing. But we can also see that the testing samples are next to some\n",
    "training sample. And with these time-series, we see a relationship between a\n",
    "sample at the time `t` and a sample at `t+1`. In this case, we are violating\n",
    "the i.i.d. assumption. The insight to get is the following: a model can\n",
    "output of its training set at the time `t` for a testing sample at the time\n",
    "`t+1`. This prediction would be close to the true value even if our model\n",
    "did not learn anything, but just memorized the training dataset.\n",
    "\n",
    "An easy way to verify this hypothesis is to not shuffle the data when doing\n",
    "the split. In this case, we will use the first 75% of the data to train and\n",
    "the remaining data to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, shuffle=False, random_state=0,\n",
    ")\n",
    "regressor.fit(data_train, target_train)\n",
    "target_predicted = regressor.predict(data_test)\n",
    "target_predicted = pd.Series(target_predicted, index=target_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = r2_score(target_test, target_predicted)\n",
    "print(f\"The R2 on this single split is: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that our model is not magical anymore. Indeed, it\n",
    "performs worse than just predicting the mean of the target. We can visually\n",
    "check what we are predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.plot(label=\"Training\")\n",
    "target_test.plot(label=\"Testing\")\n",
    "target_predicted.plot(label=\"Prediction\")\n",
    "\n",
    "plt.ylabel(\"Quote value\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "_ = plt.title(\"Model predictions using a split without shuffling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model cannot predict anything because it doesn't have samples\n",
    "around the testing sample. Let's check how we could have made a proper\n",
    "cross-validation scheme to get a reasonable generalization performance estimate.\n",
    "\n",
    "One solution would be to group the samples into time blocks, e.g. by quarter,\n",
    "and predict each group's information by using information from the other\n",
    "groups. We can use the `LeaveOneGroupOut` cross-validation for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "groups = quotes.index.to_period(\"Q\")\n",
    "cv = LeaveOneGroupOut()\n",
    "test_score = cross_val_score(regressor, data, target,\n",
    "                             cv=cv, groups=groups, n_jobs=2)\n",
    "print(f\"The mean R2 is: \"\n",
    "      f\"{test_score.mean():.2f} +/- {test_score.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that we cannot make good predictions, which is less\n",
    "surprising than our original results.\n",
    "\n",
    "Another thing to consider is the actual application of our solution. If our\n",
    "model is aimed at forecasting (i.e., predicting future data from past data),\n",
    "we should not use training data that are ulterior to the testing data. In\n",
    "this case, we can use the `TimeSeriesSplit` cross-validation to enforce this\n",
    "behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=groups.nunique())\n",
    "test_score = cross_val_score(regressor, data, target,\n",
    "                             cv=cv, groups=groups, n_jobs=2)\n",
    "print(f\"The mean R2 is: \"\n",
    "      f\"{test_score.mean():.2f} +/- {test_score.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, it is really important to not use an out of the shelves\n",
    "cross-validation strategy which do not respect some assumptions such as\n",
    "having i.i.d data. It might lead to absurd results which could make think\n",
    "that a predictive model might work."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}