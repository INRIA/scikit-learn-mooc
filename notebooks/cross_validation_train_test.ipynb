{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "native-pitch",
   "metadata": {},
   "source": [
    "# The framework and why do we need it\n",
    "\n",
    "In the previous notebooks, we introduce some concepts regarding the\n",
    "evaluation of predictive models. While this section could be slightly\n",
    "redundant, we intend to go into details into the cross-validation framework.\n",
    "\n",
    "Before we dive in, let's linger on the reasons for always having training and\n",
    "testing sets. Let's first look at the limitation of using a dataset without\n",
    "keeping any samples out.\n",
    "\n",
    "To illustrate the different concepts, we will use the California housing\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "data, target = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-jones",
   "metadata": {},
   "source": [
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Here and later, we use the name <tt class=\"docutils literal\">data</tt> and <tt class=\"docutils literal\">target</tt> to be explicit. In\n",
    "scikit-learn, documentation <tt class=\"docutils literal\">data</tt> is commonly named <tt class=\"docutils literal\">X</tt> and <tt class=\"docutils literal\">target</tt> is\n",
    "commonly called <tt class=\"docutils literal\">y</tt>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-portland",
   "metadata": {},
   "source": [
    "In this dataset, the aim is to predict the median value of houses in an area\n",
    "in California. The features collected are based on general real-estate and\n",
    "geographical information.\n",
    "\n",
    "Therefore, the task to solve is different from the one shown in the previous\n",
    "notebook. The target to be predicted is a continuous variable and not anymore\n",
    "discrete. This task is called regression.\n",
    "\n",
    "Therefore, we will use predictive model specific to regression and not to\n",
    "classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-astronomy",
   "metadata": {},
   "source": [
    "To simplify future visualization, let's transform the prices from the\n",
    "dollar ($) range to the thousand dollars (k$) range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "target *= 100\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-albania",
   "metadata": {},
   "source": [
    "## Training error vs testing error\n",
    "\n",
    "To solve this regression task, we will use a decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-quick",
   "metadata": {},
   "source": [
    "After training the regressor, we would like to know its potential statistical\n",
    "performance once deployed in production. For this purpose, we use the mean\n",
    "absolute error, which gives us an error in the native unit, i.e. k\\$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "target_predicted = regressor.predict(data)\n",
    "score = mean_absolute_error(target, target_predicted)\n",
    "print(f\"On average, our regressor makes an error of {score:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-suffering",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We get perfect prediction with no error. It is too optimistic and almost\n",
    "always revealing a methodological problem when doing machine learning.\n",
    "\n",
    "Indeed, we trained and predicted on the same dataset. Since our decision tree\n",
    "was fully grown, every sample in the dataset is stored in a leaf node.\n",
    "Therefore, our decision tree fully memorized the dataset given during `fit`\n",
    "and therefore made no error when predicting.\n",
    "\n",
    "This error computed above is called the **empirical error** or **training\n",
    "error**.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">In this MOOC, we will use consistently the term \"training error\".</p>\n",
    "</div>\n",
    "\n",
    "We trained a predictive model to minimize the training error but our aim is\n",
    "to minimize the error on data that has not been seen during training.\n",
    "\n",
    "This error is also called the **generalization error** or the \"true\"\n",
    "**testing error**.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">In this MOOC, we will use consistently the term \"testing error\".</p>\n",
    "</div>\n",
    "\n",
    "Thus, the most basic evaluation involves:\n",
    "\n",
    "* splitting our dataset into two subsets: a training set and a testing set;\n",
    "* fitting the model on the training set;\n",
    "* estimating the training error on the training set;\n",
    "* estimating the testing error on the testing set.\n",
    "\n",
    "So let's split our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-banking",
   "metadata": {},
   "source": [
    "Then, let's train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-governor",
   "metadata": {},
   "source": [
    "Finally, we estimate the different types of errors. Let's start by computing\n",
    "the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = regressor.predict(data_train)\n",
    "score = mean_absolute_error(target_train, target_predicted)\n",
    "print(f\"The training error of our model is {score:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-intro",
   "metadata": {},
   "source": [
    "We observe the same phenomena as in the previous experiment: our model\n",
    "memorized the training set. However, we now compute the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = regressor.predict(data_test)\n",
    "score = mean_absolute_error(target_test, target_predicted)\n",
    "print(f\"The testing error of our model is {score:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-payday",
   "metadata": {},
   "source": [
    "This testing error is actually about what we would expect from our model if\n",
    "it was used in a production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-excellence",
   "metadata": {},
   "source": [
    "## Stability of the cross-validation estimates\n",
    "\n",
    "When doing a single train-test split we don't give any indication regarding\n",
    "the robustness of the evaluation of our predictive model: in particular, if\n",
    "the test set is small, this estimate of the testing error will be\n",
    "unstable and wouldn't reflect the \"true error rate\" we would have observed\n",
    "with the same model on an unlimited amount of test data.\n",
    "\n",
    "For instance, we could have been lucky when we did our random split of our\n",
    "limited dataset and isolated some of the easiest cases to predict in the\n",
    "testing set just by chance: the estimation of the testing error would be\n",
    "overly optimistic, in this case.\n",
    "\n",
    "**Cross-validation** allows estimating the robustness of a predictive model\n",
    "by repeating the splitting procedure. It will give several training and\n",
    "testing errors and thus some **estimate of the variability of the\n",
    "model statistical performance**.\n",
    "\n",
    "There are different cross-validation strategies, for now we are going to\n",
    "focus on one called \"shuffle-split\". At each iteration of this strategy we:\n",
    "\n",
    "- randomly shuffle the order of the samples of a copy of the full dataset;\n",
    "- split the shuffled dataset into a train and a test set;\n",
    "- train a new model on the train set;\n",
    "- evaluate the testing error on the test set.\n",
    "\n",
    "We repeat this procedure `n_splits` times. Using `n_splits=30` means that we\n",
    "will train 30 models in total and all of them will be discarded: we just\n",
    "record their statistical performance on each variant of the test set.\n",
    "\n",
    "To evaluate the statistical performance of our regressor, we can use\n",
    "`cross_validate` with a `ShuffleSplit` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.2)\n",
    "cv_results = cross_validate(\n",
    "    regressor, data, target, cv=cv, scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-classroom",
   "metadata": {},
   "source": [
    "The results `cv_results` are stored into a Python dictionary. We will convert\n",
    "it into a pandas dataframe to ease visualization and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-carpet",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">By convention, scikit-learn model evaluation tools always use a convention\n",
    "where \"higher is better\", this explains we used\n",
    "<tt class=\"docutils literal\"><span class=\"pre\">scoring=\"neg_mean_absolute_error\"</span></tt> (meaning \"negative mean absolute error\").</p>\n",
    "</div>\n",
    "\n",
    "Let us revert the negation to get the actual error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[\"test_error\"] = -cv_results[\"test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-prophet",
   "metadata": {},
   "source": [
    "Let's check the results reported by the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-france",
   "metadata": {},
   "source": [
    "We get timing information to fit and predict at each round of\n",
    "cross-validation. Also, we get the test score, which corresponds to the\n",
    "testing error on each of the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-newsletter",
   "metadata": {},
   "source": [
    "We get 30 entries in our resulting dataframe because we performed 30 splits.\n",
    "Therefore, we can show the testing error distribution and thus, have an\n",
    "estimate of its variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(cv_results[\"test_error\"], kde=True, bins=10)\n",
    "_ = plt.xlabel(\"Mean absolute error (k$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-tract",
   "metadata": {},
   "source": [
    "We observe that the testing error is clustered around 45.5 k\\$ and\n",
    "ranges from 43 k\\$ to 49 k\\$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean cross-validated testing error is: \"\n",
    "      f\"{cv_results['test_error'].mean():.2f} k$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The standard deviation of the testing error is: \"\n",
    "      f\"{cv_results['test_error'].std():.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-hughes",
   "metadata": {},
   "source": [
    "Note that the standard deviation is much smaller than the mean: we could\n",
    "summarize that our cross-validation estimate of the testing error is\n",
    "45.88 +/- 1.00 k\\$.\n",
    "\n",
    "If we were to train a single model on the full dataset (without\n",
    "cross-validation) and then had later access to an unlimited amount of test\n",
    "data, we would expect its true testing error to fall close to that\n",
    "region.\n",
    "\n",
    "While this information is interesting in itself, it should be contrasted to\n",
    "the scale of the natural variability of the vector `target` in our dataset.\n",
    "\n",
    "Let us plot the distribution of the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(target, kde=True, bins=20)\n",
    "_ = plt.xlabel(\"Median House Value (k$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The standard deviation of the target is: {target.std():.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-cannon",
   "metadata": {},
   "source": [
    "The target variable ranges from close to 0 k\\$ up to 500 k\\$ and, with a\n",
    "standard deviation around 115 k\\$.\n",
    "\n",
    "We notice that the mean estimate of the testing error obtained by\n",
    "cross-validation is a bit smaller than the natural scale of variation of the\n",
    "target variable. Furthermore the standard deviation of the cross validation\n",
    "estimate of the testing error is even smaller.\n",
    "\n",
    "This is a good start, but not necessarily enough to decide whether the\n",
    "generalization performance is good enough to make our prediction useful in\n",
    "practice.\n",
    "\n",
    "We recall that our model makes, on average, an error around 45 k\\$. With this\n",
    "information and looking at the target distribution, such an error might be\n",
    "acceptable when predicting houses with a 500 k\\$. However, it would be an\n",
    "issue with a house with a value of 50 k\\$. Thus, this indicates that our\n",
    "metric (Mean Absolute Error) is not ideal.\n",
    "\n",
    "We might instead choose a metric relative to the target value to predict: the\n",
    "mean absolute percentage error would have been a much better choice.\n",
    "\n",
    "But in all cases, an error of 45 k\\$ might be too large to automatically use\n",
    "our model to tag house value without expert supervision.\n",
    "\n",
    "## More detail regarding `cross_validate`\n",
    "\n",
    "During cross-validation, many models are trained and evaluated. Indeed, the\n",
    "number of elements in each array of the output of `cross_validate` is a\n",
    "result from one of this `fit`/`score`. To make it explicit, it is possible\n",
    "to retrieve theses fitted models for each of the fold by passing the option\n",
    "`return_estimator=True` in `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(regressor, data, target, return_estimator=True)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[\"estimator\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-think",
   "metadata": {},
   "source": [
    "The five decision tree regressors corresponds to the five fitted decision\n",
    "trees on the different folds. Having access to these regressors is handy\n",
    "because it allows to inspect the internal fitted parameters of these\n",
    "regressors.\n",
    "\n",
    "In the case where you are interested only about the test score, scikit-learn\n",
    "provide a `cross_val_score` function. It is identical to calling the\n",
    "`cross_validate` function and to select the `test_score` only (as we\n",
    "extensively did in the previous notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(regressor, data, target)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-longer",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we saw:\n",
    "\n",
    "* the necessity of splitting the data into a train and test set;\n",
    "* the meaning of the training and testing errors;\n",
    "* the overall cross-validation framework with the possibility to study\n",
    "  statistical performance variations;"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
