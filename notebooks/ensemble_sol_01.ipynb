{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ƒ Solution of Exercise 01\n",
    "\n",
    "The aim in this notebook is to investigate if we can fine-tune a bagging\n",
    "regressor and evaluate the gain obtained.\n",
    "\n",
    "We will load the california housing dataset and split it into a training and\n",
    "a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BaggingRegressor` providing a `DecisionTreeRegressor` with default\n",
    "parameter as a `base_estimator`. Train the regressor and evaluate the\n",
    "performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "bagging = BaggingRegressor(base_estimator=tree, n_jobs=-1)\n",
    "bagging.fit(X_train, y_train)\n",
    "test_score = bagging.score(X_test, y_test)\n",
    "print(f\"Basic R2 score of a bagging regressor:\\n\"\n",
    "      f\"{test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `RandomizedSearchCV` instance using the previous model and\n",
    "tune the important parameters of the bagging regressor. You can list the\n",
    "parameters using `get_params`. Find the best parameters and check if you\n",
    "are able to find a set of parameters which improve the default regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bagging.get_params().keys():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": randint(10, 30),\n",
    "    \"max_samples\": [0.5, 0.8, 1.0],\n",
    "    \"max_features\": [0.5, 0.8, 1.0],\n",
    "    \"base_estimator__max_depth\": randint(3, 10),\n",
    "}\n",
    "search = RandomizedSearchCV(bagging, param_grid, n_iter=20)\n",
    "_ = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results = cv_results[columns].sort_values(by=\"rank_test_score\")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = search.score(X_test, y_test)\n",
    "print(f\"Basic R2 score of a bagging regressor:\\n\"\n",
    "      f\"{test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the bagging regressor provides a predictor in which fine tuning\n",
    "is not as important as in the case of fitting a single decision tree."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
