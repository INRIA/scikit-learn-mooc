{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "In this notebook, we will present the metrics that can be used in regression.\n",
    "\n",
    "Unlike in classification problems, the target `y` is a continuous variable in\n",
    "regression problems. Therefore, classification metrics cannot be used to\n",
    "evaluate the performance of regression models. Instead, there exists a set of\n",
    "metrics dedicated to regression.\n",
    "\n",
    "We will use the Ames housing dataset where the goal is to predict the price\n",
    "of houses in Ames town. As for the classification, we will only use a single\n",
    "train-test split to focus only on the regression metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../datasets/house_prices.csv\")\n",
    "X, y = data.drop(columns=\"SalePrice\"), data[\"SalePrice\"]\n",
    "X = X.select_dtypes(np.number)\n",
    "y /= 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by splitting our dataset intro a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some machine learning models were designed to be solved as an optimization\n",
    "problem: minimzing an error (also known as loss function) using a training\n",
    "set. A basic loss function used in regression is the mean squared error.\n",
    "Thus, this metric is sometimes used to evaluate a model since this is also\n",
    "the loss function optimized by a model.\n",
    "\n",
    "We will give an example using a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_train)\n",
    "\n",
    "print(f\"Mean squared error on the training set: \"\n",
    "      f\"{mean_squared_error(y_train, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear regression model is the moodel minimizing the mean squared error\n",
    "on the training set. It means that there is no other set of coefficients\n",
    "which will decrease the error.\n",
    "\n",
    "Then, we can compute the mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(f\"Mean squared error on the testing set: \"\n",
    "      f\"{mean_squared_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw MSE can be difficult to interpret. One way is to rescale the MSE\n",
    "by the variance of the target. This score is known as the $R^2$ also called\n",
    "the coefficient of determination. Indeed, this is the default score used\n",
    "in scikit-learn by calliing the method `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ score represents the proportion of variance of the target that is\n",
    "explained by the independent variables in the model. The best score possible\n",
    "is 1 but there is no lower bound. However, a model that predicts the expected\n",
    "value of the target would get a score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_regressor = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "print(f\"R2 score for a regressor predicting the mean:\"\n",
    "      f\"{dummy_regressor.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ score gives insight into the goodness of fit of the model. However,\n",
    "this score cannot be compared from one dataset to another and the value\n",
    "obtained does not have a meaningful interpretation relative the original unit\n",
    "of the target. If we wanted to get an interpretable score, we would be\n",
    "interested in the median or mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(f\"Mean absolute error: \"\n",
    "      f\"{mean_absolute_error(y_test, y_pred):.3f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By computing the mean absolute error, we can interpret that our model is\n",
    "predicting on average 22.6 k$ away from the true house price. A disadvantage\n",
    "of this metric is that the mean can be impacted by large error. For some\n",
    "applications, we might not want these large errors to have such a big\n",
    "influence on our metric. In this case we can use the median absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "print(f\"Median absolute error: \"\n",
    "      f\"{median_absolute_error(y_test, y_pred):.3f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME: in 0.24, introduce median absolute percentage error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition of metrics, we can visually represent the results by plotting\n",
    "the predicted values versus the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_actual = {\n",
    "    \"True values (k$)\": y_test, \"Predicted values (k$)\": y_pred}\n",
    "predicted_actual = pd.DataFrame(predicted_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    data=predicted_actual, x=\"True values (k$)\", y=\"Predicted values (k$)\")\n",
    "ax.axline((0, 0), slope=1, color=\"tab:orange\", label=\"Perfect fit\")\n",
    "ax.set_aspect('equal', 'box')\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this plot, correct predictions would lie on the diagonal line. This plot\n",
    "allows us to detect if the model makes errors in a consistent way, i.e.\n",
    "has some bias.\n",
    "\n",
    "On this plot, we see that for the large True price values, our model tends to\n",
    "under-estimate the price of the house. Typically, this issue arises when the\n",
    "target to predict does not follow a normal distribution. In these cases the\n",
    "model would benefit from target transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "transformer = QuantileTransformer(\n",
    "    n_quantiles=900, output_distribution=\"normal\")\n",
    "model_transformed_target = TransformedTargetRegressor(\n",
    "    regressor=regressor, transformer=transformer)\n",
    "model_transformed_target.fit(X_train, y_train)\n",
    "y_pred = model_transformed_target.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_actual = {\n",
    "    \"True values (k$)\": y_test, \"Predicted values (k$)\": y_pred}\n",
    "predicted_actual = pd.DataFrame(predicted_actual)\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    data=predicted_actual, x=\"True values (k$)\", y=\"Predicted values (k$)\")\n",
    "ax.axline((0, 0), slope=1, color=\"tab:orange\", label=\"Perfect fit\")\n",
    "ax.set_aspect('equal', 'box')\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, once we transformed the target, we see that we corrected some of the\n",
    "high values."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
