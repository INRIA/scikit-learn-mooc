{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ƒ Solution for Exercise 01\n",
    "\n",
    "We presented different classification metrics in the previous notebook.\n",
    "However, we did not use it with a cross-validation. This exercise aims at\n",
    "practising and implementing cross-validation that will use such score.\n",
    "\n",
    "We will reuse the same blood transfusion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/blood_transfusion.csv\")\n",
    "X, y = data.drop(columns=\"Class\"), data[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `StratifiedKFold` cross-validation object. Then use it inside the\n",
    "`cross_val_score` function to evaluate the decision tree. We will first use\n",
    "the accuracy as a score function. Check the documentation of the parameter\n",
    "`scoring` in `cross_val_score` to check how to explicitely mention to compute\n",
    "the accuracy (even if this is the default score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "scores = cross_val_score(tree, X, y, cv=cv, scoring=\"accuracy\")\n",
    "print(f\"Accuracy score: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment by computing the `balanced_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree, X, y, cv=cv, scoring=\"balanced_accuracy\")\n",
    "print(f\"Balanced accuracy score: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now add a bit of complexity. We would like to compute the precision\n",
    "of our model. However, during the course we saw that we need to mention the\n",
    "positive label which in our case we consider to be the class `donated`.\n",
    "\n",
    "We will show that computing the precision without providing the positive\n",
    "label will not be supported by scikit-learn because it is indeed ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    scores = cross_val_score(tree, X, y, cv=cv, scoring=\"precision\")\n",
    "except ValueError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "We use a `try`/`except` pattern to be able to print the exception.\n",
    "```\n",
    "We get an exception because by default `pos_label=1` which is not the case\n",
    "in our case. Thus, we would like to specify a parameter linked to the score\n",
    "function. In this case, we need to create a scorer using the scoring function\n",
    "and the helper function `make_scorer`.\n",
    "\n",
    "So, import `sklearn.metrics.make_scorer` and\n",
    "`sklearn.metrics.precision_score`. Check the documentation of `make_scorer`.\n",
    "Finally, create a scorer by calling `make_scorer` using the score function\n",
    "`precision_score` and pass the extra parameter `pos_label=\"donated\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "precision = make_scorer(precision_score, pos_label=\"donated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead to provide the string `\"precision\"` to the `scoring` parameter\n",
    "in the `cross_val_score` call, pass the scorer that you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree, X, y, cv=cv, scoring=precision)\n",
    "print(f\"Precision score: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_val_score` will only compute a single score provided to the `scoring`\n",
    "parameter. The function `cross_validate` allows to compute multiple score\n",
    "which could be handy by passing a list of string or scorer to the parameter\n",
    "scoring.\n",
    "\n",
    "Import `sklearn.model_selection.cross_validate` and compute the accuracy and\n",
    "balanced accuracy through cross-validation. Plot the cross-validation score\n",
    "for both metrics using a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
    "\n",
    "scores = cross_validate(tree, X, y, cv=cv, scoring=scoring)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "# Define the style of the box style\n",
    "boxplot_property = {\n",
    "    \"vert\": False, \"whis\": 100, \"patch_artist\": True, \"widths\": 0.3,\n",
    "    \"boxprops\": dict(linewidth=3, color='black', alpha=0.9),\n",
    "    \"medianprops\": dict(linewidth=2.5, color='black', alpha=0.9),\n",
    "    \"whiskerprops\": dict(linewidth=3, color='black', alpha=0.9),\n",
    "    \"capprops\": dict(linewidth=3, color='black', alpha=0.9),\n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [scores[\"test_accuracy\"], scores[\"test_balanced_accuracy\"]],\n",
    "    index=[\"Accuracy\", \"Balanced accuracy\"]\n",
    ").T\n",
    "ax = metrics.plot.box(**boxplot_property)\n",
    "_ = ax.set_title(\"Computation of multiple scores using cross_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
