{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcc3 Solution for Exercise M7.03\n",
    "\n",
    "As with the classification metrics exercise, we will evaluate the regression\n",
    "metrics within a cross-validation framework to get familiar with the syntax.\n",
    "\n",
    "We will use the Ames house prices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ames_housing = pd.read_csv(\"../datasets/house_prices.csv\")\n",
    "data = ames_housing.drop(columns=\"SalePrice\")\n",
    "target = ames_housing[\"SalePrice\"]\n",
    "data = data.select_dtypes(np.number)\n",
    "target /= 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will be to create a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the `cross_val_score` to estimate the generalization performance of\n",
    "the model. Use a `KFold` cross-validation with 10 folds. Make the use of the\n",
    "$R^2$ score explicit by assigning the parameter `scoring` (even though it is\n",
    "the default score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, data, target, cv=10, scoring=\"r2\")\n",
    "print(f\"R2 score: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, instead of using the $R^2$ score, use the mean absolute error. You need\n",
    "to refer to the documentation for the `scoring` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "scores = cross_val_score(model, data, target, cv=10,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "errors = -scores\n",
    "print(f\"Mean absolute error: \"\n",
    "      f\"{errors.mean():.3f} k$ +/- {errors.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "The `scoring` parameter in scikit-learn expects score. It means that the\n",
    "higher the values, and the smaller the errors are, the better the model is.\n",
    "Therefore, the error should be multiplied by -1. That's why the string given\n",
    "the `scoring` starts with `neg_` when dealing with metrics which are errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the `cross_validate` function and compute multiple scores/errors\n",
    "at once by passing a list of scorers to the `scoring` parameter. You can\n",
    "compute the $R^2$ score and the mean absolute error for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = [\"r2\", \"neg_mean_absolute_error\"]\n",
    "cv_results = cross_validate(model, data, target, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = {\"R2\": cv_results[\"test_r2\"],\n",
    "          \"MAE\": -cv_results[\"test_neg_mean_absolute_error\"]}\n",
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}