
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Adaptive Boosting (AdaBoost) &#8212; Scikit-learn tutorial</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sklearn_mooc.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ğŸ“ Exercise 03" href="ensemble_ex_03.html" />
    <link rel="prev" title="ğŸ“ƒ Solution for Exercise 02" href="ensemble_sol_02.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/scikit-learn-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scikit-learn tutorial</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Concepts
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml_concepts/slides.html">
   ğŸ“° Introducing machine-learning concepts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml_concepts/quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The Predictive Modeling Pipeline
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/01_tabular_data_exploration_index.html">
   Tabular data exploration
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="01_tabular_data_exploration.html">
     Tabular data exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/01_tabular_data_exploration_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_index.html">
   Fitting a scikit-learn model on numerical data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline.html">
     First model with scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_scaling.html">
     Preprocessing for numerical features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_index.html">
   Handling categorical data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline.html">
     Encoding of categorical variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_column_transformer.html">
     Using numerical and categorical variables together
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/04_parameter_tuning_index.html">
   Hyper-parameter tuning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning.html">
     Introduction to hyper-parameter tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_search.html">
     Hyper-parameter tuning in scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/04_parameter_tuning_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Overfitting/Underfitting
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../overfit/slides.html">
   ğŸ“° Slides
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../linear_models/slides.html">
   ğŸ“° Intuitions on linear models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_without_sklearn.html">
   Linear regression without scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_01.html">
   ğŸ“ƒ Solution for Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_in_sklearn.html">
   Linear regression using scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_02.html">
   ğŸ“ Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_02.html">
   ğŸ“ƒ Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_non_linear_link.html">
   Linear regression with non-linear link between data and target
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_03.html">
   ğŸ“ Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_03.html">
   ğŸ“ƒ Solution for Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_regularization.html">
   Regularization of linear regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_04.html">
   ğŸ“ Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_04.html">
   ğŸ“ƒ Solution for Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic_regression.html">
   Linear model for classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_05.html">
   ğŸ“ Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_05.html">
   ğŸ“ƒ Solution for Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_non_linear.html">
   Beyond linear separation in classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_non_linear.html#main-take-away">
   Main take away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../linear_models/linear_models_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Decision tree models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../trees/slides.html">
   ğŸ“° Intuitions on tree-based models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_dataset.html">
   Presentation of the datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_classification.html">
   Build a classification decision tree
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_sol_01.html">
   ğŸ“ƒ Solution for Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_regression.html">
   Decision tree for regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_ex_02.html">
   ğŸ“ Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_sol_02.html">
   ğŸ“ƒ Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_hyperparameters.html">
   Importance of decision tree hyper-parameters on generalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_hyperparameters.html#main-take-away">
   Main take away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../trees/trees_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Ensemble of models
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_introduction.html">
   Introductory example to ensemble models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_bagging.html">
   Bagging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_01.html">
   ğŸ“ƒ Solution of Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_random_forest.html">
   Random forest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_random_forest.html#midpoint-summary">
   Midpoint summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_02.html">
   ğŸ“ Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_02.html">
   ğŸ“ƒ Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Adaptive Boosting (AdaBoost)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_03.html">
   ğŸ“ Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_03.html">
   ğŸ“ƒ Solution for Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_gradient_boosting.html">
   Gradient-boosting decision tree (GBDT)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_04.html">
   ğŸ“ Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_04.html">
   ğŸ“ƒ Solution for Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_hist_gradient_boosting.html">
   Speeding-up gradient-boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_hyperparameters.html">
   Hyper-parameters tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_05.html">
   ğŸ“ Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_05.html">
   ğŸ“ƒ Solution for Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_take_away.html">
   Main take away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/ensemble_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Evaluating model performance
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../evaluation/01_cross_validation.html">
   The cross-validation framework
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_train_test.html">
     The framework and why do we need it
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_sol_01.html">
     ğŸ“ƒ Solution fo Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_baseline.html">
     Comparing results with baseline and chance level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../evaluation/cross_validation_choices.html">
     Choice of cross-validation
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_ex_03.html">
       ğŸ“ Introductory exercise regarding stratification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_stratification.html">
       Stratification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_ex_04.html">
       ğŸ“ Introductory exercise for sample grouping
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_grouping.html">
       Sample grouping
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_ex_05.html">
       ğŸ“ Introductory exercise for non i.i.d. data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_time.html">
       Non i.i.d. data
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_nested.html">
     Nested cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_nested.html#take-away">
     Take away
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../evaluation/02_metrics.html">
   The evaluation metrics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_classification.html">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_regression.html">
     Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evaluation/02_metrics_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Feature selection
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_introduction.html">
   Compelling advantage of using feature selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_sol_01.html">
   ğŸ“ƒ Solution for Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_limitation_model.html">
   Limitation of selecting feature using a model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_limitation_model.html#main-take-away">
   Main take away
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Interpretation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html">
   Feature importance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html#take-away">
   Take Away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../interpretation/interpretation_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/python_scripts/ensemble_adaboost.py"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.py</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/INRIA/scikit-learn-mooc"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/INRIA/scikit-learn-mooc/issues/new?title=Issue%20on%20page%20%2Fpython_scripts/ensemble_adaboost.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/INRIA/scikit-learn-mooc/edit/master/python_scripts/ensemble_adaboost.py"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="adaptive-boosting-adaboost">
<h1>Adaptive Boosting (AdaBoost)<a class="headerlink" href="#adaptive-boosting-adaboost" title="Permalink to this headline">Â¶</a></h1>
<p>In this notebook, we present the Adaptive Boosting (AdaBoost) algorithm. The
aim is to intuitions regarding the internal machinery of AdaBoost and
boosting more in general.</p>
<p>We will load the â€œpenguinâ€ dataset used in the â€œtree in depthâ€ notebook. We
will predict penguin species from the features culmen length and depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../datasets/penguins_classification.csv&quot;</span><span class="p">)</span>
<span class="n">culmen_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Culmen Length (mm)&quot;</span><span class="p">,</span> <span class="s2">&quot;Culmen Depth (mm)&quot;</span><span class="p">]</span>
<span class="n">target_column</span> <span class="o">=</span> <span class="s2">&quot;Species&quot;</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">culmen_columns</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">target_column</span><span class="p">]</span>
<span class="n">range_features</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">feature_name</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>In addition, we are also using on the function used the previous â€œtree in
depthâ€ notebook to plot the decision function of the tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">plot_decision_function</span><span class="p">(</span><span class="n">fitted_classifier</span><span class="p">,</span> <span class="n">range_features</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot the boundary of the decision function of a classifier.&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

    <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">range_features</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="c1"># create a grid to evaluate all possible samples</span>
    <span class="n">plot_step</span> <span class="o">=</span> <span class="mf">0.02</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">range_features</span><span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">plot_step</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">range_features</span><span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">plot_step</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># compute the associated prediction</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">fitted_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># make the plot of the boundary and the data samples</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;RdBu&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<p>We will purposely train a shallow decision tree. Since the tree is shallow,
it is unlikely to overfit and some of the training examples will even be
misclassified on the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">culmen_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">culmen_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">target_column</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tab:red&quot;</span><span class="p">,</span> <span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="s2">&quot;black&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot_decision_function</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">range_features</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="c1"># find the misclassified samples</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">misclassified_samples_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">misclassified_samples_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">misclassified_samples_idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s2">&quot;+k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Misclassified samples&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;center left&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ensemble_adaboost_5_0.png" src="../_images/ensemble_adaboost_5_0.png" />
</div>
</div>
<p>We observe that several samples have been misclassified by the classifier.</p>
<p>We mentioned that boosting relies on creating a new classifier which tries to
correct these misclassifications. In scikit-learn, learners support a
parameter <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> which forces the learner to pay more attention to
samples with higher weights, during the training.</p>
<p>This parameter is set when calling
<code class="docutils literal notranslate"><span class="pre">classifier.fit(X,</span> <span class="pre">y,</span> <span class="pre">sample_weight=weights)</span></code>.
We will use this trick to create a new classifier by â€˜discardingâ€™ all
correctly classified samples and only considering the misclassified samples.
Thus, misclassified samples will be assigned a weight of 1 while well
classified samples will assigned to a weight of 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">sample_weight</span><span class="p">[</span><span class="n">misclassified_samples_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">culmen_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">culmen_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">target_column</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tab:red&quot;</span><span class="p">,</span> <span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="s2">&quot;black&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plot_decision_function</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">range_features</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">misclassified_samples_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">misclassified_samples_idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s2">&quot;+k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Previous misclassified samples&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;center left&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ensemble_adaboost_7_0.png" src="../_images/ensemble_adaboost_7_0.png" />
</div>
</div>
<p>We see that the decision function drastically changed. Qualitatively, we see
that the previously misclassified samples are now correctly classified.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">newly_misclassified_samples_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">remaining_misclassified_samples_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span>
    <span class="n">misclassified_samples_idx</span><span class="p">,</span> <span class="n">newly_misclassified_samples_idx</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Number of samples previously misclassified and still misclassified: &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">remaining_misclassified_samples_idx</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of samples previously misclassified and still misclassified: 0
</pre></div>
</div>
</div>
</div>
<p>However, we are making mistakes on previously well classified samples. Thus,
we get the intuition that we should weight the predictions of each classifier
differently, most probably by using the number of mistakes each classifier
is making.</p>
<p>So we could use the classification error to combine both trees.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ensemble_weight</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">misclassified_samples_idx</span><span class="p">))</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">newly_misclassified_samples_idx</span><span class="p">))</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">]</span>
<span class="n">ensemble_weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.935672514619883, 0.6929824561403509]
</pre></div>
</div>
</div>
</div>
<p>The first classifier was 94% accurate and the second one 69% accurate.
Therefore, when predicting a class, we should trust the first classifier
slightly more than the second one. We could use these accuracy values to
weight the predictions of each learner.</p>
<p>To summarize, boosting learns several classifiers, each of which will
focus more or less on specific samples of the dataset. Boosting is thus
different from bagging: here we never resample our dataset, we just assign
different weights to the original dataset.</p>
<p>Boosting requires some strategy to combine the learners together:</p>
<ul class="simple">
<li><p>one needs to define a way to compute the weights to be assigned
to samples;</p></li>
<li><p>one needs to assign a weight to each learner when making predictions.</p></li>
</ul>
<p>Indeed, we defined a really simple scheme to assign sample weights and
learner weights. However, there are statistical theories (like in AdaBoost)
for how these sample and learner weights can be optimally calculated.</p>
<p><strong>FIXME: I think we should add a reference to ESL here.</strong></p>
<p>We will use the AdaBoost classifier implemented in scikit-learn and
look at the underlying decision tree classifiers trained.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="n">base_estimator</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">adaboost</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
    <span class="n">base_estimator</span><span class="o">=</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;SAMME&quot;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">adaboost</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">tree</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">adaboost</span><span class="o">.</span><span class="n">estimators_</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">culmen_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">culmen_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">target_column</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tab:red&quot;</span><span class="p">,</span> <span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="s2">&quot;black&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">plot_decision_function</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">range_features</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight of each classifier: </span><span class="si">{</span><span class="n">adaboost</span><span class="o">.</span><span class="n">estimator_weights_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error of each classifier: </span><span class="si">{</span><span class="n">adaboost</span><span class="o">.</span><span class="n">estimator_errors_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Weight of each classifier: [3.58351894 3.46901998 3.03303773]
Error of each classifier: [0.05263158 0.05864198 0.08787269]
</pre></div>
</div>
<img alt="../_images/ensemble_adaboost_13_1.png" src="../_images/ensemble_adaboost_13_1.png" />
</div>
</div>
<p>We see that AdaBoost has learnt three different classifiers each of which
focuses on different samples. Looking at the weights of each learner, we see
that the ensemble gives the highest weight to the first classifier. This
indeed makes sense when we look at the errors of each classifier. The first
classifier also has the highest classification performance.</p>
<p>While AdaBoost is a nice algorithm to demonsrate the internal machinery of
boosting algorithms, it is not the most efficient machine-learning algorithm.
The most efficient algorithm based on boosting is the gradient-boosting
decision tree (GBDT) algorithm which we will discuss after a short exercise.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./python_scripts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ensemble_sol_02.html" title="previous page">ğŸ“ƒ Solution for Exercise 02</a>
    <a class='right-next' id="next-link" href="ensemble_ex_03.html" title="next page">ğŸ“ Exercise 03</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By scikit-learn developers<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>