
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speeding-up gradient-boosting &#8212; Scikit-learn tutorial</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sklearn_mooc.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hyper-parameters tuning" href="ensemble_hyperparameters.html" />
    <link rel="prev" title="ğŸ“ƒ Solution for Exercise 04" href="ensemble_sol_04.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/scikit-learn-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scikit-learn tutorial</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Concepts
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml_concepts/slides.html">
   ğŸ“° Introducing machine-learning concepts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml_concepts/quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The Predictive Modeling Pipeline
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/01_tabular_data_exploration_index.html">
   Tabular data exploration
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="01_tabular_data_exploration.html">
     First look at our dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/01_tabular_data_exploration_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_index.html">
   Fitting a scikit-learn model on numerical data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_introduction.html">
     First model with scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_hands_on.html">
     Working with numerical data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_numerical_pipeline_scaling.html">
     Preprocessing for numerical features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_index.html">
   Handling categorical data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline.html">
     Encoding of categorical variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_column_transformer.html">
     Using numerical and categorical variables together
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_categorical_pipeline_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../predictive_modeling_pipeline/04_parameter_tuning_index.html">
   Hyper-parameter tuning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning.html">
     Introduction to hyper-parameter tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_search.html">
     Hyper-parameter tuning in scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_parameter_tuning_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../predictive_modeling_pipeline/04_parameter_tuning_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Overfitting/Underfitting
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../overfit/slides.html">
   ğŸ“° Slides
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../linear_models/slides.html">
   ğŸ“° Intuitions on linear models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_without_sklearn.html">
   Linear regression without scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_01.html">
   ğŸ“ƒ Solution for Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_in_sklearn.html">
   Linear regression using scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_02.html">
   ğŸ“ Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_02.html">
   ğŸ“ƒ Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_non_linear_link.html">
   Linear regression with non-linear link between data and target
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_03.html">
   ğŸ“ Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_03.html">
   ğŸ“ƒ Solution for Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_regularization.html">
   Regularization of linear regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_04.html">
   ğŸ“ Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_04.html">
   ğŸ“ƒ Solution for Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic_regression.html">
   Linear model for classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_ex_05.html">
   ğŸ“ Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models_sol_05.html">
   ğŸ“ƒ Solution for Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_non_linear.html">
   Beyond linear separation in classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_regression_non_linear.html#main-take-away">
   Main take away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../linear_models/linear_models_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Decision tree models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../trees/slides.html">
   ğŸ“° Intuitions on tree-based models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_dataset.html">
   Presentation of the datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_classification.html">
   Build a classification decision tree
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_sol_01.html">
   ğŸ“ƒ Solution for Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_regression.html">
   Decision tree for regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_ex_02.html">
   ğŸ“ Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_sol_02.html">
   ğŸ“ƒ Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_hyperparameters.html">
   Importance of decision tree hyper-parameters on generalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees_hyperparameters.html#main-take-away">
   Main take away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../trees/trees_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Ensemble of models
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_introduction.html">
   Introductory example to ensemble models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_bagging.html">
   Bagging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_01.html">
   ğŸ“ƒ Solution of Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_random_forest.html">
   Random forest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_random_forest.html#midpoint-summary">
   Midpoint summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_02.html">
   ğŸ“ Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_02.html">
   ğŸ“ƒ Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_adaboost.html">
   Adaptive Boosting (AdaBoost)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_03.html">
   ğŸ“ Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_03.html">
   ğŸ“ƒ Solution for Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_gradient_boosting.html">
   Gradient-boosting decision tree (GBDT)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_04.html">
   ğŸ“ Exercise 04
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_04.html">
   ğŸ“ƒ Solution for Exercise 04
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Speeding-up gradient-boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_hyperparameters.html">
   Hyper-parameters tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_ex_05.html">
   ğŸ“ Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_sol_05.html">
   ğŸ“ƒ Solution for Exercise 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_take_away.html">
   Main take away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/ensemble_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Evaluating model performance
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../evaluation/01_cross_validation.html">
   The cross-validation framework
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_train_test.html">
     The framework and why do we need it
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_sol_01.html">
     ğŸ“ƒ Solution fo Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_baseline.html">
     Comparing results with baseline and chance level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../evaluation/cross_validation_choices.html">
     Choice of cross-validation
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_ex_03.html">
       ğŸ“ Introductory exercise regarding stratification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_stratification.html">
       Stratification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_ex_04.html">
       ğŸ“ Introductory exercise for sample grouping
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_grouping.html">
       Sample grouping
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_ex_05.html">
       ğŸ“ Introductory exercise for non i.i.d. data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_validation_time.html">
       Non i.i.d. data
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_nested.html">
     Nested cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cross_validation_nested.html#take-away">
     Take away
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../evaluation/02_metrics.html">
   The evaluation metrics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_classification.html">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_ex_01.html">
     ğŸ“ Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_sol_01.html">
     ğŸ“ƒ Solution for Exercise 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_regression.html">
     Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_ex_02.html">
     ğŸ“ Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="metrics_sol_02.html">
     ğŸ“ƒ Solution for Exercise 02
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evaluation/02_metrics_quiz.html">
     âœ… Quiz
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Feature selection
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_introduction.html">
   Compelling advantage of using feature selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_ex_01.html">
   ğŸ“ Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_sol_01.html">
   ğŸ“ƒ Solution for Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_limitation_model.html">
   Limitation of selecting feature using a model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feature_selection_limitation_model.html#main-take-away">
   Main take away
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Interpretation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html">
   Feature importance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html#take-away">
   Take Away
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../interpretation/interpretation_quiz.html">
   âœ… Quiz
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/python_scripts/ensemble_hist_gradient_boosting.py"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.py</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/INRIA/scikit-learn-mooc"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/INRIA/scikit-learn-mooc/issues/new?title=Issue%20on%20page%20%2Fpython_scripts/ensemble_hist_gradient_boosting.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/INRIA/scikit-learn-mooc/edit/master/python_scripts/ensemble_hist_gradient_boosting.py"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="speeding-up-gradient-boosting">
<h1>Speeding-up gradient-boosting<a class="headerlink" href="#speeding-up-gradient-boosting" title="Permalink to this headline">Â¶</a></h1>
<p>In this notebook, we present a modified version of gradient boosting which
uses a reduce number of split when building the different trees. This
algorithm is called histogram gradient boosting in scikit-learn.</p>
<p>We previously mentioned that random-forest is an efficient algorithm since
each tree of the ensemble can be fitted at the same time independently.
Therefore, the algorithm scales efficiently with both the number of CPUs and
the number of samples.</p>
<p>In gradient-boosting, the algorithm is a sequential algorithm. It requires
the <code class="docutils literal notranslate"><span class="pre">N-1</span></code> trees to have been fit to be able to fit the tree at stage <code class="docutils literal notranslate"><span class="pre">N</span></code>.
Therefore, the algorithm is quite computationally expensive. The most
expensive part in this algorithm is the search for the best split in the tree
which is a brute-force approach: all possible split are evaluated and the
best one is picked. We explained this process in the notebook â€œtree in
depthâ€, which you can refer to.</p>
<p>To accelerate the gradient-boosting algorithm, one could reduce the number of
splits to be evaluated. As a consequence, the performance of such a
tree would be reduced. However, since we are combining several trees in a
gradient-boosting, we can add more estimators to overcome
this issue.</p>
<p>We will make a naive implementation of such algorithm using building blocks
from scikit-learn. First, we will load the california housing dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will make a quick benchmark of the original gradient boosting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>

<span class="n">gradient_boosting</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">gradient_boosting</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">fit_time_gradient_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">score_gradient_boosting</span> <span class="o">=</span> <span class="n">gradient_boosting</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">score_time_gradient_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gradient boosting decision tree&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R2 score: </span><span class="si">{</span><span class="n">score_gradient_boosting</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fit time: </span><span class="si">{</span><span class="n">fit_time_gradient_boosting</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score time: </span><span class="si">{</span><span class="n">score_time_gradient_boosting</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gradient boosting decision tree
R2 score: 0.804
Fit time: 7.87 s
Score time: 0.02149 s
</pre></div>
</div>
</div>
</div>
<p>We recall that a way to accelerate the gradient boosting is to reduce the
number of split considered within the tree building. One way is to bin the
data before to give them into the gradient boosting. A transformer called
<code class="docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code> is doing such transformation. Thus, we can pipeline
this preprocessing with the gradient boosting.</p>
<p>We can first demonstrate the transformation done by the <code class="docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="n">discretizer</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span>
    <span class="n">n_bins</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s2">&quot;ordinal&quot;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
<span class="n">X_trans</span> <span class="o">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_trans</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[243.,  17., 246., ..., 168., 184.,   6.],
       [225.,  16., 217., ...,  40.,  15., 210.],
       [107.,  17., 125., ..., 151.,  96., 147.],
       ...,
       [106.,  30.,  18., ...,   8., 110.,  55.],
       [219.,  33.,  70., ...,  40.,  25., 180.],
       [  7.,  13.,  31., ..., 205.,  11., 233.]])
</pre></div>
</div>
</div>
</div>
<p>We see that the discretizer transform the original data into an integer.
This integer represents the bin index when the distribution by quantile is
performed. We can check the number of bins per feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">col</span><span class="p">))</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X_trans</span><span class="o">.</span><span class="n">T</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[256, 50, 256, 254, 256, 256, 210, 235]
</pre></div>
</div>
</div>
</div>
<p>After this transformation, we see that we have at most 256 unique values per
features. Now, we will use this transformer to discretize data before to
train the gradient boosting regressor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">gradient_boosting</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">discretizer</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">))</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">gradient_boosting</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">fit_time_gradient_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">score_gradient_boosting</span> <span class="o">=</span> <span class="n">gradient_boosting</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">score_time_gradient_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KBinsDiscritizer + Gradient boosting decision tree&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R2 score: </span><span class="si">{</span><span class="n">score_gradient_boosting</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fit time: </span><span class="si">{</span><span class="n">fit_time_gradient_boosting</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score time: </span><span class="si">{</span><span class="n">score_time_gradient_boosting</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/opt/hostedtoolcache/Python/3.7.9/x64/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:202: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KBinsDiscritizer + Gradient boosting decision tree
R2 score: 0.805
Fit time: 5.00 s
Score time: 0.02527 s
</pre></div>
</div>
</div>
</div>
<p>Here, we observe that the fit time have been drastically reduce but that the
performance of the model are the identical. Scikit-learn provides a specific
class even more optimized for large dataset called
<code class="docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> and <code class="docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code>. Each
feature in the dataset <code class="docutils literal notranslate"><span class="pre">X</span></code> is first binned by computing histograms which are
later used to evaluate the potential splits. The number of splits to evaluate
is then much smaller. This algorithm becomes much more efficient than
gradient boosting when the dataset has 10,000+ samples.</p>
<p>Below we will give an example of a large dataset and we can compare
computation time with the earlier experiment in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_hist_gradient_boosting</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingRegressor</span>

<span class="n">histogram_gradient_boosting</span> <span class="o">=</span> <span class="n">HistGradientBoostingRegressor</span><span class="p">(</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">histogram_gradient_boosting</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">fit_time_histogram_gradient_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">score_histogram_gradient_boosting</span> <span class="o">=</span> <span class="n">histogram_gradient_boosting</span><span class="o">.</span><span class="n">score</span><span class="p">(</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">score_time_histogram_gradient_boosting</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Historgram gradient boosting decision tree&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R2 score: </span><span class="si">{</span><span class="n">score_histogram_gradient_boosting</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fit time: </span><span class="si">{</span><span class="n">fit_time_histogram_gradient_boosting</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score time: </span><span class="si">{</span><span class="n">score_time_histogram_gradient_boosting</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Historgram gradient boosting decision tree
R2 score: 0.845
Fit time: 1.16 s
Score time: 0.05215 s
</pre></div>
</div>
</div>
</div>
<p>The histogram gradient-boosting is the best algorithm in terms of score.
It will also scale when the number of samples increases, while the normal
gradient-boosting will not.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./python_scripts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ensemble_sol_04.html" title="previous page">ğŸ“ƒ Solution for Exercise 04</a>
    <a class='right-next' id="next-link" href="ensemble_hyperparameters.html" title="next page">Hyper-parameters tuning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By scikit-learn developers<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>