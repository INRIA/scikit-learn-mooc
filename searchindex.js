Search.setIndex({"docnames": ["appendix/acknowledgement", "appendix/adult_census_description", "appendix/datasets_intro", "appendix/glossary", "appendix/notebook_timings", "appendix/toc_redirect", "concluding_remarks", "concluding_remarks_video", "ensemble/bagging_slides", "ensemble/boosting_slides", "ensemble/ensemble_boosting_index", "ensemble/ensemble_bootstrap_index", "ensemble/ensemble_hyperparameters_index", "ensemble/ensemble_module_intro", "ensemble/ensemble_module_take_away", "ensemble/ensemble_quiz_m6_01", "ensemble/ensemble_quiz_m6_02", "ensemble/ensemble_quiz_m6_03", "ensemble/ensemble_wrap_up_quiz", "evaluation/cross_validation_baseline_index", "evaluation/cross_validation_choices_index", "evaluation/cross_validation_nested_index", "evaluation/evaluation_module_intro", "evaluation/evaluation_module_take_away", "evaluation/evaluation_quiz_m7_01", "evaluation/evaluation_quiz_m7_02", "evaluation/evaluation_quiz_m7_03", "evaluation/evaluation_quiz_m7_04", "evaluation/evaluation_quiz_m7_05", "evaluation/evaluation_wrap_up_quiz", "evaluation/metrics_classification_index", "evaluation/metrics_regression_index", "feature_selection/feature_selection_limitation_index", "feature_selection/feature_selection_module_intro", "feature_selection/feature_selection_module_take_away", "feature_selection/feature_selection_quiz", "index", "interpretation/interpretation_quiz", "linear_models/linear_models_intuitions_index", "linear_models/linear_models_module_intro", "linear_models/linear_models_module_take_away", "linear_models/linear_models_non_linear_index", "linear_models/linear_models_quiz_m4_01", "linear_models/linear_models_quiz_m4_02", "linear_models/linear_models_quiz_m4_03", "linear_models/linear_models_quiz_m4_04", "linear_models/linear_models_quiz_m4_05", "linear_models/linear_models_regularization_index", "linear_models/linear_models_slides", "linear_models/linear_models_wrap_up_quiz", "linear_models/regularized_linear_models_slides", "ml_concepts/quiz_intro_01", "ml_concepts/slides", "overfit/bias_vs_variance_quiz_m2_03", "overfit/bias_vs_variance_slides", "overfit/learning_validation_curves_quiz_m2_02", "overfit/learning_validation_curves_slides", "overfit/overfit_bias_variance_index", "overfit/overfit_module_intro", "overfit/overfit_overfitting_underfitting_index", "overfit/overfit_take_away", "overfit/overfit_validation_learning_curves_index", "overfit/overfit_wrap_up_quiz", "overfit/overfitting_vs_under_fitting_quiz_m2_01", "overfit/overfitting_vs_under_fitting_slides", "predictive_modeling_pipeline/01_tabular_data_exploration_index", "predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01", "predictive_modeling_pipeline/02_numerical_pipeline_index", "predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02", "predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation", "predictive_modeling_pipeline/03_categorical_pipeline_index", "predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03", "predictive_modeling_pipeline/03_categorical_pipeline_visualization_video", "predictive_modeling_pipeline/predictive_modeling_module_intro", "predictive_modeling_pipeline/predictive_modeling_module_take_away", "predictive_modeling_pipeline/wrap_up_quiz", "python_scripts/01_tabular_data_exploration", "python_scripts/01_tabular_data_exploration_ex_01", "python_scripts/01_tabular_data_exploration_sol_01", "python_scripts/02_numerical_pipeline_cross_validation", "python_scripts/02_numerical_pipeline_ex_00", "python_scripts/02_numerical_pipeline_ex_01", "python_scripts/02_numerical_pipeline_hands_on", "python_scripts/02_numerical_pipeline_introduction", "python_scripts/02_numerical_pipeline_scaling", "python_scripts/02_numerical_pipeline_sol_00", "python_scripts/02_numerical_pipeline_sol_01", "python_scripts/03_categorical_pipeline", "python_scripts/03_categorical_pipeline_column_transformer", "python_scripts/03_categorical_pipeline_ex_01", "python_scripts/03_categorical_pipeline_ex_02", "python_scripts/03_categorical_pipeline_sol_01", "python_scripts/03_categorical_pipeline_sol_02", "python_scripts/03_categorical_pipeline_visualization", "python_scripts/cross_validation_baseline", "python_scripts/cross_validation_ex_01", "python_scripts/cross_validation_ex_02", "python_scripts/cross_validation_grouping", "python_scripts/cross_validation_learning_curve", "python_scripts/cross_validation_nested", "python_scripts/cross_validation_sol_01", "python_scripts/cross_validation_sol_02", "python_scripts/cross_validation_stratification", "python_scripts/cross_validation_time", "python_scripts/cross_validation_train_test", "python_scripts/cross_validation_validation_curve", "python_scripts/datasets_ames_housing", "python_scripts/datasets_bike_rides", "python_scripts/datasets_blood_transfusion", "python_scripts/datasets_california_housing", "python_scripts/dev_features_importance", "python_scripts/ensemble_adaboost", "python_scripts/ensemble_bagging", "python_scripts/ensemble_ex_01", "python_scripts/ensemble_ex_02", "python_scripts/ensemble_ex_03", "python_scripts/ensemble_ex_04", "python_scripts/ensemble_gradient_boosting", "python_scripts/ensemble_hist_gradient_boosting", "python_scripts/ensemble_hyperparameters", "python_scripts/ensemble_introduction", "python_scripts/ensemble_random_forest", "python_scripts/ensemble_sol_01", "python_scripts/ensemble_sol_02", "python_scripts/ensemble_sol_03", "python_scripts/ensemble_sol_04", "python_scripts/feature_selection_ex_01", "python_scripts/feature_selection_introduction", "python_scripts/feature_selection_limitation_model", "python_scripts/feature_selection_sol_01", "python_scripts/linear_models_ex_01", "python_scripts/linear_models_ex_02", "python_scripts/linear_models_ex_03", "python_scripts/linear_models_regularization", "python_scripts/linear_models_sol_01", "python_scripts/linear_models_sol_02", "python_scripts/linear_models_sol_03", "python_scripts/linear_regression_in_sklearn", "python_scripts/linear_regression_non_linear_link", "python_scripts/linear_regression_without_sklearn", "python_scripts/logistic_regression", "python_scripts/logistic_regression_non_linear", "python_scripts/metrics_classification", "python_scripts/metrics_ex_01", "python_scripts/metrics_ex_02", "python_scripts/metrics_regression", "python_scripts/metrics_sol_01", "python_scripts/metrics_sol_02", "python_scripts/parameter_tuning_ex_02", "python_scripts/parameter_tuning_ex_03", "python_scripts/parameter_tuning_grid_search", "python_scripts/parameter_tuning_manual", "python_scripts/parameter_tuning_nested", "python_scripts/parameter_tuning_parallel_plot", "python_scripts/parameter_tuning_randomized_search", "python_scripts/parameter_tuning_sol_02", "python_scripts/parameter_tuning_sol_03", "python_scripts/trees_classification", "python_scripts/trees_dataset", "python_scripts/trees_ex_01", "python_scripts/trees_ex_02", "python_scripts/trees_hyperparameters", "python_scripts/trees_regression", "python_scripts/trees_sol_01", "python_scripts/trees_sol_02", "toc", "trees/slides", "trees/trees_classification_index", "trees/trees_hyperparameters_index", "trees/trees_intuitions_index", "trees/trees_module_intro", "trees/trees_module_take_away", "trees/trees_quiz_m5_01", "trees/trees_quiz_m5_02", "trees/trees_quiz_m5_03", "trees/trees_quiz_m5_04", "trees/trees_regression_index", "trees/trees_wrap_up_quiz", "tuning/parameter_tuning_automated_index", "tuning/parameter_tuning_automated_quiz_m3_02", "tuning/parameter_tuning_manual_index", "tuning/parameter_tuning_manual_quiz_m3_01", "tuning/parameter_tuning_module_intro", "tuning/parameter_tuning_module_take_away", "tuning/parameter_tuning_parallel_plot_video", "tuning/parameter_tuning_wrap_up_quiz"], "filenames": ["appendix/acknowledgement.md", "appendix/adult_census_description.md", "appendix/datasets_intro.md", "appendix/glossary.md", "appendix/notebook_timings.md", "appendix/toc_redirect.md", "concluding_remarks.md", "concluding_remarks_video.md", "ensemble/bagging_slides.md", "ensemble/boosting_slides.md", "ensemble/ensemble_boosting_index.md", "ensemble/ensemble_bootstrap_index.md", "ensemble/ensemble_hyperparameters_index.md", "ensemble/ensemble_module_intro.md", "ensemble/ensemble_module_take_away.md", "ensemble/ensemble_quiz_m6_01.md", "ensemble/ensemble_quiz_m6_02.md", "ensemble/ensemble_quiz_m6_03.md", "ensemble/ensemble_wrap_up_quiz.md", "evaluation/cross_validation_baseline_index.md", "evaluation/cross_validation_choices_index.md", "evaluation/cross_validation_nested_index.md", "evaluation/evaluation_module_intro.md", "evaluation/evaluation_module_take_away.md", "evaluation/evaluation_quiz_m7_01.md", "evaluation/evaluation_quiz_m7_02.md", "evaluation/evaluation_quiz_m7_03.md", "evaluation/evaluation_quiz_m7_04.md", "evaluation/evaluation_quiz_m7_05.md", "evaluation/evaluation_wrap_up_quiz.md", "evaluation/metrics_classification_index.md", "evaluation/metrics_regression_index.md", "feature_selection/feature_selection_limitation_index.md", "feature_selection/feature_selection_module_intro.md", "feature_selection/feature_selection_module_take_away.md", "feature_selection/feature_selection_quiz.md", "index.md", "interpretation/interpretation_quiz.md", "linear_models/linear_models_intuitions_index.md", "linear_models/linear_models_module_intro.md", "linear_models/linear_models_module_take_away.md", "linear_models/linear_models_non_linear_index.md", "linear_models/linear_models_quiz_m4_01.md", "linear_models/linear_models_quiz_m4_02.md", "linear_models/linear_models_quiz_m4_03.md", "linear_models/linear_models_quiz_m4_04.md", "linear_models/linear_models_quiz_m4_05.md", "linear_models/linear_models_regularization_index.md", "linear_models/linear_models_slides.md", "linear_models/linear_models_wrap_up_quiz.md", "linear_models/regularized_linear_models_slides.md", "ml_concepts/quiz_intro_01.md", "ml_concepts/slides.md", "overfit/bias_vs_variance_quiz_m2_03.md", "overfit/bias_vs_variance_slides.md", "overfit/learning_validation_curves_quiz_m2_02.md", "overfit/learning_validation_curves_slides.md", "overfit/overfit_bias_variance_index.md", "overfit/overfit_module_intro.md", "overfit/overfit_overfitting_underfitting_index.md", "overfit/overfit_take_away.md", "overfit/overfit_validation_learning_curves_index.md", "overfit/overfit_wrap_up_quiz.md", "overfit/overfitting_vs_under_fitting_quiz_m2_01.md", "overfit/overfitting_vs_under_fitting_slides.md", "predictive_modeling_pipeline/01_tabular_data_exploration_index.md", "predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01.md", "predictive_modeling_pipeline/02_numerical_pipeline_index.md", "predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02.md", "predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation.md", "predictive_modeling_pipeline/03_categorical_pipeline_index.md", "predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03.md", "predictive_modeling_pipeline/03_categorical_pipeline_visualization_video.md", "predictive_modeling_pipeline/predictive_modeling_module_intro.md", "predictive_modeling_pipeline/predictive_modeling_module_take_away.md", "predictive_modeling_pipeline/wrap_up_quiz.md", "python_scripts/01_tabular_data_exploration.py", "python_scripts/01_tabular_data_exploration_ex_01.py", "python_scripts/01_tabular_data_exploration_sol_01.py", "python_scripts/02_numerical_pipeline_cross_validation.py", "python_scripts/02_numerical_pipeline_ex_00.py", "python_scripts/02_numerical_pipeline_ex_01.py", "python_scripts/02_numerical_pipeline_hands_on.py", "python_scripts/02_numerical_pipeline_introduction.py", "python_scripts/02_numerical_pipeline_scaling.py", "python_scripts/02_numerical_pipeline_sol_00.py", "python_scripts/02_numerical_pipeline_sol_01.py", "python_scripts/03_categorical_pipeline.py", "python_scripts/03_categorical_pipeline_column_transformer.py", "python_scripts/03_categorical_pipeline_ex_01.py", "python_scripts/03_categorical_pipeline_ex_02.py", "python_scripts/03_categorical_pipeline_sol_01.py", "python_scripts/03_categorical_pipeline_sol_02.py", "python_scripts/03_categorical_pipeline_visualization.py", "python_scripts/cross_validation_baseline.py", "python_scripts/cross_validation_ex_01.py", "python_scripts/cross_validation_ex_02.py", "python_scripts/cross_validation_grouping.py", "python_scripts/cross_validation_learning_curve.py", "python_scripts/cross_validation_nested.py", "python_scripts/cross_validation_sol_01.py", "python_scripts/cross_validation_sol_02.py", "python_scripts/cross_validation_stratification.py", "python_scripts/cross_validation_time.py", "python_scripts/cross_validation_train_test.py", "python_scripts/cross_validation_validation_curve.py", "python_scripts/datasets_ames_housing.py", "python_scripts/datasets_bike_rides.py", "python_scripts/datasets_blood_transfusion.py", "python_scripts/datasets_california_housing.py", "python_scripts/dev_features_importance.py", "python_scripts/ensemble_adaboost.py", "python_scripts/ensemble_bagging.py", "python_scripts/ensemble_ex_01.py", "python_scripts/ensemble_ex_02.py", "python_scripts/ensemble_ex_03.py", "python_scripts/ensemble_ex_04.py", "python_scripts/ensemble_gradient_boosting.py", "python_scripts/ensemble_hist_gradient_boosting.py", "python_scripts/ensemble_hyperparameters.py", "python_scripts/ensemble_introduction.py", "python_scripts/ensemble_random_forest.py", "python_scripts/ensemble_sol_01.py", "python_scripts/ensemble_sol_02.py", "python_scripts/ensemble_sol_03.py", "python_scripts/ensemble_sol_04.py", "python_scripts/feature_selection_ex_01.py", "python_scripts/feature_selection_introduction.py", "python_scripts/feature_selection_limitation_model.py", "python_scripts/feature_selection_sol_01.py", "python_scripts/linear_models_ex_01.py", "python_scripts/linear_models_ex_02.py", "python_scripts/linear_models_ex_03.py", "python_scripts/linear_models_regularization.py", "python_scripts/linear_models_sol_01.py", "python_scripts/linear_models_sol_02.py", "python_scripts/linear_models_sol_03.py", "python_scripts/linear_regression_in_sklearn.py", "python_scripts/linear_regression_non_linear_link.py", "python_scripts/linear_regression_without_sklearn.py", "python_scripts/logistic_regression.py", "python_scripts/logistic_regression_non_linear.py", "python_scripts/metrics_classification.py", "python_scripts/metrics_ex_01.py", "python_scripts/metrics_ex_02.py", "python_scripts/metrics_regression.py", "python_scripts/metrics_sol_01.py", "python_scripts/metrics_sol_02.py", "python_scripts/parameter_tuning_ex_02.py", "python_scripts/parameter_tuning_ex_03.py", "python_scripts/parameter_tuning_grid_search.py", "python_scripts/parameter_tuning_manual.py", "python_scripts/parameter_tuning_nested.py", "python_scripts/parameter_tuning_parallel_plot.py", "python_scripts/parameter_tuning_randomized_search.py", "python_scripts/parameter_tuning_sol_02.py", "python_scripts/parameter_tuning_sol_03.py", "python_scripts/trees_classification.py", "python_scripts/trees_dataset.py", "python_scripts/trees_ex_01.py", "python_scripts/trees_ex_02.py", "python_scripts/trees_hyperparameters.py", "python_scripts/trees_regression.py", "python_scripts/trees_sol_01.py", "python_scripts/trees_sol_02.py", "toc.md", "trees/slides.md", "trees/trees_classification_index.md", "trees/trees_hyperparameters_index.md", "trees/trees_intuitions_index.md", "trees/trees_module_intro.md", "trees/trees_module_take_away.md", "trees/trees_quiz_m5_01.md", "trees/trees_quiz_m5_02.md", "trees/trees_quiz_m5_03.md", "trees/trees_quiz_m5_04.md", "trees/trees_regression_index.md", "trees/trees_wrap_up_quiz.md", "tuning/parameter_tuning_automated_index.md", "tuning/parameter_tuning_automated_quiz_m3_02.md", "tuning/parameter_tuning_manual_index.md", "tuning/parameter_tuning_manual_quiz_m3_01.md", "tuning/parameter_tuning_module_intro.md", "tuning/parameter_tuning_module_take_away.md", "tuning/parameter_tuning_parallel_plot_video.md", "tuning/parameter_tuning_wrap_up_quiz.md"], "titles": ["Acknowledgement", "The adult census dataset", "Datasets description", "Glossary", "Notebook timings", "Table of contents", "Concluding remarks", "\ud83c\udfa5 Concluding remarks", "\ud83c\udfa5 Intuitions on ensemble models: bagging", "\ud83c\udfa5 Intuitions on ensemble models: boosting", "Ensemble based on boosting", "Ensemble method using bootstrapping", "Hyperparameter tuning with ensemble methods", "Module overview", "Main take-away", "\u2705 Quiz M6.01", "\u2705 Quiz M6.02", "\u2705 Quiz M6.03", "\ud83c\udfc1 Wrap-up quiz 6", "Comparing a model with simple baselines", "Choice of cross-validation", "Nested cross-validation", "Module overview", "Main take-away", "\u2705 Quiz M7.01", "\u2705 Quiz M7.02", "\u2705 Quiz M7.03", "\u2705 Quiz M7.04", "\u2705 Quiz M7.05", "\ud83c\udfc1 Wrap-up quiz 7", "Classification metrics", "Regression metrics", "Caveats of feature selection", "Module overview", "Main take-away", "\u2705 Quiz", "Introduction", "\u2705 Quiz", "Intuitions on linear models", "Module overview", "Main take-away", "Non-linear feature engineering for linear models", "\u2705 Quiz M4.01", "\u2705 Quiz M4.02", "\u2705 Quiz M4.03", "\u2705 Quiz M4.04", "\u2705 Quiz M4.05", "Regularization in linear model", "\ud83c\udfa5 Intuitions on linear models", "\ud83c\udfc1 Wrap-up quiz 4", "\ud83c\udfa5 Intuitions on regularized linear models", "\u2705 Quiz Intro.01", "\ud83c\udfa5 Introducing machine-learning concepts", "\u2705 Quiz M2.03", "\ud83c\udfa5 Bias versus Variance", "\u2705 Quiz M2.02", "\ud83c\udfa5 Comparing train and test errors", "Bias versus variance trade-off", "Module overview", "Overfitting and underfitting", "Main take-away", "Validation and learning curves", "\ud83c\udfc1 Wrap-up quiz 2", "\u2705 Quiz M2.01", "\ud83c\udfa5 Overfitting and Underfitting", "Tabular data exploration", "\u2705 Quiz M1.01", "Fitting a scikit-learn model on numerical data", "\u2705 Quiz M1.02", "\ud83c\udfa5 Validation of a model", "Handling categorical data", "\u2705 Quiz M1.03", "\ud83c\udfa5 Visualizing scikit-learn pipelines in Jupyter", "Module overview", "Main take-away", "\ud83c\udfc1 Wrap-up quiz 1", "First look at our dataset", "\ud83d\udcdd Exercise M1.01", "\ud83d\udcc3 Solution for Exercise M1.01", "Model evaluation using cross-validation", "\ud83d\udcdd Exercise M1.02", "\ud83d\udcdd Exercise M1.03", "Working with numerical data", "First model with scikit-learn", "Preprocessing for numerical features", "\ud83d\udcc3 Solution for Exercise M1.02", "\ud83d\udcc3 Solution for Exercise M1.03", "Encoding of categorical variables", "Using numerical and categorical variables together", "\ud83d\udcdd Exercise M1.04", "\ud83d\udcdd Exercise M1.05", "\ud83d\udcc3 Solution for Exercise M1.04", "\ud83d\udcc3 Solution for Exercise M1.05", "Visualizing scikit-learn pipelines in Jupyter", "Comparing model performance with a simple baseline", "\ud83d\udcdd Exercise M2.01", "\ud83d\udcdd Exercise M7.01", "Sample grouping", "Effect of the sample size in cross-validation", "Nested cross-validation", "\ud83d\udcc3 Solution for Exercise M2.01", "\ud83d\udcc3 Solution for Exercise M7.01", "Stratification", "Non i.i.d. data", "Cross-validation framework", "Overfit-generalization-underfit", "The Ames housing dataset", "The bike rides dataset", "The blood transfusion dataset", "The California housing dataset", "Feature importance", "Adaptive Boosting (AdaBoost)", "Bagging", "\ud83d\udcdd Exercise M6.01", "\ud83d\udcdd Exercise M6.02", "\ud83d\udcdd Exercise M6.03", "\ud83d\udcdd Exercise M6.04", "Gradient-boosting decision tree (GBDT)", "Speeding-up gradient-boosting", "Hyperparameter tuning", "Introductory example to ensemble models", "Random forests", "\ud83d\udcc3 Solution for Exercise M6.01", "\ud83d\udcc3 Solution for Exercise M6.02", "\ud83d\udcc3 Solution for Exercise M6.03", "\ud83d\udcc3 Solution for Exercise M6.04", "\ud83d\udcdd Exercise 01", "Benefits of using feature selection", "Limitation of selecting feature using a model", "\ud83d\udcc3 Solution for Exercise 01", "\ud83d\udcdd Exercise M4.01", "\ud83d\udcdd Exercise M4.02", "\ud83d\udcdd Exercise M4.03", "Regularization of linear regression model", "\ud83d\udcc3 Solution for Exercise M4.01", "\ud83d\udcc3 Solution for Exercise M4.02", "\ud83d\udcc3 Solution for Exercise M4.03", "Linear regression using scikit-learn", "Linear regression for a non-linear features-target relationship", "Linear regression without scikit-learn", "Linear model for classification", "Beyond linear separation in classification", "Classification", "\ud83d\udcdd Exercise M7.02", "\ud83d\udcdd Exercise M7.03", "Regression", "\ud83d\udcc3 Solution for Exercise M7.02", "\ud83d\udcc3 Solution for Exercise M7.03", "\ud83d\udcdd Exercise M3.01", "\ud83d\udcdd Exercise M3.02", "Hyperparameter tuning by grid-search", "Set and get hyperparameters in scikit-learn", "Evaluation and hyperparameter tuning", "Analysis of hyperparameter search results", "Hyperparameter tuning by randomized-search", "\ud83d\udcc3 Solution for Exercise M3.01", "\ud83d\udcc3 Solution for Exercise M3.02", "Build a classification decision tree", "The penguins datasets", "\ud83d\udcdd Exercise M5.01", "\ud83d\udcdd Exercise M5.02", "Importance of decision tree hyperparameters on generalization", "Decision tree for regression", "\ud83d\udcc3 Solution for Exercise M5.01", "\ud83d\udcc3 Solution for Exercise M5.02", "Table of contents", "\ud83c\udfa5 Intuitions on tree-based models", "Decision tree in classification", "Hyperparameters of decision tree", "Intuitions on tree-based models", "Module overview", "Main take-away", "\u2705 Quiz M5.01", "\u2705 Quiz M5.02", "\u2705 Quiz M5.03", "\u2705 Quiz M5.04", "Decision tree in regression", "\ud83c\udfc1 Wrap-up quiz 5", "Automated tuning", "\u2705 Quiz M3.02", "Manual tuning", "\u2705 Quiz M3.01", "Module overview", "Main take-away", "\ud83c\udfa5 Analysis of hyperparameter search results", "\ud83c\udfc1 Wrap-up quiz 3"], "terms": {"The": [0, 2, 3, 13, 18, 22, 33, 36, 37, 39, 43, 45, 46, 49, 51, 58, 60, 62, 68, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 110, 111, 112, 113, 114, 115, 116, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 170, 172, 174, 177, 182, 183, 185], "diagram": [0, 3, 84], "present": [0, 8, 9, 13, 22, 23, 29, 34, 39, 48, 49, 50, 52, 54, 56, 58, 64, 69, 73, 75, 76, 83, 87, 94, 98, 102, 103, 105, 106, 107, 108, 109, 111, 112, 117, 118, 120, 121, 128, 137, 139, 142, 143, 145, 146, 152, 154, 158, 162, 166, 170, 171, 172], "api": [0, 6, 74, 80, 83, 85, 88, 140, 142, 157, 162, 163], "design": [0, 6, 36, 82, 106, 138, 145], "modul": [0, 1, 14, 18, 23, 34, 36, 40, 60, 74, 76, 82, 88, 109, 142, 150, 151, 152, 159, 163, 165, 171, 183], "predict": [0, 1, 13, 16, 18, 22, 23, 24, 25, 29, 33, 36, 39, 40, 42, 44, 49, 51, 53, 58, 60, 62, 63, 68, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 88, 89, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 145, 147, 149, 151, 153, 156, 157, 158, 160, 161, 162, 163, 164, 170, 174, 177, 181, 182, 185], "model": [0, 1, 10, 11, 13, 14, 15, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 49, 53, 55, 58, 60, 62, 63, 66, 68, 71, 73, 74, 75, 76, 78, 80, 81, 82, 85, 86, 87, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 126, 127, 129, 131, 132, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 156, 157, 160, 161, 162, 164, 170, 171, 177, 179, 181, 182, 183, 185], "pipelin": [0, 1, 3, 13, 22, 33, 34, 36, 39, 44, 49, 52, 58, 62, 68, 70, 73, 74, 75, 79, 84, 88, 89, 91, 95, 96, 97, 99, 100, 101, 102, 106, 109, 110, 118, 121, 126, 127, 128, 129, 131, 132, 133, 135, 136, 138, 140, 141, 148, 149, 150, 151, 152, 154, 155, 156, 170, 179, 181, 182, 185], "us": [0, 14, 17, 18, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 49, 51, 58, 62, 66, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 172, 173, 177, 179, 182, 185], "follow": [0, 3, 13, 14, 17, 18, 22, 23, 27, 29, 33, 34, 40, 45, 49, 51, 58, 60, 62, 68, 71, 73, 74, 75, 76, 80, 83, 84, 85, 87, 88, 95, 96, 97, 99, 100, 101, 103, 110, 112, 116, 117, 119, 121, 125, 132, 133, 135, 136, 137, 138, 139, 141, 142, 145, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 162, 170, 171, 177, 179, 182, 183, 185], "paramet": [0, 6, 15, 18, 26, 27, 28, 29, 37, 40, 43, 45, 46, 49, 55, 58, 60, 62, 68, 75, 79, 80, 81, 82, 84, 85, 86, 87, 89, 91, 95, 99, 100, 101, 104, 105, 110, 111, 112, 113, 115, 116, 119, 120, 121, 122, 124, 125, 128, 132, 136, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 162, 163, 170, 177, 179, 181, 182, 185], "free": [0, 6, 36, 87, 116, 119, 125, 133, 185], "icon": [0, 36], "licens": [0, 36], "under": [0, 24, 29, 36, 40, 76, 95, 100, 105, 120, 141, 142, 145, 161, 170], "cc": [0, 36], "BY": [0, 36], "3": [0, 4, 18, 29, 36, 43, 49, 58, 62, 75, 76, 78, 82, 83, 84, 85, 86, 87, 93, 94, 95, 97, 99, 100, 101, 102, 104, 106, 107, 108, 109, 111, 112, 116, 117, 118, 119, 120, 122, 123, 125, 127, 128, 131, 133, 135, 138, 139, 140, 142, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 170, 177, 182], "0": [0, 3, 4, 18, 29, 37, 49, 68, 75, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 177, 179, 185], "sourc": [0, 119], "set": [0, 6, 18, 26, 29, 35, 37, 39, 40, 42, 45, 46, 53, 55, 58, 60, 62, 63, 66, 68, 75, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 152, 154, 155, 156, 157, 158, 161, 162, 165, 175, 177, 179, 180, 181, 182, 185], "gear": 0, "svg": 0, "vector": [0, 43, 44, 95, 100, 102, 104, 117, 126, 129, 130, 134, 138, 140, 141, 142, 157, 162, 163], "cc0": 0, "close": [0, 3, 29, 45, 51, 76, 84, 99, 102, 103, 104, 109, 110, 117, 124, 125, 133, 137, 138, 145, 150, 152, 154, 157], "mit": 0, "thi": [1, 13, 14, 18, 22, 23, 27, 29, 33, 34, 36, 39, 40, 44, 49, 51, 52, 58, 60, 62, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 174, 177, 179, 182, 183, 185], "collect": [1, 3, 6, 29, 76, 79, 96, 101, 104, 120, 127, 147], "inform": [1, 6, 24, 29, 49, 76, 79, 83, 87, 88, 94, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 117, 119, 120, 127, 128, 133, 138, 140, 142, 143, 146, 150, 151, 154, 156, 158], "relat": [1, 3, 14, 18, 23, 34, 40, 58, 60, 74, 76, 88, 138, 142, 171, 182, 183], "person": [1, 6, 66, 76, 82, 108, 142, 150], "task": [1, 6, 76, 82, 93, 104, 108, 140, 172], "whether": [1, 3, 25, 66, 75, 76, 79, 84, 88, 90, 92, 93, 95, 100, 104, 105, 108, 110, 142, 147, 150, 152, 156, 160, 161, 164], "earn": [1, 76, 150], "salari": [1, 66, 109], "abov": [1, 3, 6, 18, 29, 49, 75, 76, 80, 84, 85, 93, 99, 102, 104, 105, 109, 110, 112, 117, 118, 130, 133, 134, 139, 140, 141, 142, 143, 145, 146, 150, 152, 156, 158, 160, 162, 163, 164, 177, 179, 185], "below": [1, 3, 18, 49, 62, 79, 86, 87, 93, 109, 110, 118, 124, 130, 134, 139, 142, 145, 154, 157, 158, 160, 163, 164, 177, 179, 181, 185], "50": [1, 4, 18, 29, 33, 62, 76, 80, 82, 84, 85, 94, 101, 102, 103, 104, 105, 106, 107, 108, 109, 115, 117, 118, 119, 120, 121, 124, 133, 145, 150, 151, 153, 154], "k": [1, 3, 25, 62, 79, 82, 83, 84, 94, 98, 104, 105, 111, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 127, 128, 129, 145, 147, 149, 150, 152, 153, 156, 157, 162, 163, 182], "we": [1, 3, 13, 14, 18, 22, 23, 25, 28, 29, 33, 34, 37, 39, 40, 43, 49, 51, 55, 58, 60, 62, 66, 68, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 170, 171, 177, 179, 181, 182, 185], "extens": [1, 104], "explor": [1, 6, 49, 77, 78, 82, 84, 87, 100, 114, 116, 123, 125, 133, 138, 149, 150, 152, 153, 154, 156, 165, 185], "first": [1, 8, 9, 29, 48, 50, 52, 54, 56, 58, 64, 65, 66, 67, 69, 73, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 152, 158, 160, 161, 162, 164, 165, 166, 182], "sequenc": [1, 87, 117, 148, 155], "tabular": [1, 6, 66, 73, 76, 83, 88, 165], "data": [1, 18, 20, 22, 23, 24, 25, 28, 29, 36, 39, 40, 45, 49, 60, 62, 68, 71, 73, 74, 75, 77, 78, 80, 81, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 173, 177, 179, 182, 185], "notebook": [1, 18, 23, 36, 49, 66, 75, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 124, 127, 128, 131, 133, 135, 137, 139, 140, 141, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 162, 163, 164, 165, 179], "look": [1, 6, 29, 49, 65, 66, 68, 77, 78, 80, 82, 83, 85, 87, 97, 98, 100, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 119, 132, 133, 136, 138, 139, 141, 142, 150, 157, 158, 165, 179, 185], "our": [1, 6, 18, 25, 29, 43, 49, 65, 66, 73, 79, 81, 82, 83, 84, 86, 88, 89, 91, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 115, 116, 117, 119, 124, 125, 126, 127, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 145, 146, 151, 153, 157, 158, 162, 164, 165, 185], "To": [1, 3, 8, 9, 29, 37, 48, 49, 50, 52, 54, 56, 64, 69, 75, 76, 82, 83, 84, 88, 89, 91, 95, 97, 98, 99, 100, 102, 103, 104, 105, 110, 111, 112, 115, 118, 119, 124, 127, 133, 137, 138, 141, 142, 145, 154, 156, 159, 162, 163, 166, 177], "avoid": [1, 3, 6, 40, 75, 76, 99, 110, 111, 112, 115, 123, 124, 129, 131, 135, 137, 150, 153, 154, 156], "repeat": [1, 3, 18, 29, 49, 60, 62, 79, 81, 86, 89, 91, 97, 98, 99, 102, 104, 127, 141, 143, 146, 149, 156, 157, 159, 160, 162, 163, 164, 185], "same": [1, 18, 26, 29, 37, 40, 45, 49, 68, 76, 81, 82, 83, 84, 86, 87, 88, 92, 97, 98, 99, 101, 102, 104, 105, 106, 110, 111, 112, 117, 118, 127, 130, 131, 133, 134, 135, 137, 138, 139, 141, 142, 145, 147, 153, 154, 162, 177, 185], "redirect": 1, "reader": [1, 76, 112, 138, 140, 145], "particular": [1, 3, 6, 27, 73, 76, 79, 80, 82, 83, 85, 88, 92, 94, 99, 100, 104, 121, 142, 145, 150, 152, 153, 156], "penguin": [2, 18, 77, 78, 111, 114, 123, 130, 131, 132, 134, 135, 136, 137, 139, 140, 157, 159, 160, 162, 163, 164, 165, 185], "adult": [2, 49, 66, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 101, 121, 148, 150, 151, 152, 154, 155, 165], "censu": [2, 49, 66, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 101, 104, 109, 121, 148, 150, 151, 152, 154, 155, 165], "california": [2, 94, 104, 106, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 165], "hous": [2, 3, 51, 75, 93, 94, 98, 104, 105, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 133, 144, 145, 147, 165], "am": [2, 133, 144, 145, 147, 165], "blood": [2, 95, 100, 142, 143, 146, 165], "transfus": [2, 95, 100, 142, 143, 146, 165], "bike": [2, 29, 165], "ride": [2, 29, 165], "aim": [3, 36, 82, 95, 100, 103, 104, 111, 113, 114, 115, 116, 120, 122, 123, 124, 125, 126, 127, 129, 130, 131, 134, 135, 142, 143, 146, 159, 160, 163, 164], "describ": [3, 71, 82, 83, 84, 94, 109, 185], "For": [3, 6, 36, 49, 55, 60, 73, 76, 79, 82, 83, 84, 87, 88, 93, 94, 97, 99, 101, 104, 105, 107, 109, 110, 114, 115, 117, 119, 121, 123, 124, 126, 127, 128, 129, 131, 133, 135, 138, 139, 140, 142, 145, 147, 150, 151, 152, 154, 161, 164, 173, 177, 182], "you": [3, 6, 14, 18, 23, 29, 34, 36, 40, 49, 52, 60, 62, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 104, 105, 107, 109, 110, 111, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 171, 175, 177, 179, 181, 183, 185], "don": [3, 6, 80, 85, 95, 100, 104, 108, 126, 129, 133, 150], "t": [3, 6, 80, 85, 87, 95, 97, 100, 103, 104, 108, 110, 118, 125, 126, 129, 133, 142, 145, 146, 150], "find": [3, 6, 51, 60, 76, 82, 83, 84, 87, 95, 96, 99, 100, 101, 103, 105, 113, 114, 116, 122, 123, 125, 128, 129, 132, 133, 136, 137, 141, 148, 149, 150, 152, 154, 155, 156, 159, 160, 163, 164, 170, 179], "ad": [3, 18, 40, 55, 95, 98, 100, 110, 115, 119, 121, 124, 138, 141, 150, 154], "bottom": [3, 76, 142], "page": [3, 36, 82, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "type": [3, 14, 23, 29, 44, 52, 73, 74, 76, 82, 83, 89, 90, 91, 92, 104, 106, 107, 108, 109, 112, 126, 129, 132, 136, 140, 142, 145, 157, 162, 163, 177], "problem": [3, 15, 18, 22, 29, 39, 40, 45, 49, 51, 52, 58, 62, 66, 75, 76, 81, 86, 87, 89, 91, 93, 95, 97, 100, 101, 102, 104, 107, 108, 109, 117, 127, 133, 137, 138, 139, 140, 142, 145, 150, 152, 153, 156, 157, 158, 161, 162, 170, 171, 177, 185], "where": [3, 6, 29, 40, 43, 44, 46, 49, 62, 71, 75, 79, 84, 89, 91, 95, 97, 100, 102, 104, 109, 110, 115, 121, 124, 127, 133, 139, 140, 141, 145, 150, 152, 154, 156, 157, 161, 179, 185], "goal": [3, 25, 36, 76, 79, 80, 81, 85, 86, 89, 90, 91, 92, 93, 97, 119, 120, 121, 127, 145, 148, 149, 155, 156, 185], "can": [3, 6, 14, 15, 18, 22, 23, 28, 29, 34, 36, 39, 40, 45, 49, 55, 58, 60, 62, 68, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 171, 172, 174, 177, 179, 182, 183, 185], "take": [3, 16, 29, 76, 79, 82, 83, 84, 88, 92, 94, 96, 97, 99, 101, 103, 104, 106, 107, 108, 109, 112, 130, 134, 139, 142, 150, 153, 154, 165, 177, 179], "finit": [3, 66, 71, 76, 87], "valu": [3, 13, 15, 18, 24, 28, 29, 36, 37, 40, 42, 45, 49, 51, 62, 66, 68, 71, 75, 76, 80, 82, 85, 87, 88, 89, 91, 94, 97, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 173, 174, 177, 179, 181, 182, 185], "exampl": [3, 6, 11, 14, 23, 34, 40, 51, 60, 73, 74, 76, 79, 81, 84, 86, 87, 88, 93, 94, 97, 102, 103, 107, 111, 112, 118, 121, 127, 133, 134, 138, 139, 141, 145, 147, 150, 151, 161, 165, 171, 182, 183], "ar": [3, 13, 14, 15, 16, 17, 18, 22, 23, 25, 27, 28, 29, 33, 34, 36, 37, 39, 40, 44, 49, 51, 55, 58, 60, 62, 68, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 125, 127, 128, 129, 131, 133, 134, 135, 137, 138, 139, 140, 141, 142, 145, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 161, 162, 163, 164, 170, 171, 173, 177, 179, 181, 182, 183, 185], "iri": [3, 102], "setosa": 3, "versicolor": 3, "virginica": 3, "from": [3, 6, 14, 18, 24, 25, 29, 36, 37, 45, 49, 51, 58, 60, 62, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 172, 174, 177, 179, 181, 182, 185], "petal": 3, "sepal": 3, "measur": [3, 6, 18, 29, 68, 77, 78, 79, 82, 107, 110, 124, 127, 130, 134, 139, 142, 152, 157, 158], "patient": [3, 6, 25, 131, 135], "ha": [3, 25, 37, 44, 45, 49, 66, 73, 75, 76, 78, 82, 84, 86, 87, 88, 92, 97, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 118, 119, 124, 131, 133, 135, 137, 139, 142, 143, 145, 146, 149, 151, 154, 156, 157, 158, 163, 177, 179, 185], "diseas": [3, 6, 25, 76, 131, 135], "result": [3, 29, 68, 76, 79, 81, 82, 83, 84, 86, 87, 88, 91, 92, 94, 96, 97, 99, 101, 102, 103, 104, 112, 115, 116, 117, 119, 120, 121, 124, 125, 126, 127, 128, 129, 131, 133, 135, 137, 138, 142, 145, 150, 151, 152, 154, 156, 157, 163, 165, 178, 179, 181, 185], "medic": [3, 6, 25, 76], "an": [3, 16, 22, 23, 26, 28, 35, 36, 40, 43, 44, 49, 51, 53, 55, 58, 60, 71, 73, 74, 75, 76, 79, 83, 84, 86, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 107, 108, 109, 110, 112, 115, 117, 118, 119, 120, 121, 124, 126, 127, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 147, 148, 150, 151, 152, 155, 156, 157, 161, 162, 163, 170, 173, 177, 179, 181, 182, 183, 185], "email": 3, "spam": 3, "content": [3, 82, 88, 106, 147, 150], "sender": 3, "titl": [3, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 124, 125, 127, 128, 133, 136, 137, 139, 140, 141, 142, 146, 153, 157, 161, 162, 163, 164], "etc": [3, 25, 29, 36, 76, 87, 99, 107, 120, 131, 135], "when": [3, 6, 16, 17, 18, 22, 23, 27, 28, 29, 35, 40, 45, 55, 60, 62, 68, 75, 76, 79, 82, 83, 84, 87, 88, 89, 91, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 110, 111, 115, 117, 118, 119, 121, 124, 125, 126, 127, 128, 129, 133, 135, 137, 139, 140, 141, 142, 147, 150, 151, 152, 154, 157, 158, 174, 179, 182, 183], "have": [3, 25, 29, 43, 51, 55, 60, 62, 68, 71, 76, 79, 81, 82, 83, 84, 86, 87, 91, 94, 98, 99, 102, 103, 104, 106, 107, 108, 109, 110, 111, 114, 117, 118, 119, 120, 121, 123, 124, 126, 127, 129, 133, 134, 138, 139, 140, 141, 142, 145, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 161, 162, 163, 170, 177, 179, 182, 183, 185], "two": [3, 13, 14, 29, 37, 49, 66, 68, 75, 76, 77, 78, 82, 83, 84, 87, 88, 97, 99, 101, 102, 104, 105, 106, 108, 110, 117, 119, 120, 127, 128, 129, 130, 133, 134, 137, 138, 140, 141, 142, 148, 150, 152, 153, 154, 155, 156, 157, 158, 160, 162, 163, 164, 177, 185], "call": [3, 13, 14, 29, 45, 46, 60, 62, 68, 71, 75, 76, 82, 83, 84, 87, 88, 89, 91, 94, 95, 98, 100, 101, 104, 105, 108, 111, 117, 118, 119, 120, 121, 129, 131, 133, 135, 137, 138, 139, 142, 143, 145, 146, 147, 148, 150, 151, 152, 154, 155, 157, 162, 163, 182], "binari": [3, 6, 42, 62, 76, 93, 101, 140, 142, 172, 185], "case": [3, 29, 33, 51, 76, 79, 82, 84, 87, 88, 90, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 110, 117, 119, 121, 126, 129, 131, 133, 135, 139, 141, 142, 143, 145, 146, 147, 149, 151, 152, 154, 156, 157], "least": [3, 102, 119, 161, 185], "three": [3, 79, 88, 101, 102, 105, 109, 110, 111, 114, 123, 157, 158], "multi": [3, 127, 131, 135, 153], "class": [3, 15, 25, 27, 43, 49, 62, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 106, 107, 108, 109, 110, 111, 112, 118, 121, 132, 133, 136, 138, 139, 140, 141, 143, 146, 147, 148, 150, 151, 152, 154, 155, 157, 159, 161, 163, 173, 185], "illustr": [3, 33, 60, 79, 83, 84, 87, 96, 99, 101, 102, 104, 110, 121, 138, 141, 142, 152, 157, 158, 161, 162], "provid": [3, 37, 82, 84, 87, 88, 104, 107, 109, 113, 116, 117, 118, 122, 125, 129, 133, 136, 137, 139, 140, 141, 142, 143, 146, 147, 150, 152, 185], "user": [3, 6, 79, 88, 93, 105, 119, 120, 121, 133, 145, 150, 154, 182, 185], "contain": [3, 18, 29, 44, 49, 62, 66, 68, 75, 76, 79, 82, 83, 87, 88, 89, 91, 97, 102, 106, 107, 108, 109, 114, 121, 123, 126, 128, 129, 133, 138, 139, 140, 141, 142, 150, 154, 160, 162, 164, 177, 185], "2": [3, 4, 18, 28, 29, 37, 43, 44, 51, 68, 73, 76, 78, 79, 82, 83, 84, 85, 87, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 115, 117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 129, 131, 133, 134, 135, 138, 139, 140, 141, 142, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 165, 177, 185], "repres": [3, 6, 66, 68, 71, 75, 76, 82, 83, 84, 87, 88, 102, 106, 108, 110, 117, 118, 130, 133, 134, 138, 139, 140, 141, 142, 145, 157], "x": [3, 24, 28, 29, 43, 44, 68, 76, 82, 83, 84, 107, 109, 110, 111, 112, 117, 123, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 149, 150, 153, 156, 157, 158, 161, 162, 163, 164, 179], "y": [3, 28, 29, 43, 68, 76, 82, 83, 84, 102, 109, 110, 111, 112, 117, 123, 130, 134, 136, 137, 138, 139, 140, 141, 145, 153, 157, 158, 161, 162, 163, 164, 179], "axi": [3, 18, 29, 78, 94, 101, 102, 106, 109, 110, 112, 125, 127, 128, 133, 136, 138, 139, 141, 142, 145, 150, 153, 154, 156, 157, 161, 179], "becaus": [3, 6, 18, 76, 79, 80, 83, 84, 85, 87, 88, 89, 91, 101, 102, 103, 104, 105, 110, 112, 121, 124, 127, 133, 138, 143, 145, 146, 147, 151, 152, 154, 156, 158, 162], "onli": [3, 6, 18, 29, 37, 43, 49, 51, 66, 68, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 104, 107, 108, 111, 117, 119, 121, 127, 129, 131, 132, 133, 135, 136, 139, 140, 141, 142, 143, 145, 146, 150, 151, 152, 156, 161, 174, 177, 181, 183], "here": [3, 29, 62, 76, 77, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 94, 95, 96, 100, 103, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 126, 128, 129, 130, 131, 132, 133, 134, 138, 140, 141, 142, 143, 144, 148, 149, 150, 151, 152, 155, 158, 159, 160, 162], "encod": [3, 6, 29, 49, 70, 71, 82, 88, 89, 91, 106, 107, 109, 118, 121, 133, 140, 165, 177], "color": [3, 76, 99, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 137, 138, 139, 140, 142, 146, 153, 156, 161, 162, 164, 179], "blue": [3, 76, 79, 97, 104, 111, 112, 136, 140, 141, 142, 152, 157, 161, 163], "orang": [3, 76, 112, 117, 142, 162], "point": [3, 6, 15, 76, 80, 82, 84, 85, 92, 97, 102, 107, 108, 109, 110, 112, 118, 119, 121, 124, 133, 138, 140, 141, 142, 145, 152, 154, 157, 161], "thu": [3, 6, 29, 37, 63, 82, 84, 88, 95, 97, 99, 100, 103, 104, 105, 107, 108, 109, 110, 111, 115, 118, 119, 120, 121, 124, 126, 129, 133, 136, 139, 140, 141, 145, 150, 151, 152, 153, 156, 157, 161, 162, 177], "each": [3, 6, 18, 25, 29, 36, 40, 49, 51, 68, 71, 76, 77, 78, 79, 82, 83, 84, 87, 88, 96, 97, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 130, 133, 134, 138, 139, 140, 142, 148, 150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 164, 173, 177, 179, 185], "entir": [3, 35, 79, 87, 88, 108, 109, 119, 124, 126, 129, 177], "wa": [3, 76, 83, 84, 92, 93, 97, 99, 100, 102, 104, 106, 109, 111, 112, 117, 121, 127, 130, 133, 134, 138, 142, 152, 157, 159, 162, 163], "linear": [3, 6, 13, 15, 16, 29, 37, 39, 40, 42, 43, 44, 45, 49, 55, 60, 76, 82, 84, 87, 88, 89, 90, 91, 92, 95, 97, 100, 109, 112, 120, 128, 130, 131, 134, 135, 144, 145, 147, 151, 157, 158, 160, 162, 164, 172, 174, 177, 182], "decis": [3, 6, 10, 13, 15, 16, 18, 27, 35, 43, 60, 84, 88, 90, 92, 94, 98, 103, 104, 105, 111, 112, 114, 115, 118, 120, 121, 122, 123, 124, 128, 132, 136, 138, 140, 141, 142, 143, 146, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177], "rule": [3, 82, 83, 120, 133, 140, 173], "black": [3, 76, 82, 87, 94, 97, 99, 101, 104, 105, 106, 107, 108, 109, 111, 112, 117, 123, 125, 127, 128, 133, 134, 137, 138, 139, 146, 150, 154, 157, 161, 162, 163, 164], "dot": 3, "line": [3, 29, 44, 71, 76, 82, 110, 112, 117, 131, 135, 138, 140, 141, 142, 143, 145, 146, 153, 154, 157, 161, 162, 163, 179, 185], "new": [3, 6, 29, 36, 40, 76, 80, 82, 83, 84, 85, 87, 88, 89, 91, 95, 96, 97, 98, 100, 101, 103, 104, 110, 111, 114, 115, 117, 119, 123, 124, 131, 135, 138, 142, 148, 150, 151, 155, 160, 162, 163, 164], "accord": [3, 76], "its": [3, 6, 18, 23, 29, 49, 60, 63, 76, 81, 83, 84, 86, 87, 88, 95, 99, 100, 101, 103, 104, 105, 110, 113, 117, 119, 121, 122, 127, 133, 137, 139, 142, 143, 145, 146, 149, 156, 157, 179], "posit": [3, 6, 27, 28, 29, 45, 49, 68, 105, 110, 112, 120, 133, 139, 142, 143, 145, 146, 154, 185], "respect": [3, 29, 43, 44, 87, 88, 92, 95, 100, 101, 103, 105, 119, 121, 133, 145, 147], "ly": [3, 133], "left": [3, 75, 76, 83, 94, 97, 101, 102, 103, 107, 109, 110, 111, 112, 117, 119, 120, 123, 129, 134, 136, 142, 152, 153, 157, 161, 163], "while": [3, 18, 29, 82, 83, 84, 87, 100, 104, 105, 107, 109, 110, 111, 112, 117, 118, 119, 121, 124, 127, 129, 133, 141, 142, 145, 153, 156, 161, 177], "right": [3, 76, 77, 78, 82, 87, 89, 91, 101, 110, 119, 124, 126, 129, 142, 152, 161], "defin": [3, 18, 29, 36, 49, 58, 68, 75, 79, 87, 88, 89, 91, 93, 96, 97, 101, 102, 103, 110, 111, 116, 125, 130, 131, 133, 134, 135, 138, 139, 141, 142, 148, 149, 150, 153, 154, 155, 156, 157, 159, 163, 177, 179, 181, 182, 185], "higher": [3, 6, 27, 39, 44, 85, 86, 88, 99, 104, 106, 107, 110, 111, 120, 133, 137, 147, 152, 179], "dimens": [3, 44, 76, 156], "would": [3, 18, 29, 51, 76, 79, 81, 82, 83, 86, 87, 89, 91, 99, 100, 101, 102, 103, 104, 106, 108, 109, 110, 112, 117, 118, 119, 121, 124, 127, 131, 133, 135, 137, 138, 139, 140, 142, 143, 145, 146, 149, 152, 156, 157, 161, 162], "hyperplan": 3, "howev": [3, 6, 22, 36, 82, 83, 84, 87, 88, 90, 92, 94, 97, 99, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 115, 117, 118, 119, 120, 121, 124, 126, 127, 129, 133, 134, 137, 138, 140, 142, 143, 145, 146, 147, 152, 154, 156, 157, 161, 162, 182], "shape": [3, 43, 44, 76, 82, 83, 87, 106, 107, 109, 110, 111, 112, 138, 145, 162], "depend": [3, 18, 22, 27, 28, 29, 37, 40, 79, 84, 87, 88, 99, 101, 103, 109, 110, 112, 119, 127, 131, 133, 135, 136, 142, 147, 150, 154, 158], "A": [3, 6, 29, 36, 45, 55, 63, 66, 68, 76, 84, 88, 97, 99, 103, 104, 109, 118, 119, 133, 137, 138, 142, 145, 156, 162, 172, 173, 177, 183], "These": [3, 6, 23, 76, 79, 83, 87, 106, 121, 142, 151, 157, 162, 182], "handl": [3, 73, 74, 82, 87, 88, 92, 106, 117, 138, 150, 165], "discret": [3, 87, 104, 108, 118, 140, 145], "1": [3, 4, 18, 27, 29, 43, 44, 46, 49, 51, 62, 68, 76, 78, 79, 82, 83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 165, 177, 179, 185], "cat": [3, 93], "dog": 3, "scikit": [3, 13, 14, 22, 23, 24, 27, 28, 33, 34, 37, 38, 39, 40, 43, 46, 58, 60, 62, 66, 68, 70, 73, 74, 79, 80, 82, 84, 85, 87, 88, 89, 91, 96, 101, 102, 104, 109, 111, 114, 116, 118, 121, 123, 125, 126, 129, 132, 133, 136, 138, 140, 142, 143, 145, 146, 147, 150, 152, 165, 170, 171, 173, 174, 180, 182, 183, 185], "logisticregress": [3, 45, 46, 49, 75, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 97, 101, 102, 129, 132, 136, 140, 142, 147, 151, 157, 179, 181], "histgradientboostingclassifi": [3, 88, 90, 92, 118, 148, 150, 152, 153, 154, 155], "note": [3, 8, 9, 36, 48, 49, 50, 52, 54, 56, 64, 69, 76, 79, 82, 83, 84, 87, 88, 92, 94, 95, 99, 100, 101, 104, 105, 108, 109, 110, 112, 120, 121, 138, 139, 150, 151, 152, 156, 157, 162, 166, 177], "histor": 3, "reason": [3, 6, 18, 49, 60, 76, 78, 84, 90, 92, 99, 103, 104, 107, 110, 117, 119, 129, 142, 156], "name": [3, 15, 29, 49, 62, 76, 78, 82, 83, 84, 85, 86, 87, 88, 94, 95, 100, 101, 102, 104, 106, 107, 108, 109, 110, 112, 117, 119, 122, 125, 133, 139, 142, 150, 151, 153, 154, 181, 185], "confus": [3, 117, 151, 162, 182], "contrari": [3, 76, 87, 104, 110, 162], "what": [3, 6, 15, 24, 27, 28, 29, 35, 42, 44, 49, 51, 52, 60, 62, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 88, 96, 99, 101, 102, 103, 104, 105, 110, 120, 121, 135, 137, 139, 141, 142, 151, 152, 157, 162, 177, 179], "suggest": 3, "procedur": [3, 6, 18, 49, 79, 82, 99, 103, 104, 112, 119, 121, 124, 127, 128, 138, 152, 156, 172, 179, 181], "how": [3, 18, 22, 23, 26, 29, 33, 34, 39, 43, 49, 58, 60, 66, 71, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 93, 94, 98, 100, 102, 103, 105, 110, 111, 112, 117, 119, 121, 133, 135, 137, 142, 143, 146, 150, 151, 152, 153, 154, 156, 157, 159, 161, 162, 163, 170, 175, 179, 181, 182], "well": [3, 6, 13, 15, 22, 68, 78, 84, 97, 101, 102, 105, 108, 109, 110, 111, 112, 117, 119, 120, 128, 142, 151, 161], "idea": [3, 76, 93, 100, 110, 117, 152], "behind": [3, 6, 13, 22, 120], "dataset": [3, 16, 18, 25, 29, 35, 37, 39, 40, 42, 44, 49, 55, 58, 62, 65, 66, 68, 71, 73, 75, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 177, 179, 185], "evalu": [3, 18, 22, 23, 26, 29, 37, 45, 49, 58, 62, 67, 68, 76, 81, 82, 83, 86, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102, 103, 104, 108, 110, 112, 113, 115, 117, 118, 122, 124, 128, 129, 133, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 162, 177, 178, 182, 185], "separ": [3, 29, 41, 42, 45, 66, 76, 78, 81, 82, 86, 88, 101, 106, 107, 108, 136, 140, 152, 157, 161, 165, 173, 177], "sever": [3, 13, 16, 23, 68, 79, 97, 99, 104, 110, 111, 112, 115, 117, 118, 120, 121, 124, 130, 134, 138, 141, 154], "time": [3, 18, 29, 49, 68, 76, 79, 82, 84, 87, 88, 89, 90, 91, 92, 93, 97, 99, 102, 103, 104, 105, 107, 108, 110, 112, 115, 117, 118, 119, 120, 121, 124, 127, 133, 140, 142, 150, 153, 154, 157, 159, 163, 165, 172, 177], "differ": [3, 6, 15, 16, 18, 22, 25, 29, 37, 45, 49, 55, 60, 62, 66, 68, 71, 76, 77, 78, 79, 83, 84, 87, 88, 92, 94, 95, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 129, 130, 133, 134, 137, 138, 143, 145, 146, 147, 149, 151, 152, 153, 154, 156, 157, 158, 161, 162, 177, 185], "get": [3, 6, 18, 34, 42, 49, 55, 62, 68, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 89, 90, 91, 92, 97, 98, 99, 102, 103, 104, 105, 107, 109, 111, 112, 115, 116, 117, 124, 125, 126, 127, 129, 133, 138, 142, 143, 144, 145, 146, 147, 150, 152, 153, 154, 156, 157, 160, 161, 162, 164, 165, 179, 180, 181], "s": [3, 4, 6, 17, 23, 25, 26, 29, 35, 36, 49, 75, 76, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 120, 122, 123, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 145, 147, 150, 151, 152, 153, 154, 157, 158, 161, 162, 182, 185], "uncertainti": [3, 79, 88, 112, 126, 129, 152], "see": [3, 8, 9, 39, 48, 50, 52, 54, 56, 64, 69, 76, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 117, 118, 120, 122, 124, 125, 127, 129, 133, 135, 136, 137, 138, 139, 140, 141, 142, 145, 147, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 162, 163, 166], "document": [3, 4, 6, 15, 62, 80, 82, 83, 84, 85, 87, 89, 91, 94, 96, 97, 101, 138, 142, 143, 144, 146, 147, 151], "more": [3, 18, 29, 36, 55, 58, 62, 76, 79, 82, 83, 84, 87, 89, 91, 92, 94, 95, 98, 99, 100, 101, 105, 106, 107, 109, 110, 111, 112, 117, 118, 119, 120, 121, 127, 131, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 161, 162, 185], "detail": [3, 13, 18, 29, 39, 63, 76, 79, 80, 82, 83, 85, 87, 88, 89, 91, 95, 97, 100, 107, 109, 110, 117, 119, 120, 138, 142, 143, 146, 147, 150, 158, 170, 171, 185], "n_sampl": [3, 112, 117, 127, 128, 138, 141, 161], "row": [3, 18, 62, 66, 76, 87, 93, 104, 106, 109, 112, 133, 138, 150, 153, 154, 156, 185], "n_featur": [3, 44, 119, 121, 127, 128, 138, 141], "column": [3, 6, 18, 29, 37, 43, 44, 49, 62, 66, 71, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 104, 106, 107, 108, 109, 110, 112, 117, 119, 121, 122, 123, 125, 127, 128, 131, 133, 135, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 161, 162, 164, 177, 185], "number": [3, 6, 16, 17, 18, 29, 37, 43, 45, 49, 51, 55, 62, 71, 75, 76, 79, 80, 82, 83, 84, 85, 87, 88, 89, 91, 95, 97, 98, 100, 102, 104, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 121, 124, 125, 127, 128, 129, 133, 134, 138, 142, 144, 145, 147, 149, 150, 152, 153, 154, 156, 161, 162, 172, 177, 179, 183, 185], "equal": [3, 6, 29, 45, 62, 84, 102, 117, 133, 150, 151, 162], "flower": 3, "4": [3, 4, 18, 29, 75, 76, 78, 82, 83, 84, 85, 86, 87, 93, 94, 97, 100, 101, 102, 104, 106, 107, 108, 109, 110, 112, 117, 118, 119, 120, 122, 125, 127, 131, 133, 135, 138, 139, 142, 147, 150, 151, 152, 153, 154, 156, 157, 158, 161, 162, 163, 165, 177], "length": [3, 6, 18, 29, 77, 78, 82, 83, 106, 107, 111, 114, 123, 130, 131, 132, 134, 135, 136, 137, 139, 140, 142, 150, 154, 157, 158, 159, 160, 161, 162, 163, 164, 185], "width": [3, 118], "In": [3, 6, 15, 22, 23, 29, 34, 36, 37, 39, 40, 49, 60, 66, 74, 76, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 116, 117, 118, 119, 120, 121, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 171, 177, 179, 182], "common": [3, 60, 79, 87, 103, 112, 133, 145, 185], "math": [3, 106], "convent": [3, 76, 84, 138], "matric": [3, 87], "capit": [3, 49, 76, 79, 81, 82, 83, 84, 86, 87, 88, 150, 151, 154], "letter": [3, 104, 109], "f": [3, 8, 9, 18, 29, 48, 50, 52, 54, 56, 64, 69, 76, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 102, 103, 104, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 133, 134, 135, 136, 137, 138, 139, 140, 142, 145, 146, 147, 150, 151, 152, 154, 155, 157, 161, 162, 163, 166, 179], "consist": [3, 40, 75, 79, 104, 131, 135, 147], "iter": [3, 29, 68, 79, 84, 87, 102, 103, 104, 115, 119, 124, 133, 152, 153, 154], "optim": [3, 22, 23, 45, 66, 84, 95, 99, 100, 111, 116, 117, 118, 120, 125, 129, 133, 137, 142, 145, 147, 150, 151, 152, 154, 156, 157, 161, 177, 183, 185], "method": [3, 4, 6, 14, 62, 75, 76, 77, 78, 82, 83, 84, 88, 97, 103, 110, 113, 117, 120, 121, 122, 128, 133, 138, 141, 142, 145, 151, 152, 154, 165, 185], "befor": [3, 45, 49, 76, 80, 82, 84, 85, 87, 102, 104, 106, 110, 118, 121, 126, 129, 131, 133, 135, 139, 142, 145, 159, 163], "converg": [3, 68, 84, 87], "algorithm": [3, 13, 16, 18, 24, 35, 76, 83, 84, 87, 97, 110, 111, 115, 117, 118, 119, 121, 124, 126, 127, 129, 131, 135, 138, 140, 157, 158], "over": [3, 15, 24, 29, 39, 40, 76, 95, 97, 99, 100, 103, 105, 110, 114, 118, 120, 123, 145, 148, 150, 155, 157, 159, 161, 163, 170, 173], "done": [3, 6, 75, 83, 91, 118, 119, 121, 129, 133, 151, 152, 157, 161], "monitor": [3, 6, 29], "score": [3, 18, 27, 28, 29, 37, 49, 60, 62, 68, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 109, 110, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 133, 135, 136, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 163, 175, 177, 179, 185], "jargon": 3, "object": [3, 6, 29, 49, 60, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 104, 106, 107, 108, 121, 133, 142, 143, 146, 148, 150, 151, 152, 154, 155, 156, 157, 162, 163, 177], "onc": [3, 6, 18, 29, 82, 84, 92, 97, 102, 104, 112, 119, 121, 140, 142, 144, 147, 148, 149, 150, 153, 154, 155, 156, 159, 163, 179], "quantiti": [3, 6, 87, 88, 107, 110], "e": [3, 6, 18, 29, 49, 62, 66, 68, 71, 73, 74, 75, 76, 82, 83, 84, 86, 87, 88, 91, 97, 98, 99, 102, 103, 104, 110, 117, 118, 119, 120, 127, 131, 133, 135, 136, 137, 140, 142, 145, 147, 148, 150, 154, 155, 156, 177, 179, 181, 185], "g": [3, 6, 18, 29, 76, 87, 88, 97, 99, 103, 110, 114, 119, 120, 123, 127, 130, 131, 133, 134, 135, 137, 139, 140, 148, 150, 154, 155, 156, 158, 160, 161, 162, 164, 177, 185], "size": [3, 51, 58, 60, 61, 87, 94, 95, 100, 107, 109, 111, 112, 119, 129, 157, 165], "weight": [3, 29, 40, 42, 45, 46, 49, 82, 95, 97, 100, 110, 111, 117, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 157, 172], "dure": [3, 13, 22, 25, 29, 33, 34, 39, 40, 58, 60, 74, 75, 76, 82, 87, 89, 91, 102, 104, 107, 111, 120, 127, 133, 137, 143, 146, 150, 152, 154, 157, 160, 162, 164, 170, 171, 182, 183], "four": [3, 107, 108, 142], "never": [3, 18, 58, 76, 82, 83, 87, 111, 112, 145, 150, 154, 179], "seen": [3, 25, 49, 79, 81, 83, 84, 86, 87, 104, 139, 142, 150, 151, 152, 154, 160, 164], "aspect": [3, 6, 22, 34, 79, 84, 98, 128, 133, 172], "configur": [3, 84, 116, 125, 138, 150], "learnt": [3, 60, 98, 110, 138, 157], "nearest": [3, 62, 82, 83, 84, 182, 185], "neighbor": [3, 62, 80, 82, 83, 84, 85, 149, 156, 182, 185], "approach": [3, 6, 14, 23, 34, 40, 60, 74, 87, 102, 118, 137, 150, 152, 154, 156, 171, 183], "polynomi": [3, 44, 55, 112, 138], "sai": [3, 62, 110], "degre": [3, 44, 55, 110, 112, 131, 133, 135, 138], "between": [3, 6, 13, 15, 18, 22, 29, 40, 49, 55, 58, 60, 62, 76, 78, 79, 82, 84, 87, 95, 99, 100, 103, 105, 107, 108, 110, 112, 114, 117, 119, 123, 126, 127, 129, 131, 133, 134, 135, 138, 139, 142, 145, 153, 154, 156, 158, 161, 162, 170, 185], "10": [3, 4, 18, 25, 36, 49, 62, 75, 76, 79, 80, 82, 85, 87, 92, 94, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 112, 115, 118, 119, 120, 122, 124, 129, 131, 132, 133, 135, 136, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 161, 163, 177, 179, 185], "impact": [3, 18, 45, 49, 58, 87, 89, 90, 91, 92, 98, 99, 115, 119, 124, 132, 133, 136, 145, 153, 156, 161, 179, 181, 182, 183, 185], "comput": [3, 6, 29, 49, 62, 68, 76, 79, 80, 83, 84, 85, 87, 88, 90, 92, 94, 95, 96, 98, 99, 100, 101, 102, 104, 105, 110, 111, 112, 115, 117, 118, 119, 120, 124, 126, 127, 129, 131, 134, 135, 137, 138, 139, 142, 143, 144, 145, 146, 147, 149, 152, 153, 154, 156, 157, 159, 162, 163, 179], "inde": [3, 18, 29, 76, 82, 83, 84, 88, 92, 95, 97, 99, 100, 103, 104, 106, 107, 108, 109, 110, 111, 112, 117, 118, 119, 120, 126, 127, 128, 129, 133, 135, 137, 138, 140, 141, 142, 143, 145, 146, 147, 151, 152, 154, 157, 158, 161, 162], "usual": [3, 17, 82, 84, 88, 97, 103, 105, 107, 131, 135, 142, 153, 154], "inspect": [3, 6, 29, 62, 66, 84, 93, 104, 111, 116, 119, 125, 128, 132, 136, 138, 140, 141, 150, 153, 154, 157, 159, 161, 163, 185], "regard": [3, 13, 14, 22, 24, 33, 34, 39, 73, 75, 84, 87, 89, 91, 94, 95, 97, 98, 100, 102, 105, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 155, 157, 159, 160, 161, 162, 163, 164], "tune": [3, 13, 17, 26, 35, 40, 45, 49, 95, 99, 100, 105, 113, 120, 121, 122, 127, 129, 149, 153, 155, 156, 171, 177, 182, 185], "maxim": [3, 49, 97, 99, 133, 147, 148, 149, 150, 154, 155, 156, 175, 182], "It": [3, 6, 29, 36, 60, 76, 80, 83, 84, 85, 87, 88, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 117, 118, 120, 121, 125, 126, 129, 133, 136, 138, 139, 142, 143, 145, 146, 147, 150, 152, 153, 154, 157, 161, 162], "involv": [3, 6, 76, 101, 104, 151], "grid": [3, 99, 107, 116, 119, 120, 125, 133, 149, 152, 154, 156, 161, 165, 175, 177, 178, 179, 183, 185], "search": [3, 49, 98, 99, 116, 118, 119, 120, 121, 122, 125, 133, 137, 148, 149, 152, 155, 156, 161, 165, 175, 177, 178, 179, 182, 183, 185], "random": [3, 11, 13, 14, 15, 17, 18, 37, 49, 53, 82, 97, 101, 102, 103, 104, 107, 109, 110, 112, 114, 115, 117, 118, 120, 123, 124, 126, 127, 128, 129, 138, 149, 150, 153, 156, 165, 173, 178, 179, 183], "some": [3, 6, 18, 22, 23, 29, 33, 36, 46, 49, 62, 66, 68, 73, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 91, 93, 97, 99, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 123, 125, 126, 128, 129, 133, 138, 139, 140, 141, 145, 147, 150, 152, 153, 154, 156, 157, 161, 162, 164, 177, 185], "further": [3, 39, 76, 97, 98, 138, 139, 140, 152, 161], "read": [3, 6, 76, 97, 107, 110, 145, 185], "post": [3, 51, 71, 171], "mean": [3, 6, 28, 29, 49, 62, 75, 76, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 129, 131, 133, 134, 135, 136, 137, 138, 139, 140, 142, 144, 145, 146, 147, 150, 151, 152, 154, 155, 156, 157, 162, 174, 185], "machin": [3, 23, 29, 34, 36, 40, 58, 60, 66, 71, 74, 76, 82, 83, 84, 86, 87, 88, 89, 91, 93, 95, 96, 99, 100, 101, 102, 103, 104, 112, 121, 126, 127, 128, 129, 133, 137, 138, 140, 141, 142, 145, 150, 154], "mooc": [3, 76, 83, 93, 94, 95, 98, 100, 104, 105, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 157, 159, 160, 161, 162, 163, 164], "refer": [3, 14, 23, 34, 40, 60, 74, 75, 76, 83, 84, 89, 91, 94, 95, 96, 97, 98, 100, 101, 104, 105, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 151, 157, 159, 160, 161, 162, 163, 164, 171, 183], "process": [3, 6, 36, 60, 68, 74, 75, 76, 88, 103, 112, 118, 126, 127, 129, 133, 147, 151, 152, 159, 163, 182], "make": [3, 6, 24, 25, 29, 45, 49, 53, 58, 62, 63, 73, 76, 79, 80, 82, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 133, 135, 137, 138, 139, 141, 142, 144, 145, 147, 148, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 172], "appli": [3, 6, 15, 16, 17, 18, 24, 26, 27, 29, 39, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 84, 87, 88, 93, 102, 105, 106, 107, 109, 139, 141, 147, 150, 151, 153, 156, 161, 172, 173, 175, 179, 181, 185], "unlabel": 3, "word": [3, 29, 137, 151, 160, 164, 179], "equival": [3, 18, 29, 49, 75, 76, 83, 95, 100, 104, 119, 132, 136, 138, 140, 142, 156, 177], "unseen": [3, 68, 76, 102, 103, 119, 141], "notion": 3, "out": [3, 6, 25, 75, 76, 79, 82, 83, 87, 96, 98, 101, 103, 104, 110, 112, 115, 116, 119, 120, 124, 125, 129, 132, 133, 136, 142, 150, 152, 157, 159, 160, 163, 164], "ti": 3, "definit": [3, 138, 151], "distribut": [3, 6, 76, 77, 78, 84, 96, 97, 101, 102, 103, 104, 105, 106, 107, 108, 109, 118, 133, 140, 145, 147, 149, 152, 154, 156, 158, 162, 179], "condit": [3, 6, 110, 133], "check": [3, 6, 29, 49, 62, 76, 79, 82, 83, 84, 86, 87, 88, 95, 97, 98, 100, 102, 103, 104, 105, 107, 109, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 133, 137, 138, 139, 141, 142, 143, 146, 150, 152, 153, 157, 158, 160, 161, 162, 164, 170, 177], "wikipedia": [3, 60, 112], "articl": [3, 6, 60, 112], "finish": [3, 133], "_": [3, 76, 78, 83, 84, 88, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 122, 123, 124, 125, 127, 128, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 151, 153, 157, 158, 161, 162, 163, 164], "end": [3, 84, 87, 94, 95, 98, 100, 101, 102, 104, 105, 107, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 155, 157, 159, 160, 161, 162, 163, 164], "thei": [3, 6, 29, 58, 68, 76, 80, 82, 84, 85, 87, 88, 92, 101, 102, 105, 106, 109, 110, 112, 118, 119, 121, 133, 138, 142, 145, 151, 157, 162, 164, 171, 177, 182], "avail": [3, 6, 29, 36, 51, 75, 76, 77, 78, 79, 82, 83, 93, 97, 98, 106, 108, 109, 114, 123, 127, 129, 133, 137, 139, 142, 151, 154, 177], "after": [3, 18, 28, 49, 79, 87, 104, 106, 112, 115, 118, 119, 122, 124, 137, 151, 155, 156], "been": [3, 76, 79, 82, 87, 94, 102, 104, 110, 111, 118, 124, 127, 140, 151, 152, 157], "slope": [3, 29, 107, 139], "intercept": [3, 40, 130, 131, 134, 135, 137, 138, 139, 140, 157], "one": [3, 6, 14, 18, 25, 37, 43, 49, 60, 68, 71, 75, 76, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 95, 96, 97, 99, 100, 101, 102, 104, 107, 109, 110, 111, 117, 118, 119, 121, 128, 133, 137, 138, 140, 142, 143, 145, 146, 150, 151, 152, 156, 157, 158, 161, 163, 173, 185], "section": [3, 79, 82, 87, 88, 94, 95, 97, 98, 100, 104, 105, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 154, 157, 159, 160, 161, 162, 163, 164], "about": [3, 13, 17, 22, 24, 29, 33, 36, 39, 58, 62, 66, 73, 74, 76, 79, 83, 84, 87, 96, 98, 101, 104, 105, 106, 108, 110, 117, 120, 141, 145, 150, 158, 162, 170, 179, 182, 185], "also": [3, 13, 22, 25, 27, 29, 33, 36, 46, 60, 62, 76, 82, 83, 84, 87, 88, 89, 90, 91, 92, 95, 98, 99, 100, 103, 104, 105, 106, 107, 110, 111, 112, 115, 116, 118, 119, 121, 124, 125, 127, 133, 138, 139, 140, 141, 142, 145, 151, 152, 153, 154, 156, 157], "python": [3, 6, 29, 36, 68, 73, 76, 78, 79, 89, 91, 104, 107, 108, 109, 110, 112, 118, 133, 140, 143, 146, 157, 158, 162, 163], "pass": [3, 18, 29, 49, 62, 68, 75, 79, 87, 88, 89, 91, 95, 99, 100, 104, 112, 139, 143, 144, 146, 147, 149, 150, 152, 156, 157, 185], "function": [3, 6, 18, 29, 36, 44, 53, 60, 62, 68, 75, 79, 82, 83, 84, 87, 96, 101, 104, 105, 106, 109, 110, 111, 112, 116, 117, 125, 126, 129, 130, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 150, 152, 153, 157, 159, 162, 163, 174, 185], "anoth": [3, 6, 18, 60, 76, 79, 99, 101, 103, 112, 121, 127, 128, 130, 133, 134, 138, 141, 142, 145, 154, 157, 161], "includ": [3, 29, 34, 36, 66, 87, 99, 106, 127, 128, 131, 133, 135, 138, 151, 174], "gridsearchcv": [3, 6, 99, 120, 125, 149, 150, 152, 154, 156, 161, 177, 179, 185], "someth": [3, 92, 141, 151], "occur": [3, 87, 133], "your": [3, 6, 34, 39, 49, 62, 75, 76, 77, 80, 81, 85, 87, 88, 89, 90, 91, 92, 95, 96, 100, 102, 113, 114, 115, 116, 119, 126, 129, 130, 131, 132, 135, 143, 144, 148, 149, 155, 159, 160, 164, 177, 179], "stick": 3, "too": [3, 6, 63, 83, 93, 99, 104, 105, 115, 118, 119, 121, 124, 133, 150, 156, 161, 179], "so": [3, 6, 14, 29, 68, 76, 78, 84, 86, 87, 89, 91, 94, 95, 100, 101, 102, 103, 104, 106, 107, 110, 111, 116, 117, 119, 125, 133, 137, 138, 142, 143, 146, 151, 152, 156, 177], "up": [3, 6, 10, 35, 45, 76, 79, 82, 87, 97, 99, 101, 104, 109, 110, 127, 130, 134, 138, 139, 142, 150, 162, 165, 182], "nois": [3, 49, 55, 60, 105, 112, 117, 138, 141], "rather": [3, 29, 34, 79, 82, 107, 108, 142, 147, 154, 156], "than": [3, 6, 18, 27, 28, 29, 34, 36, 44, 49, 55, 62, 75, 76, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 94, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 118, 119, 120, 121, 124, 126, 128, 129, 130, 131, 133, 134, 135, 140, 141, 142, 145, 147, 149, 150, 152, 153, 154, 156, 160, 161, 164, 174, 177, 179, 185], "relev": [3, 62, 82, 97, 110, 142], "pattern": [3, 23, 76, 97, 126, 129, 143, 146, 152], "tell": [3, 76, 105, 110], "great": [3, 6, 51], "poorli": [3, 91], "real": [3, 51, 76, 82, 83, 87, 88, 102, 104, 130, 134, 142, 145, 162], "world": [3, 162], "fit_predict": 3, "kneighborsclassifi": [3, 62, 80, 83, 85, 185], "decisiontreeregressor": [3, 18, 94, 98, 103, 104, 105, 112, 113, 117, 120, 121, 122, 138, 161, 162, 164, 177], "One": [3, 51, 62, 71, 75, 79, 80, 85, 87, 102, 103, 108, 110, 118, 142, 145, 152], "focu": [3, 18, 76, 82, 104, 106, 109, 111, 117, 133, 142, 145, 150, 151], "were": [3, 29, 68, 79, 82, 88, 97, 104, 105, 108, 117, 126, 129, 130, 134, 142, 154, 156, 161, 164], "If": [3, 6, 28, 29, 37, 43, 55, 68, 76, 79, 83, 87, 94, 95, 97, 98, 99, 100, 103, 104, 105, 109, 110, 111, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 151, 152, 156, 157, 159, 160, 161, 162, 163, 164, 175, 185], "do": [3, 6, 17, 18, 29, 60, 68, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 96, 99, 101, 103, 104, 105, 106, 109, 115, 118, 119, 121, 124, 126, 127, 129, 133, 137, 138, 142, 143, 146, 150, 151, 152, 153, 157, 162, 179, 181, 185], "1d": [3, 29, 138], "5": [3, 4, 18, 29, 49, 62, 68, 75, 76, 78, 79, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 128, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 145, 147, 150, 152, 153, 154, 156, 157, 158, 161, 162, 163, 164, 165, 181, 182, 185], "someon": [3, 76], "come": [3, 6, 29, 58, 76, 82, 117, 120, 127, 130, 134, 139, 151, 152, 162], "along": [3, 76, 79, 87, 89, 91, 106, 130, 134, 145, 157], "doe": [3, 6, 18, 24, 29, 36, 49, 76, 79, 84, 87, 88, 90, 91, 92, 94, 97, 98, 99, 100, 102, 103, 107, 110, 119, 122, 133, 140, 141, 145, 147, 150, 154, 156, 157, 162, 179, 183], "15": [3, 4, 76, 82, 84, 87, 94, 105, 106, 116, 118, 119, 122, 125, 142, 154, 156, 157, 177], "continu": [3, 6, 37, 42, 44, 66, 76, 82, 104, 106, 110, 139, 140, 142, 145, 147, 158, 161], "price": [3, 51, 75, 93, 94, 104, 106, 109, 110, 144, 145, 147], "descript": [3, 29, 51, 75, 76, 80, 85, 94, 95, 98, 100, 104, 105, 109, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 157, 159, 160, 161, 162, 163, 164, 165], "room": [3, 51, 104, 109, 110], "surfac": [3, 29], "locat": [3, 77, 78, 94, 106, 107, 109, 153], "ag": [3, 49, 76, 79, 81, 82, 83, 84, 86, 87, 88, 104, 109, 110, 133, 150, 151, 154], "mri": 3, "scan": [3, 6, 151], "want": [3, 18, 76, 77, 78, 82, 83, 87, 90, 92, 93, 94, 95, 97, 98, 100, 102, 103, 104, 105, 107, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 157, 158, 159, 160, 161, 162, 163, 164, 177, 179, 185], "tree": [3, 6, 10, 13, 15, 16, 17, 18, 60, 76, 84, 87, 88, 90, 92, 94, 98, 103, 104, 105, 110, 111, 112, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 128, 138, 143, 146, 148, 150, 154, 155, 158, 159, 160, 163, 164, 170, 171, 172, 173, 174, 175, 177], "piecewis": [3, 162, 174], "constant": [3, 24, 86, 110, 135, 162, 174], "given": [3, 6, 18, 29, 51, 60, 68, 82, 84, 87, 96, 99, 101, 102, 104, 106, 108, 109, 110, 112, 117, 121, 128, 132, 133, 136, 137, 139, 140, 142, 147, 152, 154, 157, 172, 179, 181, 182], "output": [3, 18, 42, 76, 79, 84, 87, 88, 103, 104, 107, 110, 112, 130, 134, 140, 142, 147], "correspond": [3, 18, 29, 76, 79, 82, 87, 88, 89, 91, 97, 99, 104, 105, 106, 107, 108, 109, 110, 112, 114, 123, 139, 142, 150, 151, 153, 154, 162, 174, 177], "ridg": [3, 40, 45, 46, 49, 109, 110, 112, 133, 136], "order": [3, 6, 18, 29, 40, 49, 71, 76, 84, 88, 91, 92, 93, 97, 102, 104, 106, 116, 121, 125, 133, 139, 150, 153, 154, 185], "shrink": [3, 45, 46, 49, 133, 136], "constrain": [3, 40, 45, 63, 105], "toward": [3, 45, 46, 49, 110, 127, 133, 136], "zero": [3, 28, 29, 42, 44, 45, 46, 49, 55, 58, 76, 87, 105, 110, 133, 136, 138, 140], "2d": [3, 138, 140], "singl": [3, 15, 16, 18, 24, 25, 27, 28, 29, 35, 42, 43, 44, 45, 46, 49, 51, 55, 62, 66, 68, 71, 75, 76, 79, 82, 84, 87, 88, 93, 96, 99, 101, 102, 103, 104, 110, 112, 117, 120, 121, 122, 127, 128, 130, 131, 134, 135, 138, 142, 143, 145, 146, 150, 151, 152, 157, 161, 172, 173, 174, 175, 177, 179, 181, 185], "orient": [3, 110], "clf": 3, "give": [3, 6, 14, 22, 24, 29, 33, 55, 58, 60, 73, 76, 79, 84, 86, 87, 88, 97, 98, 99, 102, 104, 107, 108, 110, 111, 112, 117, 118, 119, 120, 121, 127, 133, 137, 138, 142, 145, 152, 156, 157], "concret": [3, 29, 60], "graphic": [3, 68, 88, 102, 109, 139], "plot": [3, 18, 29, 49, 62, 68, 76, 77, 78, 84, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 123, 125, 127, 128, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 179], "compos": [3, 49, 75, 76, 83, 87, 88, 89, 90, 91, 92, 93, 96, 101, 106, 121, 145, 148, 150, 152, 154, 155, 161], "sinc": [3, 76, 79, 84, 95, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 127, 133, 137, 138, 140, 141, 142, 145, 150, 157, 158, 162, 163], "potenti": [3, 51, 76, 84, 88, 98, 104, 105, 118, 137, 141, 142, 152, 181], "choic": [3, 29, 36, 45, 55, 58, 60, 87, 100, 101, 104, 107, 109, 110, 112, 133, 137, 147, 150, 154, 156, 165, 185], "circl": [3, 76, 109, 112, 141], "vs": [3, 84, 87, 142], "squar": [3, 28, 60, 107, 133, 134, 137, 138, 145, 147], "boil": 3, "down": [3, 6, 119], "fact": [3, 18, 84, 86, 92, 107, 117, 133, 154, 164, 177], "access": [3, 15, 29, 36, 49, 60, 80, 85, 95, 100, 104, 110, 112, 114, 123, 133, 185], "exactli": [3, 45, 46, 58, 62, 82, 92, 97, 141, 185], "know": [3, 6, 88, 95, 100, 104, 105, 106, 109, 112, 117, 129, 133, 138, 142, 150], "frame": [3, 106, 107, 108, 109], "scienc": [3, 6, 36, 97, 107], "solv": [3, 6, 29, 45, 62, 76, 82, 88, 97, 100, 102, 104, 107, 108, 133, 137, 138, 140, 145, 162, 185], "try": [3, 6, 29, 76, 82, 84, 85, 88, 89, 91, 93, 99, 104, 107, 111, 112, 117, 119, 121, 133, 137, 140, 141, 142, 143, 145, 146, 147, 148, 150, 152, 154, 155, 156, 157, 162, 163, 164, 177, 182], "might": [3, 6, 29, 37, 51, 86, 87, 88, 90, 92, 97, 98, 102, 103, 104, 105, 107, 110, 119, 134, 142, 145, 150, 154], "speci": [3, 18, 77, 78, 111, 132, 136, 140, 157, 158, 159, 161, 163, 185], "commonli": [3, 76, 82, 83], "denot": 3, "eventu": 3, "ideal": [3, 104, 142, 145], "let": [3, 6, 18, 25, 44, 75, 76, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 117, 119, 127, 128, 132, 133, 134, 136, 137, 138, 141, 142, 145, 147, 150, 151, 154, 157, 158, 161, 162, 185], "On": [3, 6, 29, 82, 84, 85, 88, 93, 99, 104, 110, 111, 112, 119, 124, 126, 129, 133, 137, 141, 142, 145, 150, 152, 154, 157, 162, 163, 164], "figur": [3, 27, 76, 78, 79, 82, 102, 104, 107, 108, 109, 110, 111, 112, 117, 140, 152, 153, 154, 157, 158, 179], "mathemat": [3, 60, 95, 100, 138, 139, 140, 145, 157], "b": [3, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 130, 134, 139, 154, 156, 172, 173, 174, 175, 177, 179, 181, 185], "creat": [3, 29, 45, 49, 62, 71, 73, 74, 75, 79, 80, 82, 84, 85, 87, 88, 95, 96, 98, 100, 101, 102, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 147, 150, 151, 152, 154, 157, 159, 160, 162, 163, 164, 173, 177, 182], "infin": 3, "vari": [3, 18, 82, 95, 98, 100, 102, 105, 107, 110, 125, 127, 133, 137, 139, 142, 151, 156, 177], "specif": [3, 13, 22, 23, 37, 66, 83, 84, 89, 90, 91, 92, 97, 104, 105, 107, 109, 110, 111, 117, 118, 121, 127, 133, 142, 150, 151, 153, 157, 161, 162, 177], "fulfil": 3, "requir": [3, 6, 13, 18, 22, 29, 33, 36, 39, 40, 49, 58, 62, 73, 75, 76, 79, 82, 84, 88, 95, 100, 101, 107, 111, 118, 119, 133, 147, 152, 154, 156, 161, 170, 177, 182, 185], "minim": [3, 6, 40, 60, 66, 94, 99, 104, 105, 137, 145, 147, 157, 173], "sum": [3, 40, 42, 60, 76, 83, 85, 117, 134, 142], "error": [3, 6, 16, 28, 29, 40, 42, 53, 55, 58, 60, 61, 63, 76, 79, 83, 89, 91, 94, 97, 98, 99, 105, 111, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 130, 131, 133, 134, 135, 137, 138, 141, 142, 144, 145, 147, 148, 155, 165, 173], "red": [3, 27, 79, 104, 111, 112, 117, 136, 140, 141, 152, 157, 161, 163], "best": [3, 13, 18, 22, 33, 39, 55, 60, 62, 76, 93, 99, 100, 102, 105, 113, 115, 116, 118, 119, 121, 122, 124, 125, 130, 133, 134, 137, 138, 142, 145, 148, 149, 150, 151, 152, 154, 155, 156, 157, 170, 179, 182, 183, 185], "possibl": [3, 6, 15, 29, 36, 42, 44, 60, 62, 66, 71, 76, 84, 87, 94, 98, 99, 102, 104, 105, 110, 112, 118, 119, 121, 129, 130, 133, 134, 138, 140, 141, 145, 147, 149, 150, 152, 153, 156, 160, 162, 164, 179, 185], "abstract": [3, 107], "manner": [3, 14, 29, 87, 97, 133, 147], "state": [3, 6, 14, 62, 76, 82, 83, 84, 87, 88, 109, 150, 154], "jockei": 3, "wheel": 3, "i": [3, 13, 18, 20, 22, 29, 49, 73, 74, 75, 76, 79, 82, 83, 84, 86, 87, 88, 91, 92, 98, 99, 102, 104, 110, 112, 117, 118, 119, 120, 130, 131, 133, 134, 135, 136, 137, 142, 145, 147, 150, 156, 165, 179, 185], "support": [3, 6, 90, 92, 95, 100, 138, 141, 143, 146], "fit_transform": [3, 68, 84, 87, 88, 106, 118, 129, 138], "standardscal": [3, 29, 49, 62, 68, 75, 79, 84, 88, 90, 92, 93, 95, 100, 101, 102, 109, 110, 132, 136, 140, 141, 149, 151, 156, 177, 179, 181, 185], "columntransform": [3, 74, 88, 90, 92, 93, 148, 150, 152, 154, 155], "enough": [3, 6, 91, 92, 101, 104, 105, 117, 119, 141, 145, 151, 157, 161, 163, 177], "flexibl": [3, 6, 55, 58, 60, 63, 95, 100, 105, 121, 141], "both": [3, 15, 16, 18, 22, 29, 39, 40, 49, 55, 66, 75, 76, 78, 83, 84, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 102, 105, 106, 110, 111, 115, 117, 118, 121, 124, 126, 127, 129, 130, 133, 134, 138, 140, 141, 142, 143, 145, 146, 150, 152, 156, 157, 158, 160, 161, 164, 170, 171, 177, 179, 185], "opposit": 3, "cluster": [3, 104, 172], "whose": [3, 118, 151], "group": [3, 6, 20, 25, 29, 76, 102, 103, 104, 109, 165], "subset": [3, 17, 42, 45, 73, 76, 79, 82, 83, 88, 93, 104, 107, 109, 119, 121, 124, 126, 127, 128, 129, 148, 155, 157, 158, 161, 177], "similar": [3, 46, 49, 62, 68, 80, 84, 85, 87, 90, 92, 106, 112, 119, 127, 133, 138, 141, 142, 147, 150, 151, 152, 153, 154, 157, 185], "applic": [3, 6, 97, 103, 142, 145, 161], "them": [3, 6, 13, 62, 76, 78, 79, 84, 87, 88, 96, 99, 101, 104, 110, 112, 114, 118, 119, 120, 123, 133, 138, 140, 142, 145, 150, 151, 152, 156, 160, 163, 164, 177, 185], "broad": 3, "topic": [3, 97, 104, 109], "custom": 3, "commerc": 3, "websit": [3, 36, 51, 80, 85], "although": 3, "mention": [3, 51, 79, 95, 100, 103, 106, 111, 118, 120, 133, 137, 140, 142, 143, 145, 146, 151, 154, 164], "cover": [3, 52, 76, 79, 82, 87, 88], "impli": [3, 161], "fix": [3, 29, 49, 55, 60, 87, 95, 100, 119, 133, 149, 150, 156, 161, 177, 179, 183], "like": [3, 6, 18, 25, 29, 55, 76, 82, 83, 87, 88, 89, 91, 99, 101, 104, 106, 108, 110, 111, 112, 119, 127, 133, 134, 138, 139, 142, 143, 146, 147, 151], "necessari": [3, 6, 45, 76, 119, 152], "subdivid": [3, 157], "select": [3, 6, 13, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 39, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 77, 78, 79, 81, 82, 84, 86, 89, 90, 91, 92, 99, 102, 104, 110, 112, 117, 119, 121, 125, 126, 129, 130, 134, 137, 138, 140, 150, 151, 152, 153, 156, 158, 170, 172, 173, 174, 175, 177, 179, 181, 185], "final": [3, 13, 23, 39, 45, 58, 62, 73, 83, 84, 87, 88, 99, 103, 104, 107, 109, 112, 116, 117, 119, 124, 125, 126, 128, 129, 133, 143, 144, 146, 147, 150, 151, 152, 160, 164, 182], "sometim": [3, 6, 60, 88, 101, 142, 145, 152, 154], "context": [3, 6, 15, 103, 140, 142], "clear": [3, 76, 100, 105, 161], "mani": [3, 6, 29, 43, 49, 62, 75, 76, 77, 78, 83, 84, 87, 88, 99, 101, 102, 104, 105, 106, 109, 112, 119, 121, 133, 142, 151, 156, 185], "need": [3, 6, 22, 24, 29, 37, 40, 62, 68, 76, 80, 82, 84, 85, 87, 88, 93, 95, 99, 100, 104, 105, 107, 110, 111, 112, 117, 119, 120, 121, 122, 133, 137, 138, 141, 143, 144, 146, 147, 148, 150, 151, 152, 154, 155, 161, 175, 177], "criteria": [3, 119], "ml": [3, 6, 97], "cheatsheet": 3, "http": [3, 6, 36, 76, 83, 97, 104, 109], "readthedoc": 3, "io": [3, 36], "en": 3, "latest": [3, 28], "html": [3, 82, 84, 85, 88, 93, 99, 104, 109, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "googl": 3, "develop": [3, 6, 36, 73, 76, 89, 91, 107, 131, 135, 138], "com": [3, 6, 36], "advanc": [3, 6, 36, 73, 90, 92], "terminolog": 3, "org": [3, 76, 82, 83, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "stabl": [3, 110, 112, 133, 177, 185], "modifi": [4, 6, 118, 120, 138], "run": [4, 6, 18, 45, 68, 80, 85, 94, 98, 99, 110, 116, 125, 133, 153, 154, 177, 179, 185], "statu": [4, 25, 76, 82, 87, 88, 150, 152, 154], "python_script": 4, "01_tabular_data_explor": 4, "2023": 4, "08": [4, 29, 107, 133], "30": [4, 76, 82, 87, 88, 94, 95, 97, 98, 100, 105, 106, 108, 109, 112, 118, 119, 120, 122, 148, 150, 151, 152, 154, 155, 161, 164], "09": [4, 107, 133], "48": [4, 82, 83, 84, 103, 106, 122, 153], "cach": 4, "11": [4, 76, 87, 94, 106, 119, 122, 133, 150, 154, 156, 161, 163, 177], "36": [4, 75, 78, 104, 106, 119, 122, 131, 135, 158, 162], "01_tabular_data_exploration_ex_01": 4, "29": [4, 94, 106, 110, 118, 120, 122, 127, 138], "01_tabular_data_exploration_sol_01": 4, "02_numerical_pipeline_cross_valid": 4, "77": [4, 106, 108, 118, 142], "02_numerical_pipeline_ex_00": 4, "49": [4, 87, 106, 118, 119, 122, 127, 137, 154], "95": [4, 103, 109, 154, 157, 162, 163], "02_numerical_pipeline_ex_01": 4, "02_numerical_pipeline_hands_on": 4, "26": [4, 94, 106, 107, 117, 154], "02_numerical_pipeline_introduct": 4, "6": [4, 13, 22, 39, 49, 73, 75, 76, 78, 84, 85, 93, 94, 97, 100, 101, 102, 103, 104, 106, 107, 109, 110, 118, 119, 120, 122, 131, 133, 135, 142, 145, 147, 150, 153, 154, 156, 157, 158, 161, 162, 163, 165, 177], "03": [4, 10, 12, 21, 29, 31, 41, 47, 57, 67, 70, 165, 176], "02_numerical_pipeline_sc": 4, "01": [4, 11, 19, 32, 38, 59, 61, 65, 84, 99, 107, 119, 120, 132, 136, 150, 151, 153, 165, 167, 169, 180], "02_numerical_pipeline_sol_00": 4, "84": [4, 93, 106, 135], "02_numerical_pipeline_sol_01": 4, "13": [4, 76, 82, 84, 94, 97, 106, 107, 108, 119, 122, 141, 145, 156], "03_categorical_pipelin": 4, "03_categorical_pipeline_column_transform": 4, "8": [4, 62, 76, 78, 82, 85, 87, 93, 94, 97, 100, 101, 102, 103, 104, 105, 106, 109, 110, 112, 116, 117, 118, 119, 120, 122, 123, 125, 133, 136, 138, 142, 147, 148, 150, 153, 154, 155, 156, 157, 162, 163, 177, 179, 185], "73": [4, 83, 106], "03_categorical_pipeline_ex_01": 4, "03_categorical_pipeline_ex_02": 4, "7": [4, 18, 49, 75, 76, 78, 84, 85, 87, 94, 97, 100, 101, 102, 104, 106, 107, 109, 110, 118, 119, 122, 131, 133, 135, 142, 147, 150, 153, 154, 156, 157, 158, 161, 163, 165, 177, 185], "19": [4, 78, 87, 94, 106, 107, 118, 119, 120, 122, 131, 133, 135, 137, 153, 154, 156, 158], "03_categorical_pipeline_sol_01": 4, "75": [4, 62, 82, 84, 87, 93, 94, 101, 103, 106, 109], "03_categorical_pipeline_sol_02": 4, "21": [4, 87, 94, 104, 106, 107, 109, 110, 120, 122, 147, 154, 156], "03_categorical_pipeline_visu": 4, "27": [4, 76, 87, 94, 106, 107, 122], "cross_validation_baselin": 4, "98": [4, 108, 110, 157, 162, 163], "cross_validation_ex_01": 4, "12": [4, 76, 84, 93, 94, 106, 107, 108, 109, 119, 122, 142, 150, 154, 156, 163], "02": [4, 10, 11, 20, 30, 38, 41, 61, 67, 84, 165, 167, 176, 178], "04": [4, 12, 30, 47, 70, 84, 111, 119, 133, 165, 168], "cross_validation_ex_02": 4, "58": [4, 106, 107], "cross_validation_group": 4, "38": [4, 76, 82, 84, 87, 106, 150, 151, 154], "cross_validation_learning_curv": 4, "47": [4, 94, 104, 106], "59": [4, 84, 87, 106, 107], "cross_validation_nest": 4, "51": [4, 106, 120, 122, 185], "23": [4, 87, 94, 104, 106, 107, 108, 109, 110, 118, 120], "34": [4, 106, 109, 153], "cross_validation_sol_01": 4, "65": [4, 87, 93, 106], "cross_validation_sol_02": 4, "9": [4, 29, 75, 76, 78, 85, 93, 94, 97, 100, 101, 102, 104, 106, 107, 108, 109, 110, 118, 119, 120, 122, 133, 140, 143, 145, 146, 147, 150, 154, 156, 157, 158, 162, 163, 185], "cross_validation_stratif": 4, "92": [4, 83, 87, 94, 145, 153, 157, 162, 163, 185], "cross_validation_tim": 4, "52": [4, 104, 106, 107, 109, 110, 122, 127, 154, 157], "89": [4, 84, 94, 127, 157, 162, 163], "cross_validation_train_test": 4, "cross_validation_validation_curv": 4, "00": [4, 29, 84, 104, 107, 134, 137, 150], "37": [4, 82, 83, 84, 87, 104, 106, 109, 110, 119, 153], "datasets_ames_h": 4, "datasets_bike_rid": 4, "53": [4, 106, 107, 118, 120, 127, 154], "datasets_blood_transfus": 4, "datasets_california_h": 4, "22": [4, 94, 104, 106, 107, 109, 110, 122, 145, 147, 150, 153], "dev_features_import": 4, "54": [4, 106, 107, 119, 122], "71": [4, 106, 154, 162], "05": [4, 29, 31, 47, 70, 94, 97, 101, 102, 103, 107, 109, 112, 117, 120, 123, 133, 136, 142, 152, 157, 161, 163, 165], "ensemble_adaboost": 4, "ensemble_bag": 4, "55": [4, 98, 106, 107, 119], "ensemble_ex_01": 4, "94": [4, 111], "ensemble_ex_02": 4, "91": [4, 94, 106, 157, 162, 163], "ensemble_ex_03": 4, "ensemble_ex_04": 4, "88": [4, 87, 104, 109, 110, 119, 150, 154], "ensemble_gradient_boost": 4, "56": [4, 88, 106, 107, 122, 146, 154], "106": [4, 87, 107], "ensemble_hist_gradient_boost": 4, "57": [4, 106, 107, 122], "46": [4, 87, 94, 104, 106, 117, 118, 122, 156], "25": [4, 62, 76, 82, 83, 84, 88, 94, 104, 105, 106, 107, 109, 110, 122, 134, 139, 150, 151, 154], "ensemble_hyperparamet": 4, "125": [4, 118], "ensemble_introduct": 4, "ensemble_random_forest": 4, "74": [4, 106, 124], "ensemble_sol_01": 4, "ensemble_sol_02": 4, "69": [4, 106, 111], "ensemble_sol_03": 4, "105": [4, 87, 107], "ensemble_sol_04": 4, "82": [4, 81, 83, 86, 118, 119], "feature_selection_ex_01": 4, "83": [4, 76, 103, 118, 154], "feature_selection_introduct": 4, "16": [4, 76, 84, 87, 88, 94, 97, 103, 106, 108, 118, 119, 122, 138, 147, 153, 156, 157, 163], "68": [4, 78, 93, 106, 146, 154, 156], "feature_selection_limitation_model": 4, "06": 4, "60": [4, 29, 76, 83, 93, 106, 107, 110, 112, 153, 161], "96": [4, 120, 157, 162, 163], "feature_selection_sol_01": 4, "linear_models_ex_01": 4, "linear_models_ex_02": 4, "31": [4, 106, 116, 119, 125, 142, 154], "linear_models_ex_03": 4, "07": [4, 103, 110, 133], "linear_models_regular": 4, "linear_models_sol_01": 4, "linear_models_sol_02": 4, "28": [4, 76, 82, 84, 87, 94, 104, 106, 107, 108, 118, 122, 150, 151, 154], "linear_models_sol_03": 4, "97": [4, 153, 157, 162, 163, 185], "linear_regression_in_sklearn": 4, "linear_regression_non_linear_link": 4, "linear_regression_without_sklearn": 4, "35": [4, 76, 105, 106, 108, 119, 124], "logistic_regress": [4, 132, 136, 140], "logistic_regression_non_linear": 4, "metrics_classif": 4, "metrics_ex_01": 4, "metrics_ex_02": 4, "metrics_regress": 4, "32": [4, 88, 106, 119], "metrics_sol_01": 4, "metrics_sol_02": 4, "parameter_tuning_ex_02": 4, "parameter_tuning_ex_03": 4, "parameter_tuning_grid_search": 4, "parameter_tuning_manu": 4, "parameter_tuning_nest": 4, "parameter_tuning_parallel_plot": 4, "81": [4, 29, 75, 81, 86, 118, 119], "parameter_tuning_randomized_search": 4, "parameter_tuning_sol_02": 4, "parameter_tuning_sol_03": 4, "trees_classif": 4, "trees_dataset": 4, "trees_ex_01": 4, "trees_ex_02": 4, "39": [4, 78, 87, 88, 106, 118, 131, 135, 154, 158], "trees_hyperparamet": 4, "trees_regress": 4, "62": [4, 93, 106, 150], "trees_sol_01": 4, "trees_sol_02": 4, "lot": [6, 76, 109, 110, 129, 133, 142], "materi": 6, "far": [6, 94, 105, 117, 124, 128, 133], "congratul": 6, "And": [6, 103], "thank": [6, 152], "everyon": 6, "instructor": 6, "staff": 6, "peopl": [6, 76, 97, 104, 109, 110, 142], "who": [6, 88, 142], "help": [6, 62, 68, 84, 86, 90, 92, 95, 96, 100, 101, 105, 106, 107, 108, 109, 110, 119, 126, 129, 133, 140, 142, 145, 185], "forum": [6, 36], "student": [6, 36], "hard": [6, 76, 77, 78, 126, 129, 142, 147], "work": [6, 40, 49, 62, 67, 76, 84, 87, 88, 102, 103, 107, 112, 119, 121, 128, 129, 133, 148, 151, 153, 155, 157, 159, 162, 163, 165, 170, 185], "summar": [6, 104, 111, 119, 121], "train": [6, 15, 16, 17, 18, 25, 26, 29, 34, 35, 37, 40, 42, 43, 45, 49, 53, 55, 58, 60, 61, 62, 63, 68, 71, 73, 74, 76, 79, 80, 81, 84, 85, 86, 87, 88, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 174, 175, 177, 182, 185], "test": [6, 18, 26, 29, 34, 35, 37, 45, 49, 55, 58, 60, 61, 62, 68, 74, 75, 79, 80, 81, 84, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 133, 135, 136, 140, 141, 142, 143, 145, 146, 148, 150, 151, 152, 154, 155, 156, 159, 162, 163, 165, 175, 177, 179, 185], "built": [6, 37, 96, 101, 110, 112, 142, 161, 163, 173], "matrix": [6, 29, 84, 87, 97, 121, 126, 129, 133, 138], "featur": [6, 15, 16, 17, 18, 24, 29, 33, 34, 35, 37, 40, 42, 43, 44, 49, 51, 60, 62, 66, 67, 68, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 88, 89, 91, 93, 94, 96, 100, 101, 104, 106, 107, 108, 109, 111, 112, 117, 118, 119, 121, 126, 129, 131, 135, 136, 139, 140, 141, 145, 150, 151, 152, 156, 157, 158, 159, 160, 161, 162, 163, 164, 172, 173, 177, 185], "observ": [6, 28, 45, 49, 53, 55, 76, 78, 84, 86, 87, 88, 90, 92, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 111, 112, 115, 117, 119, 121, 124, 125, 127, 133, 135, 138, 140, 141, 142, 145, 150, 153, 156, 157, 158, 161, 162, 164, 174], "transform": [6, 29, 40, 68, 71, 83, 84, 87, 88, 93, 96, 99, 101, 104, 105, 107, 112, 118, 121, 126, 129, 133, 138, 145, 150, 151, 152, 153, 154, 179], "often": [6, 40, 43, 45, 60, 63, 76, 87, 88, 99, 101, 112, 138, 145, 147, 152, 177, 182, 185], "typic": [6, 13, 51, 73, 76, 87, 104, 109, 119, 126, 129, 140, 145, 147, 152, 154, 172], "categor": [6, 37, 49, 66, 71, 73, 74, 75, 76, 77, 78, 89, 91, 106, 121, 133, 140, 142, 150, 158, 165, 177], "variabl": [6, 24, 29, 36, 40, 49, 51, 60, 62, 66, 68, 70, 71, 75, 79, 80, 83, 84, 85, 89, 91, 94, 97, 98, 103, 104, 105, 106, 108, 109, 112, 119, 121, 133, 139, 140, 145, 150, 152, 154, 156, 158, 165, 177, 179, 185], "must": [6, 45, 49, 110, 133, 152, 157, 162, 163, 185], "seek": [6, 34, 119, 120, 142], "suffic": [6, 119], "But": [6, 93, 100, 103, 104, 109, 133, 152, 153], "larg": [6, 18, 49, 71, 88, 99, 104, 107, 109, 115, 116, 118, 119, 124, 125, 128, 129, 132, 133, 136, 145, 149, 152, 153, 154, 156, 179], "detect": 6, "underfit": [6, 13, 22, 29, 33, 39, 45, 53, 55, 58, 60, 61, 62, 63, 98, 117, 119, 120, 121, 138, 141, 165, 170, 172], "simpl": [6, 76, 81, 86, 95, 100, 106, 111, 112, 120, 121, 133, 138, 139, 140, 151, 157, 163, 165], "multipl": [6, 87, 97, 110, 112, 117, 131, 135, 143, 144, 146, 147, 153, 172, 173], "hyper": [6, 18, 37, 99, 101, 152, 156, 179], "control": [6, 46, 80, 84, 85, 95, 99, 100, 105, 119, 121, 127, 132, 136, 148, 149, 151, 153, 155, 156, 157, 161, 172, 182], "import": [6, 13, 18, 22, 29, 36, 37, 49, 60, 62, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 168, 170, 177, 179, 181, 185], "randomsearchcv": 6, "understand": [6, 13, 22, 33, 39, 58, 80, 82, 85, 87, 97, 98, 102, 105, 130, 134, 142, 161, 162, 170, 171, 182], "suit": [6, 145, 171], "intuit": [6, 10, 11, 13, 14, 22, 39, 47, 58, 73, 82, 83, 87, 107, 109, 111, 112, 117, 125, 137, 138, 140, 141, 157, 158, 162, 163, 165], "debug": 6, "build": [6, 18, 29, 73, 75, 76, 83, 93, 95, 100, 112, 118, 128, 150, 161, 165, 167], "combin": [6, 13, 14, 16, 42, 43, 44, 68, 76, 82, 84, 88, 97, 99, 108, 109, 110, 111, 112, 116, 117, 118, 119, 120, 121, 125, 128, 133, 137, 138, 140, 147, 148, 149, 150, 152, 154, 155, 156, 157, 172, 173, 179, 182, 183], "particularli": [6, 89, 91, 119], "few": [6, 76, 77, 78, 81, 82, 86, 104, 106, 108, 109, 119, 121, 152, 158], "benefit": [6, 17, 24, 33, 84, 87, 98, 117, 120, 121, 133, 145, 159, 163, 165], "non": [6, 20, 29, 39, 42, 44, 45, 68, 71, 76, 84, 92, 95, 99, 100, 101, 106, 107, 108, 109, 110, 112, 127, 131, 133, 135, 140, 156, 157, 162, 164, 165, 171, 172, 183], "engin": [6, 40, 97, 107, 131, 133, 135, 138, 165], "base": [6, 13, 14, 15, 16, 18, 29, 34, 36, 42, 49, 51, 62, 76, 77, 78, 84, 90, 92, 97, 104, 107, 112, 117, 120, 121, 127, 128, 131, 135, 138, 141, 142, 147, 150, 152, 157, 158, 165, 185], "seri": [6, 94, 96, 97, 101, 103, 110, 112, 117, 136, 140, 157], "threshold": [6, 15, 27, 76, 93, 109, 157, 162, 163, 173], "variou": [6, 58, 93], "attribut": [6, 37, 76, 84, 87, 97, 99, 104, 109, 110, 112, 114, 123, 137, 138, 149, 150, 154, 156, 179, 185], "natur": [6, 22, 36, 83, 87, 88, 104, 107, 112, 133, 154], "miss": [6, 76, 87, 97, 104, 106, 108, 109, 131, 135, 185], "histgradientboostingregressor": [6, 18, 29, 118, 119, 125, 147], "classifi": [6, 15, 24, 27, 42, 49, 71, 77, 78, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 100, 101, 102, 108, 111, 112, 121, 127, 132, 136, 140, 141, 143, 146, 147, 148, 150, 151, 152, 154, 155, 157, 159, 161, 163, 171, 172, 179, 181, 185], "goto": 6, "strongli": [6, 110], "advis": [6, 110], "pointer": 6, "doc": 6, "rich": 6, "didact": [6, 36, 87, 88, 106], "improv": [6, 36, 68, 92, 93, 97, 98, 100, 101, 105, 113, 115, 119, 122, 124, 138, 145, 153, 179, 182], "compris": [6, 142], "guid": [6, 145, 185], "everi": [6, 76, 79, 104, 107, 110, 137, 152], "explain": [6, 18, 29, 39, 60, 88, 110, 117, 118, 124, 128, 136, 145, 150, 170], "tri": [6, 68, 107, 111, 133], "demonstr": [6, 88, 94, 111, 117, 118, 133, 138, 161], "good": [6, 22, 25, 49, 76, 79, 81, 82, 83, 86, 87, 88, 90, 92, 102, 103, 104, 105, 108, 110, 119, 120, 121, 128, 130, 133, 134, 137, 141, 142, 150, 152, 153, 154, 156, 157, 179], "softwar": [6, 36], "ask": [6, 126, 129, 130, 132, 134, 136, 142], "question": [6, 82, 90, 92, 106, 130, 134, 142, 156], "stackoverflow": 6, "github": [6, 36, 82, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "discuss": [6, 14, 18, 36, 49, 76, 79, 83, 111, 117, 119, 120, 133], "driven": [6, 151], "inclus": 6, "contribut": [6, 62, 84, 97, 133, 156, 179], "other": [6, 14, 27, 29, 36, 45, 62, 75, 76, 79, 83, 84, 87, 88, 89, 91, 94, 95, 96, 100, 101, 102, 103, 107, 110, 112, 119, 127, 133, 137, 138, 141, 145, 150, 152, 153, 154, 160, 164, 179, 182, 185], "advocaci": 6, "curat": 6, "overflow": 6, "code": [6, 29, 36, 49, 51, 71, 77, 80, 81, 89, 95, 96, 112, 113, 114, 115, 116, 118, 126, 129, 130, 131, 132, 133, 134, 143, 144, 148, 149, 150, 152, 153, 155, 156, 159, 160, 179], "start": [6, 36, 49, 76, 80, 81, 82, 84, 85, 86, 87, 88, 90, 92, 94, 97, 98, 101, 102, 103, 104, 107, 108, 117, 119, 120, 126, 127, 129, 132, 133, 136, 139, 140, 142, 145, 147, 149, 151, 156, 157, 158, 159, 163], "carpentri": 6, "resourc": [6, 36, 73, 76, 107, 119, 152], "git": 6, "lab": [6, 36], "unsupervis": [6, 51], "structur": [6, 60, 73, 76, 84, 87, 88, 97, 119, 145, 156, 157, 162, 171], "instanc": [6, 49, 66, 76, 82, 83, 84, 87, 97, 104, 106, 107, 109, 110, 113, 116, 122, 125, 126, 127, 128, 129, 131, 133, 135, 137, 139, 142, 144, 145, 147, 151, 154, 157, 162, 163, 175, 181, 182], "sampl": [6, 14, 15, 16, 18, 20, 29, 45, 51, 61, 63, 66, 76, 77, 78, 79, 82, 83, 84, 87, 88, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 118, 119, 121, 124, 126, 129, 130, 133, 134, 138, 139, 140, 141, 142, 147, 149, 150, 152, 154, 156, 157, 158, 160, 161, 162, 164, 165, 174, 183], "supervis": [6, 51, 104, 172], "recov": [6, 18, 97, 133], "link": [6, 15, 81, 82, 86, 97, 106, 107, 108, 109, 110, 119, 126, 129, 142, 145], "drive": 6, "system": [6, 76, 97], "hand": [6, 29, 93, 97, 111, 124, 133, 138, 150, 152], "nuanc": 6, "deep": [6, 92, 119, 120, 161], "better": [6, 17, 18, 28, 49, 75, 79, 83, 86, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 112, 119, 120, 121, 126, 129, 130, 133, 134, 137, 147, 151, 152, 154, 156, 161, 177, 185], "gradient": [6, 10, 13, 14, 16, 17, 18, 29, 84, 88, 111, 115, 116, 120, 124, 125, 147, 150, 154, 165], "boost": [6, 13, 14, 16, 17, 18, 29, 88, 115, 116, 120, 124, 125, 150, 154, 165], "classif": [6, 15, 22, 38, 39, 41, 49, 51, 62, 66, 75, 76, 82, 83, 89, 91, 93, 95, 96, 97, 100, 101, 102, 104, 108, 111, 131, 135, 139, 143, 144, 145, 146, 147, 159, 161, 162, 163, 165, 170, 171, 172, 185], "regress": [6, 18, 22, 27, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 55, 60, 62, 68, 75, 82, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 104, 109, 112, 114, 117, 123, 126, 129, 131, 132, 135, 136, 140, 141, 142, 144, 147, 149, 151, 156, 157, 160, 161, 164, 165, 170, 171, 172, 177, 185], "nativ": [6, 49, 76, 82, 87, 88, 104, 127, 138, 150, 152, 154], "input": [6, 24, 40, 42, 43, 60, 75, 76, 81, 83, 84, 86, 87, 90, 91, 92, 94, 97, 100, 101, 110, 112, 130, 134, 138, 139, 152, 157, 158, 172, 185], "speech": 6, "text": [6, 36, 51, 107, 139], "imag": [6, 97], "voic": 6, "pretrain": 6, "human": [6, 76, 107], "cost": [6, 83, 104, 107, 120, 153, 154], "mainten": 6, "Not": [6, 88, 89, 91, 99], "pytorch": 6, "tensorflow": 6, "introduct": [6, 58, 73, 165], "andrea": 6, "c": [6, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 97, 99, 108, 132, 136, 142, 151, 157, 162, 163, 172, 173, 174, 175, 177, 179, 181, 185], "m\u00fcller": 6, "sarah": 6, "guido": 6, "handbook": 6, "jake": 6, "van": 6, "der": 6, "pla": 6, "broader": [6, 160, 164], "statist": [6, 18, 58, 76, 78, 83, 84, 87, 90, 92, 104, 109, 111, 112, 126, 129, 142, 185], "jame": 6, "witten": 6, "hasti": 6, "tibshirani": 6, "theori": [6, 111], "concept": [6, 13, 14, 22, 23, 33, 34, 39, 40, 58, 60, 74, 97, 102, 104, 147, 170, 171, 183], "kera": 6, "aur\u00e9lien": 6, "g\u00e9ron": 6, "kaggl": 6, "particip": 6, "challeng": [6, 36, 108], "team": 6, "solut": [6, 10, 11, 12, 18, 19, 30, 31, 32, 36, 38, 41, 47, 61, 65, 67, 70, 87, 103, 126, 127, 137, 141, 150, 165, 167, 176, 178, 180], "share": [6, 112], "winner": 6, "wai": [6, 73, 75, 76, 79, 82, 86, 87, 99, 100, 101, 103, 111, 112, 117, 118, 119, 126, 127, 129, 138, 142, 145, 162, 177, 185], "now": [6, 18, 29, 49, 62, 75, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 138, 139, 140, 142, 143, 146, 148, 150, 152, 153, 154, 155, 157, 160, 161, 164, 177, 185], "touch": 6, "briefli": 6, "fit": [6, 14, 24, 26, 29, 39, 40, 42, 43, 44, 45, 49, 53, 66, 68, 79, 80, 82, 85, 86, 87, 90, 92, 93, 95, 99, 100, 101, 103, 104, 105, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 133, 134, 136, 137, 138, 140, 141, 142, 145, 147, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 170, 174, 179], "wider": [6, 36, 55], "mai": [6, 25, 45, 51, 76, 104, 109, 119, 133, 137, 142, 147, 156], "fail": [6, 103, 143, 146], "weak": [6, 16, 119, 154], "analysi": [6, 73, 82, 95, 100, 108, 109, 133, 145, 154, 156, 157, 165, 178], "kei": [6, 8, 9, 48, 50, 52, 54, 56, 64, 68, 69, 95, 100, 102, 105, 119, 122, 125, 127, 128, 136, 150, 151, 154, 161, 166], "achiev": [6, 18, 76, 81, 84, 86, 98, 100, 108, 133, 161], "reliabl": [6, 97], "even": [6, 36, 39, 63, 78, 79, 83, 87, 88, 90, 91, 92, 97, 101, 103, 104, 111, 118, 119, 124, 127, 133, 138, 141, 142, 143, 144, 146, 147, 150, 156, 182, 183], "cross": [6, 13, 18, 22, 23, 24, 25, 26, 29, 33, 34, 39, 40, 45, 49, 58, 59, 61, 62, 67, 68, 75, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 105, 109, 110, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 129, 131, 133, 135, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 161, 165, 170, 175, 177, 179, 182, 183, 185], "accuraci": [6, 18, 27, 49, 62, 68, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 97, 99, 100, 101, 102, 108, 111, 117, 127, 128, 129, 130, 134, 136, 140, 143, 146, 147, 150, 151, 152, 153, 154, 155, 156, 157, 159, 163, 185], "imperfect": [6, 110], "estim": [6, 13, 17, 22, 29, 33, 39, 45, 49, 58, 62, 68, 73, 79, 87, 88, 93, 99, 101, 103, 109, 110, 111, 112, 113, 115, 116, 118, 119, 120, 121, 122, 124, 125, 126, 127, 129, 133, 138, 140, 144, 145, 147, 150, 151, 152, 154, 170, 177, 179, 182, 185], "actual": [6, 76, 80, 83, 85, 94, 103, 104, 105, 119, 142, 145, 152], "gener": [6, 17, 18, 22, 23, 28, 29, 49, 52, 58, 60, 61, 62, 68, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 138, 140, 141, 142, 144, 145, 147, 148, 149, 150, 151, 152, 154, 155, 156, 162, 165, 168, 177, 179, 185], "As": [6, 29, 49, 76, 79, 82, 83, 84, 87, 88, 90, 92, 95, 97, 99, 100, 101, 106, 108, 109, 110, 112, 117, 118, 133, 141, 142, 144, 145, 147, 151, 152, 153, 156, 161, 164], "narrow": 6, "spend": [6, 107, 119], "increasingli": 6, "effort": [6, 107], "split": [6, 15, 18, 23, 29, 37, 43, 45, 68, 76, 79, 81, 86, 87, 88, 94, 99, 102, 103, 104, 106, 110, 113, 117, 118, 119, 121, 122, 124, 126, 129, 141, 142, 145, 150, 152, 154, 157, 159, 161, 162, 163, 172, 173], "afford": 6, "trust": [6, 82, 83, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 151, 152, 154, 157, 163, 164], "think": [6, 77, 78, 103, 107, 131, 135], "carefulli": [6, 97], "complet": [6, 15, 29, 36, 49, 99, 101, 126, 129, 133, 149, 152, 156, 179], "futur": [6, 76, 79, 88, 93, 103, 104, 140, 150, 157, 162, 163], "upon": [6, 93, 100, 101], "affect": [6, 103, 133, 140, 150, 162], "live": [6, 133], "sure": [6, 18, 62, 82, 84, 87, 92, 116, 125], "divers": [6, 157], "demograph": [6, 120], "increas": [6, 16, 18, 28, 29, 45, 49, 53, 55, 60, 78, 84, 87, 100, 104, 105, 110, 115, 118, 119, 124, 133, 139, 140, 141, 150, 154, 156, 157, 159, 161, 162, 163, 175, 183], "coverag": 6, "phrase": 6, "recommend": [6, 36, 73, 76, 87], "identifi": [6, 13, 73, 88, 97, 100, 105, 142, 179], "ani": [6, 15, 18, 29, 36, 75, 76, 79, 82, 84, 86, 88, 91, 92, 94, 97, 100, 102, 103, 104, 105, 107, 108, 109, 110, 112, 119, 120, 121, 125, 126, 127, 128, 129, 133, 137, 145, 150, 152, 153, 156, 161, 174, 185], "bia": [6, 37, 53, 58, 60, 110, 131, 135, 145, 165], "acquisit": 6, "full": [6, 8, 9, 18, 36, 48, 50, 51, 52, 54, 56, 64, 68, 69, 79, 80, 84, 85, 87, 99, 104, 119, 124, 126, 128, 129, 139, 148, 152, 155, 166, 179, 182], "chain": [6, 79, 84, 88], "acquir": [6, 13, 22, 33, 39, 58, 105, 107, 170, 182], "fanci": 6, "put": [6, 33, 37, 84, 105, 110, 133, 157], "product": [6, 99, 102, 104, 131, 133, 135, 150], "routin": [6, 18, 97, 185], "debt": 6, "simpler": [6, 14, 88], "easier": [6, 84, 87, 94, 138, 145], "maintain": 6, "less": [6, 29, 88, 97, 103, 109, 110, 111, 112, 119, 120, 128, 133, 135, 138, 150, 156], "power": [6, 29, 36, 107, 119, 120, 133, 138, 157], "drift": 6, "gave": [6, 142], "methodolog": [6, 36, 58, 104, 162], "element": [6, 22, 83, 87, 97, 104, 133, 134, 139, 142], "alwai": [6, 15, 18, 22, 24, 45, 55, 81, 82, 83, 86, 88, 92, 94, 97, 99, 100, 101, 102, 104, 105, 108, 109, 121, 127, 141, 142, 152, 153, 164, 177, 179, 185], "solid": 6, "conclus": [6, 76, 96, 97, 99, 101, 102, 103, 105, 108, 119, 127], "standpoint": 6, "biggest": 6, "shortcom": 6, "cannot": [6, 18, 29, 60, 76, 102, 103, 105, 110, 119, 126, 129, 141, 142, 145, 147, 150, 153, 164, 182], "autom": [6, 76, 165, 183], "domain": 6, "knowledg": [6, 36, 73, 99, 105, 112, 129, 138, 141, 152], "critic": [6, 36, 106], "thing": [6, 76, 87, 88, 93, 103, 150], "oper": [6, 84, 112, 142, 152], "risk": [6, 131, 135, 141], "advertis": 6, "individu": [6, 17, 29, 76, 84, 88, 108, 112, 114, 121, 123, 133, 141, 157, 185], "caus": [6, 18, 53, 60, 76, 87, 91, 92, 119, 133, 150, 152, 179], "wast": [6, 119], "bit": [6, 29, 86, 104, 105, 110, 133, 143, 146, 152], "monei": 6, "annoi": 6, "otherwis": [6, 18, 82, 91, 97, 99, 121, 138, 139, 161], "mostli": [6, 156], "harmless": 6, "medicin": 6, "kill": 6, "logic": [6, 150], "fals": [6, 16, 55, 83, 87, 90, 92, 97, 99, 103, 107, 109, 125, 127, 128, 133, 135, 138, 142, 146, 149, 150, 154, 156, 157, 163, 175], "brain": 6, "tumor": 6, "sent": 6, "surgeri": 6, "veri": [6, 18, 58, 62, 76, 82, 88, 90, 92, 99, 100, 102, 105, 108, 109, 110, 112, 117, 119, 121, 125, 133, 138, 142, 150, 151, 152, 153, 154, 161, 179], "danger": [6, 133, 154], "mr": 6, "confirm": [6, 94, 102, 107, 109, 112, 126, 129, 145, 152, 153], "should": [6, 18, 23, 29, 34, 35, 45, 71, 75, 76, 83, 84, 88, 92, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 116, 117, 119, 120, 125, 126, 127, 129, 130, 133, 134, 138, 141, 142, 143, 146, 147, 148, 150, 151, 152, 155, 157, 159, 161, 162, 163, 175, 177, 179, 182, 183], "delai": 6, "life": [6, 76, 126, 129, 145], "save": [6, 185], "treatment": [6, 60], "hospit": [6, 25], "stai": [6, 40, 45, 112, 133], "overcrowd": 6, "unit": [6, 76, 82, 84, 87, 88, 104, 107, 109, 110, 111, 133, 137, 139, 145, 150, 154], "chang": [6, 28, 29, 37, 49, 76, 78, 84, 96, 101, 107, 108, 109, 110, 111, 115, 124, 127, 133, 140, 145, 148, 151, 155, 157, 158, 182, 185], "inpati": 6, "chose": [6, 55, 76, 117, 133], "load": [6, 18, 49, 66, 77, 78, 79, 80, 84, 85, 87, 88, 89, 91, 95, 98, 99, 100, 102, 103, 104, 105, 108, 109, 111, 113, 118, 119, 120, 122, 131, 132, 133, 135, 136, 137, 141, 142, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 179, 185], "interest": [6, 51, 76, 77, 78, 94, 96, 101, 102, 104, 105, 107, 109, 112, 117, 131, 135, 137, 138, 142, 145, 147, 150, 151, 152, 153, 154, 156, 185], "focus": [6, 14, 63, 109, 111, 133, 142, 152], "easi": [6, 88, 103, 104, 107, 161], "accumul": 6, "target": [6, 18, 29, 39, 40, 41, 44, 49, 51, 60, 62, 66, 68, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 163, 165, 177, 185], "proxi": [6, 142], "reflect": [6, 104, 112, 121], "ground": [6, 117, 142], "truth": [6, 117, 142], "polici": [6, 25], "uneven": 6, "across": [6, 49, 79, 84, 94, 110, 133, 154, 185], "popul": [6, 76, 104, 109, 110, 142, 156], "eg": 6, "qualiti": [6, 110, 145, 152], "affair": 6, "desir": [6, 81, 86, 121, 133], "qualif": 6, "respons": 6, "women": 6, "pai": [6, 87, 111], "men": 6, "pick": [6, 29, 93, 99, 106, 107, 110, 118, 151, 182], "amplifi": 6, "inequ": 6, "mechan": [6, 29, 83, 84, 152], "die": 6, "naiv": [6, 18, 29, 76, 99, 108, 118, 121], "bad": [6, 91, 100, 129, 133, 141, 142, 179], "health": [6, 36], "fallaci": 6, "compar": [6, 13, 17, 18, 22, 29, 37, 49, 51, 61, 62, 75, 76, 79, 81, 83, 84, 86, 87, 88, 89, 91, 99, 100, 101, 105, 109, 110, 112, 115, 117, 118, 122, 124, 127, 128, 129, 131, 133, 135, 142, 145, 154, 156, 157, 165, 177, 185], "wors": [6, 18, 28, 49, 75, 100, 101, 103, 137, 177], "baselin": [6, 22, 24, 81, 86, 88, 89, 91, 96, 97, 100, 101, 120, 165], "heart": [6, 29, 107, 131, 135], "pressur": 6, "greater": [6, 29, 75], "trigger": 6, "care": [6, 34, 87, 99, 102, 108, 109, 126, 129, 133], "which": [6, 14, 16, 17, 18, 23, 25, 27, 29, 33, 34, 40, 45, 49, 60, 62, 68, 71, 74, 75, 76, 79, 82, 83, 84, 86, 87, 88, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 149, 150, 151, 153, 154, 156, 161, 162, 163, 170, 171, 172, 177, 179, 181, 183, 185], "learner": [6, 14, 111, 112, 117, 119, 120], "predictor": [6, 14, 15, 16, 17, 49, 68, 83, 84, 88, 101, 122, 133, 150, 157], "pure": [6, 129, 163], "benefici": [6, 33, 84, 119, 127, 152, 154, 161], "intervent": [6, 76], "brittl": 6, "interpret": [6, 17, 36, 107, 109, 110, 137, 145, 153, 157], "subject": [6, 76, 142], "caution": [6, 92, 110], "feedback": 6, "loop": [6, 99, 110, 148, 150, 152, 155, 185], "todai": 6, "ai": 6, "alloc": 6, "loan": 6, "screen": [6, 8, 9, 48, 50, 52, 54, 56, 64, 69, 166], "job": [6, 84], "prioritis": 6, "treatement": 6, "law": [6, 29], "enforc": [6, 103, 107, 119, 133], "court": 6, "fairlearn": [6, 76], "assess": [6, 25, 49, 79, 83, 96, 98, 99, 101, 105, 115, 124, 130, 133, 134, 141, 142, 145, 152, 156], "shift": [6, 84], "technolog": [6, 97], "induc": [6, 110, 112], "societi": 6, "though": [6, 101, 118, 144, 147], "difficult": [6, 107, 119, 137, 145], "intersect": [6, 153, 156], "No": [6, 24], "found": [6, 62, 99, 108, 109, 116, 119, 125, 133, 137, 148, 150, 152, 155, 156, 157, 161, 162, 179, 185], "short": [6, 34, 82, 109, 120, 158], "move": [6, 88, 107, 153, 156], "choos": [6, 18, 36, 76, 89, 91, 104, 110, 126, 127, 129, 133, 138, 152, 175, 185], "revolut": 6, "fantast": [6, 129], "opportun": 6, "With": [6, 37, 91, 104, 107, 119, 127, 128, 142, 150, 154, 161], "lift": 6, "roadblock": 6, "hope": [6, 93, 145], "empow": 6, "varieti": [6, 36, 79], "mindset": 6, "dream": 6, "being": [6, 43, 94, 156], "adventur": 6, "navig": [8, 9, 48, 50, 52, 54, 56, 64, 69, 166], "slide": [8, 9, 48, 50, 52, 54, 56, 64, 69, 140, 153, 156, 166], "click": [8, 9, 15, 48, 50, 52, 54, 56, 64, 69, 153, 156, 166, 179], "press": [8, 9, 48, 50, 52, 54, 56, 64, 69, 166], "arrow": [8, 9, 48, 50, 52, 54, 56, 64, 69, 166], "go": [8, 9, 13, 22, 29, 33, 36, 39, 48, 50, 52, 54, 56, 58, 64, 69, 73, 79, 80, 85, 87, 95, 97, 99, 100, 103, 104, 105, 107, 109, 110, 117, 120, 127, 140, 142, 147, 150, 157, 166, 170, 182], "next": [8, 9, 48, 50, 52, 54, 56, 60, 64, 69, 82, 83, 87, 93, 95, 96, 100, 101, 102, 103, 111, 117, 119, 120, 133, 138, 151, 157, 166], "previou": [8, 9, 16, 18, 22, 29, 48, 49, 50, 52, 54, 56, 62, 64, 66, 68, 69, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 101, 102, 103, 104, 105, 112, 113, 116, 117, 118, 119, 121, 122, 125, 126, 129, 130, 131, 133, 134, 135, 137, 138, 141, 143, 146, 148, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 163, 164, 166, 177, 179, 182, 185], "p": [8, 9, 48, 50, 52, 54, 56, 64, 69, 97, 143, 146, 166], "toggl": [8, 9, 48, 50, 52, 54, 56, 64, 69, 166], "mode": [8, 9, 36, 48, 50, 52, 54, 56, 64, 69, 166], "adapt": [10, 102, 120, 138, 141, 145, 154, 165], "adaboost": [10, 13, 117, 165], "gbdt": [10, 111, 124, 165], "exercis": [10, 11, 12, 19, 29, 30, 31, 32, 36, 38, 41, 47, 49, 61, 65, 67, 70, 82, 87, 119, 137, 138, 150, 152, 157, 165, 167, 176, 177, 178, 180], "m6": [10, 11, 12, 119, 165], "speed": [10, 29, 34, 35, 45, 107, 110, 127, 152, 154, 165], "quiz": [10, 11, 12, 19, 20, 21, 30, 31, 38, 41, 47, 57, 59, 61, 65, 67, 70, 156, 165, 167, 168, 169, 176, 178, 180], "bag": [11, 13, 15, 16, 111, 113, 119, 120, 121, 122, 165], "introductori": [11, 140, 165], "forest": [11, 13, 14, 15, 17, 18, 37, 110, 114, 115, 117, 118, 120, 123, 124, 127, 128, 165], "togeth": [13, 14, 70, 75, 83, 84, 91, 96, 97, 99, 101, 111, 117, 141, 161, 165], "ensembl": [13, 14, 17, 18, 29, 60, 88, 90, 92, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 147, 148, 150, 152, 154, 155], "famili": [13, 14, 39, 58, 60, 76, 82, 84, 88, 120, 151], "techniqu": [13, 33, 76, 110], "bootstrap": [13, 14, 18, 119, 120, 121, 122, 165], "ii": [13, 22, 79, 83, 137], "belong": [13, 18, 49, 82, 86, 87, 97, 100, 108, 140, 147, 157, 177], "former": [13, 75, 76, 84, 127, 142], "strategi": [13, 14, 18, 22, 23, 24, 25, 29, 49, 62, 79, 81, 83, 86, 89, 91, 93, 94, 96, 97, 99, 101, 102, 103, 104, 106, 111, 112, 115, 118, 121, 124, 131, 134, 135, 137, 142, 145, 152, 182, 185], "later": [13, 18, 76, 82, 83, 93, 100, 104, 118, 138, 141, 142, 149, 150, 152, 156], "hyperparamet": [13, 17, 26, 40, 62, 95, 98, 99, 100, 105, 113, 117, 120, 122, 129, 132, 133, 136, 147, 149, 156, 170, 171, 178, 179, 180, 181, 182, 183], "allow": [13, 14, 29, 45, 68, 76, 79, 82, 84, 87, 95, 100, 104, 106, 109, 110, 119, 126, 129, 130, 133, 134, 138, 139, 140, 143, 146, 152, 154, 161, 162, 170, 179, 182, 183], "technic": [13, 22, 33, 36, 39, 58, 73, 170, 182], "skill": [13, 22, 33, 39, 58, 73, 170, 182], "carri": [13, 22, 33, 39, 49, 58, 73, 87, 98, 109, 128, 170, 182], "basic": [13, 22, 33, 36, 39, 52, 58, 73, 102, 104, 110, 122, 145, 170, 182], "usag": [13, 22, 33, 39, 58, 82, 106, 107, 108, 109, 121, 152, 170, 182], "mainli": [13, 14, 22, 33, 39, 76, 106, 157, 170], "around": [13, 22, 33, 39, 76, 82, 93, 97, 100, 103, 104, 105, 107, 110, 141, 142, 145, 170], "overfit": [13, 16, 18, 22, 29, 33, 39, 45, 53, 55, 58, 60, 61, 62, 63, 98, 99, 103, 110, 111, 112, 115, 119, 120, 121, 124, 128, 133, 141, 152, 156, 161, 165, 170, 172, 175], "valid": [13, 18, 22, 23, 24, 25, 26, 29, 33, 34, 39, 40, 45, 49, 58, 59, 60, 62, 67, 68, 75, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 109, 110, 115, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 129, 131, 133, 135, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 154, 155, 161, 162, 165, 170, 175, 177, 179, 182, 183, 185], "principl": [13, 22, 34, 142], "through": [13, 22, 29, 33, 36, 39, 58, 73, 95, 100, 105, 110, 116, 125, 133, 139, 140, 143, 146, 150, 170, 179, 182], "hour": [13, 22, 39, 49, 58, 73, 76, 79, 81, 82, 83, 84, 86, 87, 88, 150, 151, 154, 170, 182], "saw": [14, 29, 40, 82, 84, 87, 88, 104, 105, 117, 119, 133, 137, 140, 141, 143, 146, 150, 152, 153, 154, 157, 161, 162, 163, 171], "parallel": [14, 16, 117, 152, 153, 156, 179], "sequenti": [14, 16, 55, 84, 118, 119, 153, 179], "intern": [14, 45, 68, 84, 88, 99, 104, 111, 112, 115, 116, 124, 125, 133, 145, 147, 150, 151, 152, 179], "machineri": [14, 111, 117], "art": 14, "learn": [14, 16, 17, 23, 24, 27, 28, 29, 34, 37, 38, 40, 43, 46, 53, 60, 62, 66, 68, 70, 71, 74, 76, 79, 80, 82, 84, 85, 86, 87, 88, 89, 91, 95, 96, 97, 99, 100, 101, 102, 103, 104, 108, 109, 111, 114, 116, 118, 119, 121, 123, 125, 126, 127, 128, 129, 132, 133, 136, 138, 140, 141, 142, 143, 145, 146, 147, 150, 152, 153, 155, 158, 162, 171, 172, 173, 174, 180, 181, 183, 185], "earli": [14, 29, 115, 116, 124, 125], "stop": [14, 29, 89, 91, 94, 101, 107, 115, 116, 119, 124, 125], "stack": 14, "By": [15, 18, 29, 46, 49, 76, 84, 87, 99, 102, 105, 107, 121, 129, 133, 142, 145, 147, 160, 164, 177], "default": [15, 18, 27, 28, 46, 49, 62, 68, 79, 80, 84, 85, 87, 95, 100, 102, 107, 113, 119, 120, 122, 132, 133, 136, 142, 143, 144, 145, 146, 147, 151, 152, 177, 182], "baggingclassifi": [15, 121], "baggingregressor": [15, 112, 113, 120, 121, 122], "draw": [15, 29, 76, 96, 101, 112, 119, 127, 154, 157, 179], "replac": [15, 29, 87, 106, 107, 109, 112], "without": [15, 36, 38, 49, 62, 76, 80, 83, 85, 94, 97, 99, 100, 103, 104, 106, 107, 108, 119, 120, 127, 128, 131, 133, 135, 137, 141, 142, 143, 145, 146, 165, 185], "d": [15, 16, 17, 18, 20, 25, 27, 29, 37, 43, 45, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 76, 83, 97, 165, 172, 177, 179, 181, 185], "all": [15, 16, 17, 18, 24, 26, 27, 28, 29, 37, 44, 45, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 79, 80, 82, 83, 84, 85, 87, 90, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 127, 133, 134, 138, 139, 142, 145, 147, 149, 150, 151, 152, 153, 156, 157, 160, 162, 164, 172, 173, 175, 177, 179, 181, 185], "answer": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 87, 106, 156, 172, 173, 174, 175, 177, 179, 181, 185], "hint": [15, 28, 29, 49, 62, 75, 77, 78, 80, 81, 85, 86, 90, 92, 133, 185], "those": [15, 28, 58, 82, 96, 101, 112, 118, 133, 138, 145, 150, 152, 156, 174, 181, 185], "base_estim": [15, 122], "decid": [15, 22, 76, 82, 104, 109, 126, 129, 131, 135, 152], "resampl": [15, 53, 99, 107, 111, 133], "perform": [15, 17, 18, 19, 22, 23, 24, 26, 29, 34, 35, 49, 62, 66, 68, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 133, 138, 141, 142, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 161, 170, 177, 179, 182, 183, 185], "correct": [16, 17, 18, 29, 62, 83, 85, 111, 117, 119, 142, 148, 154, 155, 161, 185], "statement": [16, 18, 27, 29, 62, 179, 185], "simultan": 16, "slightli": [16, 76, 85, 87, 88, 104, 107, 111, 112, 119, 120, 121, 124], "histogram": [16, 29, 68, 76, 77, 78, 84, 96, 101, 106, 109, 116, 118, 125, 140, 150, 154], "acceler": [16, 29, 107, 118], "subsampl": [16, 109, 121, 126, 129], "origin": [16, 68, 79, 82, 83, 87, 88, 102, 103, 106, 111, 112, 117, 118, 121, 131, 135, 138, 139, 145, 157, 158, 162], "bin": [16, 76, 84, 94, 97, 101, 104, 105, 106, 107, 108, 109, 118, 153, 154], "numer": [16, 49, 66, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 96, 101, 104, 106, 107, 109, 131, 133, 135, 138, 149, 150, 151, 156, 165, 177, 185], "tend": [16, 29, 97, 119, 120, 133, 145, 152], "true": [16, 18, 27, 29, 49, 55, 60, 62, 68, 83, 94, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 127, 130, 131, 133, 134, 135, 140, 142, 145, 147, 149, 150, 152, 156, 175, 179, 185], "shallow": [17, 111, 117, 119, 161], "deeper": [17, 94, 95, 98, 100, 104, 105, 111, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 157, 159, 160, 161, 162, 163, 164], "exist": [17, 76, 79, 97], "maximum": [17, 29, 84, 87, 99, 105, 138, 142, 150, 154, 157, 159, 160, 162, 163, 164, 172, 175], "depth": [17, 18, 36, 77, 78, 105, 109, 111, 117, 118, 119, 120, 131, 132, 135, 136, 140, 148, 155, 157, 158, 159, 160, 161, 162, 163, 164, 172, 175, 177], "rate": [17, 29, 83, 94, 98, 104, 107, 119, 142, 150, 153, 155], "option": [17, 84, 87, 94, 102, 104, 107, 115, 124, 182, 185], "reduc": [17, 18, 40, 45, 49, 93, 97, 98, 118, 119, 120, 121, 127, 133, 134], "sensit": [17, 53, 141, 142, 153, 156, 171], "program": [18, 29, 36, 49, 62, 73, 75, 97, 126, 129, 177, 185], "notic": [18, 84, 100, 104, 109, 110, 133, 140, 142, 147, 149, 156], "tradit": 18, "panda": [18, 29, 36, 49, 62, 66, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 121, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 177, 179, 185], "pd": [18, 29, 49, 62, 66, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 121, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 177, 179, 185], "read_csv": [18, 29, 49, 62, 66, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 106, 107, 108, 111, 114, 121, 123, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 177, 179, 185], "csv": [18, 29, 49, 62, 66, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 106, 107, 108, 111, 114, 121, 123, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 177, 179, 185], "feature_nam": [18, 49, 106, 109, 114, 123, 130, 133, 134, 137, 139, 140, 141, 157, 158, 160, 161, 162, 163, 164], "culmen": [18, 77, 78, 111, 131, 132, 135, 136, 140, 157, 158, 159, 161, 163, 185], "mm": [18, 78, 111, 114, 123, 130, 131, 132, 134, 135, 136, 137, 139, 140, 157, 158, 159, 160, 161, 162, 163, 164, 185], "flipper": [18, 114, 123, 130, 131, 134, 135, 137, 139, 158, 160, 161, 162, 164, 185], "target_nam": [18, 29, 49, 62, 75, 79, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 106, 107, 114, 121, 123, 130, 131, 133, 134, 135, 137, 139, 141, 148, 150, 151, 152, 154, 155, 160, 161, 162, 164, 177, 185], "bodi": [18, 77, 78, 107, 114, 123, 130, 131, 134, 135, 137, 139, 158, 160, 161, 162, 164, 185], "mass": [18, 29, 114, 123, 130, 131, 134, 135, 137, 139, 158, 160, 161, 162, 164, 185], "dropna": [18, 131, 135, 185], "frac": [18, 29], "random_st": [18, 37, 82, 84, 86, 88, 94, 95, 99, 100, 101, 102, 103, 104, 105, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 132, 133, 136, 140, 141, 142, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 161, 163, 177], "reset_index": [18, 132, 136, 140], "drop": [18, 29, 37, 49, 62, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 106, 107, 108, 109, 110, 121, 142, 143, 144, 145, 146, 147, 148, 150, 152, 154, 155, 177], "therefor": [18, 29, 75, 76, 79, 84, 86, 88, 94, 97, 98, 99, 101, 104, 105, 109, 111, 117, 118, 119, 121, 127, 128, 129, 133, 134, 138, 140, 141, 142, 145, 147, 152, 156, 161], "randomli": [18, 29, 99, 101, 104, 110, 112, 121, 154], "shuffl": [18, 37, 82, 97, 99, 102, 103, 104, 110, 116, 125, 142, 145], "break": [18, 97, 133], "spuriou": 18, "troubl": [18, 102], "outsid": [18, 150, 157, 160, 164], "scope": [18, 76, 138, 145, 147], "regressor": [18, 24, 28, 29, 40, 46, 49, 83, 84, 94, 98, 103, 104, 105, 112, 113, 116, 117, 118, 119, 120, 121, 122, 124, 125, 133, 138, 145, 171, 174, 177], "sklearn": [18, 29, 45, 49, 62, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 159, 161, 162, 163, 164, 177, 179, 181, 185], "randomforestregressor": [18, 110, 117, 119, 121, 123, 124], "except": [18, 89, 91, 143, 146], "exact": [18, 29, 117], "fold": [18, 25, 29, 49, 62, 75, 79, 97, 102, 104, 110, 116, 125, 127, 128, 129, 130, 131, 133, 134, 135, 144, 147, 152, 154, 156, 177, 185], "model_select": [18, 29, 49, 62, 79, 81, 82, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 135, 136, 140, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 159, 161, 163, 177, 179, 185], "cross_valid": [18, 29, 49, 62, 68, 75, 79, 87, 88, 89, 90, 91, 92, 93, 94, 95, 100, 101, 102, 105, 109, 110, 116, 117, 118, 120, 125, 127, 128, 133, 135, 143, 144, 146, 147, 150, 151, 152, 177, 185], "cv": [18, 29, 49, 68, 75, 79, 88, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 110, 116, 120, 125, 128, 133, 135, 143, 146, 147, 150, 152, 154, 155, 161, 177, 179, 185], "store": [18, 29, 76, 82, 84, 94, 96, 101, 102, 104, 106, 107, 108, 112, 120, 127, 128, 133, 137, 141, 149, 150, 156, 185], "return_train_scor": [18, 29, 62, 105, 133], "count": [18, 49, 62, 75, 76, 78, 82, 84, 86, 87, 94, 97, 102, 106, 107, 108, 109, 157, 177, 185], "rang": [18, 40, 49, 62, 68, 75, 82, 84, 97, 99, 102, 104, 107, 108, 109, 110, 112, 133, 139, 152, 153, 154, 156, 158, 160, 164, 174, 177, 179, 185], "substanti": [18, 49, 75, 177, 185], "almost": [18, 49, 75, 83, 92, 104, 110, 136, 139, 145, 152, 163, 177], "100": [18, 49, 62, 82, 83, 94, 98, 101, 104, 105, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 133, 138, 141, 142, 145, 149, 154, 155, 156, 185], "again": [18, 95, 100, 110, 112, 115, 124, 138, 142, 153], "curv": [18, 43, 60, 62, 95, 100, 115, 124, 139, 142, 165], "n_estim": [18, 111, 112, 115, 117, 118, 119, 120, 121, 122, 123, 124], "20": [18, 29, 62, 76, 78, 87, 93, 94, 99, 104, 105, 106, 107, 108, 109, 115, 119, 120, 122, 124, 131, 133, 135, 142, 147, 148, 149, 154, 155, 156, 158], "200": [18, 62, 75, 79, 97, 107, 117, 118, 154], "500": [18, 62, 87, 88, 91, 104, 107, 109, 145, 153, 154], "1_000": [18, 29, 97, 115, 124], "decreas": [18, 29, 49, 55, 60, 84, 110, 118, 127, 133, 145, 150, 156], "becom": [18, 95, 98, 100, 105, 110, 118, 119, 150, 179], "reach": [18, 98, 105, 115, 124, 150, 153, 161, 179], "plateau": [18, 98, 115, 124], "experi": [18, 36, 49, 62, 73, 81, 86, 95, 97, 98, 99, 100, 104, 105, 109, 115, 116, 118, 124, 125, 141, 143, 146, 156, 159, 162, 163], "instead": [18, 29, 49, 62, 75, 79, 83, 84, 87, 89, 90, 91, 92, 94, 95, 97, 98, 100, 101, 104, 112, 117, 119, 120, 121, 133, 138, 140, 142, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 158, 162, 163, 177], "max_depth": [18, 105, 111, 112, 115, 116, 117, 119, 120, 124, 125, 138, 157, 162, 163, 164, 177], "limit": [18, 29, 32, 34, 42, 58, 60, 63, 82, 88, 104, 105, 112, 133, 138, 141, 145, 154, 158, 160, 164, 165], "gap": [18, 105, 133], "begin": [18, 83, 115, 124, 133, 152], "consid": [18, 44, 62, 71, 75, 87, 103, 105, 106, 109, 110, 111, 117, 118, 119, 121, 133, 138, 143, 146, 157, 163, 172, 181, 185], "none": [18, 49, 95, 97, 100, 104, 106, 107, 108, 109, 112, 115, 119, 120, 124, 132, 136, 153, 157, 162, 163, 185], "rf_1_tree": 18, "cv_results_tre": 18, "train_scor": [18, 29, 105, 133], "return": [18, 28, 29, 68, 79, 82, 83, 87, 89, 91, 110, 112, 117, 130, 133, 134, 139, 142, 143, 146, 150, 151, 153, 154, 179], "arrai": [18, 29, 43, 44, 68, 79, 82, 83, 84, 85, 87, 88, 97, 98, 104, 105, 110, 111, 112, 115, 118, 123, 124, 133, 140, 142, 146, 150, 157, 163], "83120264": 18, "83309064": 18, "83195043": 18, "84834224": 18, "85790323": 18, "86235297": 18, "84791111": 18, "85183089": 18, "82241954": 18, "85045978": 18, "perfect": [18, 42, 58, 94, 104, 110, 117, 126, 128, 129, 141, 142, 161], "r2": [18, 28, 103, 109, 120, 125, 145, 147], "surpris": [18, 86, 97, 102, 103, 126, 129, 138, 157, 163], "memor": [18, 83, 103, 104, 105], "expect": [18, 29, 68, 76, 78, 82, 87, 88, 99, 102, 103, 104, 109, 112, 119, 129, 131, 133, 135, 141, 145, 147, 152, 156, 161], "itself": [18, 84, 97, 99, 100, 104, 108, 112, 145, 152, 182], "automat": [18, 68, 76, 82, 84, 87, 89, 91, 104, 151, 152, 177, 182], "prevent": [18, 87, 91, 112, 119, 179], "max_it": [18, 29, 84, 87, 88, 91, 97, 118, 119, 125], "recal": [18, 27, 62, 87, 99, 104, 118, 120, 142, 151, 152, 154, 156, 185], "averag": [18, 29, 62, 83, 94, 97, 101, 102, 104, 107, 109, 110, 112, 117, 118, 119, 120, 121, 124, 127, 133, 137, 142, 143, 145, 146, 147, 185], "small": [18, 40, 78, 79, 88, 97, 100, 102, 104, 105, 110, 112, 117, 118, 119, 133, 136, 138, 148, 150, 155, 179], "behav": [18, 95, 100, 101, 133, 177], "high": [18, 29, 37, 53, 55, 60, 66, 76, 78, 82, 86, 87, 100, 105, 106, 107, 108, 109, 110, 150, 151, 154], "optimum": 18, "m7": [19, 20, 21, 30, 31, 165], "stratif": [20, 165], "framework": [22, 23, 34, 58, 59, 98, 102, 105, 116, 125, 144, 147, 152, 165, 182], "keep": [22, 29, 76, 93, 97, 104, 106, 107, 109, 110, 127, 128, 129, 132, 136, 140, 141, 152, 154], "mind": [22, 76, 104, 110, 119, 126, 127, 128, 129, 141, 154], "metric": [22, 27, 29, 68, 79, 83, 98, 103, 104, 108, 112, 113, 115, 122, 123, 124, 127, 131, 133, 134, 135, 137, 138, 143, 144, 145, 146, 147, 153, 162, 165, 185], "besid": [22, 23, 33, 39, 82, 88, 90, 92, 94, 97, 98, 116, 125, 127, 136, 157, 170, 183], "insight": [22, 33, 36, 49, 66, 76, 103, 105, 112, 126, 129, 139, 140, 145, 154], "addit": [22, 29, 71, 79, 83, 87, 104, 107, 109, 115, 116, 120, 121, 124, 125, 133, 138, 139, 142, 145, 150, 151, 152, 154, 156, 177], "necess": [22, 104], "appropri": [22, 76], "nest": [22, 23, 26, 119, 133, 148, 150, 152, 155, 165, 177, 183, 185], "wise": [23, 152, 153, 183], "encount": [23, 75, 87, 89, 91, 102], "show": [23, 39, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 93, 98, 99, 102, 104, 105, 106, 109, 111, 112, 117, 119, 120, 121, 128, 130, 131, 133, 134, 135, 137, 138, 139, 141, 142, 143, 146, 150, 151, 152, 153, 154, 156, 157, 159, 162, 163, 164, 170, 179, 182], "comparison": [23, 40, 99, 120, 142], "remov": [24, 35, 49, 76, 110, 118, 129, 131, 135, 140, 150, 153, 157, 162, 163, 185], "dummi": [24, 49, 62, 81, 86, 91, 94, 96, 101, 142, 145], "reli": [24, 76, 82, 84, 110, 111, 128, 142], "ye": [24, 42, 44], "whatev": [24, 153, 157], "chosen": [24, 87, 91, 108, 115, 124, 145, 183], "record": [25, 29, 51, 76, 83, 87, 104, 107, 108, 110], "suppos": [25, 87, 97], "imbalanc": [25, 62, 76, 101, 133, 142, 185], "addition": [25, 84, 133], "suspect": 25, "systemat": [25, 53, 60, 100, 145, 151], "bias": 25, "due": [25, 29, 86, 88, 102, 117, 121, 147, 157], "factor": [25, 29, 94, 145], "devic": [25, 29], "socioeconom": 25, "most": [25, 29, 49, 76, 82, 83, 86, 87, 91, 92, 95, 96, 97, 100, 101, 104, 106, 110, 111, 112, 118, 127, 133, 137, 142, 143, 146, 150, 153, 157, 162, 163, 172, 174, 177, 179], "suitabl": 25, "abil": [25, 105, 142, 148, 155], "stratifi": [25, 96, 101, 102, 185], "leav": [25, 83, 95, 100, 119, 154, 161, 163], "inner": [26, 99, 116, 125, 133, 152, 177], "outer": [26, 99, 116, 124, 125, 133, 152, 177, 185], "balanc": [27, 62, 105, 119, 133, 142, 143, 145, 146, 185], "roc": [27, 142], "auc": [27, 142], "precis": [27, 29, 60, 88, 119, 139, 142, 143, 146, 150], "regular": [27, 37, 39, 40, 45, 46, 49, 110, 112, 132, 136, 154, 162, 165, 183], "assum": [27, 29, 44, 45, 55, 71, 91, 102, 103, 110, 133, 138, 140, 177], "logist": [27, 43, 45, 46, 49, 68, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 100, 101, 102, 126, 129, 132, 136, 140, 142, 151, 157], "stronger": [27, 107, 112, 156], "lead": [27, 60, 76, 87, 88, 91, 97, 103, 117, 119, 120, 121, 133, 142, 149, 152, 153, 154, 156], "lower": [27, 28, 29, 49, 55, 91, 97, 98, 101, 104, 107, 110, 119, 124, 133, 135, 142, 145, 147, 152, 156], "r": [28, 100, 103, 104, 109, 110, 144, 145, 147, 157, 162, 163], "absolut": [28, 29, 49, 94, 98, 104, 105, 113, 114, 115, 117, 118, 122, 123, 124, 131, 134, 135, 137, 138, 144, 145, 147], "median": [28, 93, 94, 99, 104, 109, 110, 120, 125, 127, 128, 133, 145, 146, 173, 174], "cross_val_scor": [28, 62, 97, 99, 103, 104, 121, 129, 143, 144, 146, 147, 148, 155], "model_a": 28, "neg_mean_squared_error": [28, 133, 147], "strictli": 28, "model_b": 28, "rememb": [28, 49, 76, 112, 131, 135, 181, 185], "alia": 28, "neg": [28, 29, 49, 68, 104, 105, 110, 133, 134, 139, 142], "guarante": [28, 110, 161], "either": [28, 71, 83, 97, 100, 102, 126, 127, 129, 134, 140, 142, 145], "open": [29, 49, 62, 75, 80, 82, 85, 103, 106, 107, 177], "bike_rid": [29, 107], "command": [29, 49, 62, 75, 177, 185], "cycl": [29, 107], "index_col": [29, 103, 107, 153, 154, 179], "parse_d": [29, 103, 107], "index": [29, 49, 76, 83, 97, 102, 103, 107, 110, 112, 118, 127, 131, 133, 135, 136, 140, 146, 150, 152, 157], "appendix": [29, 94, 95, 98, 100, 104, 105, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 157, 159, 160, 161, 162, 163, 164], "remind": 29, "cheap": [29, 51, 88], "sensor": [29, 76, 107], "gp": [29, 107], "cyclist": [29, 107], "via": [29, 36, 79, 87, 99, 105, 109, 116, 117, 118, 120, 121, 125, 127, 150, 151, 161], "meter": [29, 107], "expens": [29, 75, 118, 150, 183], "blindli": 29, "introduc": [29, 36, 83, 84, 104, 110, 112, 127, 133, 135, 138, 139, 145, 147, 165], "flavor": 29, "classic": 29, "newton": 29, "second": [29, 37, 84, 87, 90, 92, 96, 101, 102, 107, 111, 117, 118, 141, 145, 154, 161, 163], "p_": 29, "meca": 29, "rho": 29, "sc_x": 29, "v_": 29, "c_r": 29, "mg": 29, "co": 29, "alpha": [29, 45, 46, 49, 76, 97, 100, 109, 110, 111, 112, 117, 123, 133, 134, 136, 137, 138, 139, 140, 141, 145, 157, 161, 162, 163, 164], "sin": 29, "ma": 29, "v_d": 29, "air": 29, "densiti": 29, "kg": [29, 158], "m": [29, 87, 97], "frontal": 29, "c_x": 29, "drag": 29, "coeffici": [29, 37, 40, 44, 49, 109, 133, 136, 138, 139, 140, 145, 172], "v_a": 29, "roll": 29, "rider": 29, "bicycl": 29, "standard": [29, 49, 76, 79, 84, 88, 89, 91, 96, 97, 99, 101, 104, 105, 110, 116, 125, 133, 141, 142, 152], "graviti": 29, "radian": 29, "equat": [29, 137, 140], "complex": [29, 49, 63, 82, 88, 89, 91, 93, 98, 106, 117, 143, 146, 161, 162], "term": [29, 76, 83, 84, 103, 104, 112, 114, 117, 118, 121, 123, 127, 139, 162], "within": [29, 34, 79, 97, 99, 102, 104, 109, 110, 112, 116, 118, 125, 127, 133, 144, 147, 152, 153, 157, 164], "parenthesi": 29, "produc": 29, "fight": [29, 39], "wind": 29, "resist": 29, "tire": 29, "floor": 29, "third": [29, 117], "hill": 29, "forward": [29, 107], "fourth": 29, "last": [29, 36, 49, 71, 87, 102, 106, 108, 133, 138, 142, 143, 146, 157, 162, 163], "hi": [29, 108, 154], "simplifi": [29, 49, 103, 104, 127, 140, 156, 158, 177], "beta_": 29, "closer": [29, 102, 107, 133, 140], "previous": [29, 75, 87, 88, 95, 100, 103, 106, 111, 117, 118, 119, 120, 138, 140, 145, 148, 150, 152, 154, 155, 161, 162], "part": [29, 76, 87, 88, 99, 105, 110, 118, 129, 130, 133, 134, 142, 159, 163], "cube": 29, "multipli": [29, 147], "sine": 29, "angl": 29, "arc": 29, "tangent": 29, "np": [29, 49, 94, 95, 97, 98, 100, 101, 102, 105, 107, 109, 110, 111, 112, 115, 117, 118, 121, 123, 124, 126, 127, 129, 130, 133, 134, 137, 138, 139, 141, 142, 144, 145, 147, 149, 153, 156, 161, 162, 164, 174, 179], "arctan": 29, "ourself": [29, 142], "clip": 29, "brake": 29, "preprocess": [29, 36, 49, 62, 67, 68, 75, 76, 79, 87, 88, 89, 90, 91, 92, 93, 95, 97, 100, 101, 102, 109, 110, 112, 118, 121, 132, 133, 135, 136, 138, 140, 141, 145, 148, 150, 151, 152, 154, 155, 156, 165, 177, 179, 181, 185], "linear_model": [29, 45, 49, 75, 79, 82, 84, 87, 88, 89, 91, 93, 97, 101, 102, 109, 110, 112, 129, 132, 133, 135, 136, 137, 138, 140, 141, 142, 145, 147, 151, 157, 162, 164, 177, 179, 181], "ridgecv": [29, 49, 109, 110, 133], "shufflesplit": [29, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 133], "n_split": [29, 94, 98, 99, 101, 102, 103, 104, 105, 110, 125, 133, 146, 152], "mae": [29, 124, 131, 134, 135, 147], "return_estim": [29, 49, 104, 109, 110, 116, 120, 125, 127, 133, 152, 185], "subsequ": [29, 73, 97, 116, 119, 125, 126, 129, 133, 135, 181, 182], "Be": [29, 76, 87, 88, 89, 91, 105, 119, 141, 150, 151, 177], "awar": [29, 33, 34, 76, 83, 87, 88, 89, 91, 93, 105, 106, 119, 141, 150, 151, 177], "investig": [29, 84, 103, 110, 113, 116, 120, 122, 125, 127, 157], "consequ": [29, 102, 112, 118, 121], "003": [29, 79, 88, 92, 151, 152], "obtain": [29, 49, 62, 75, 79, 83, 87, 88, 89, 91, 93, 97, 99, 101, 103, 104, 107, 109, 110, 113, 119, 120, 122, 129, 133, 137, 141, 142, 145, 152, 153, 154, 155, 157, 179], "closest": [29, 83], "watt": [29, 107], "70": [29, 76, 93, 103, 106], "90": [29, 76, 82, 84, 94, 97, 102, 134, 157, 162, 163], "neg_mean_absolute_error": [29, 94, 98, 104, 105, 117, 118, 119, 122, 124, 135, 147], "request": [29, 87, 118, 133], "h": [29, 110], "beta": 29, "cadenc": [29, 107], "turn": [29, 107, 131, 135], "pedal": [29, 107], "rotat": [29, 76, 97, 107], "per": [29, 49, 76, 79, 81, 82, 83, 84, 86, 87, 88, 99, 104, 107, 109, 118, 121, 138, 142, 150, 151, 152, 154], "minut": [29, 33, 88, 107, 154], "beat": [29, 107], "1000": [29, 49, 88, 107, 119, 124, 125, 142, 144, 145, 147, 156], "activ": [29, 71, 153, 179], "early_stop": [29, 119, 125], "40": [29, 76, 78, 82, 83, 84, 88, 104, 106, 119, 122, 131, 134, 135, 139, 149, 150, 151, 154, 156, 158], "80": [29, 75, 93, 94, 106, 148, 155], "consider": [29, 119, 139], "test_scor": [29, 79, 87, 88, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 109, 117, 118, 120, 125, 127, 128, 129, 133, 135, 151, 152, 155, 157, 163], "dictionari": [29, 68, 79, 104], "made": [29, 35, 43, 76, 95, 97, 100, 103, 104, 108, 117, 142, 147, 151], "ignor": [29, 75, 87, 88, 90, 91, 92, 93, 94, 110, 156], "datafram": [29, 49, 62, 75, 76, 77, 78, 82, 83, 84, 87, 88, 93, 94, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 117, 119, 120, 122, 123, 125, 127, 128, 133, 138, 139, 141, 142, 146, 147, 150, 152, 153, 154, 156, 157, 161, 162, 164, 177, 185], "account": [29, 83, 94, 97, 106, 110, 142, 177], "date": [29, 88, 97, 106, 107], "hesit": 29, "uniqu": [29, 62, 82, 87, 97, 102, 112, 118, 150, 154], "dai": 29, "datetimeindex": [29, 107], "went": 29, "df": [29, 75, 153], "capac": [29, 98], "leaveonegroupout": [29, 103], "numpi": [29, 36, 66, 68, 73, 84, 94, 97, 98, 100, 101, 102, 105, 107, 109, 110, 111, 112, 117, 118, 123, 124, 126, 127, 129, 130, 133, 134, 137, 138, 139, 141, 142, 144, 145, 147, 153, 156, 161, 162, 164, 179], "had": [29, 104, 110, 138, 140], "indic": [29, 76, 88, 97, 104, 107, 109, 110, 112, 127, 130, 133, 134, 156, 157], "differenti": [29, 73, 76, 152, 158], "integ": [29, 49, 71, 79, 82, 87, 89, 91, 97, 106, 108, 110, 112, 154, 156, 185], "align": [29, 108, 138, 154], "pessimist": 29, "optimist": [29, 83, 97, 99, 104], "deviat": [29, 49, 79, 84, 97, 99, 104, 105, 110, 116, 125, 133, 152], "analys": [29, 82, 110], "reus": [29, 130, 134, 143, 146, 152], "train_indic": 29, "test_indic": 29, "list": [29, 36, 62, 87, 90, 92, 102, 110, 112, 113, 115, 122, 124, 133, 143, 144, 146, 147, 151, 157, 162, 163, 185], "data_linear_model_train": 29, "data_linear_model": 29, "iloc": [29, 85, 102, 107, 109, 110, 111, 112, 117, 150, 161], "data_linear_model_test": 29, "data_train": [29, 82, 84, 88, 103, 104, 112, 113, 114, 115, 117, 119, 122, 123, 124, 129, 132, 136, 140, 142, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 160, 162, 163, 164], "data_test": [29, 82, 83, 84, 85, 88, 103, 104, 112, 113, 114, 115, 117, 119, 122, 123, 124, 129, 132, 136, 140, 142, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 161, 162, 163, 164], "target_train": [29, 82, 84, 86, 88, 102, 103, 104, 112, 113, 114, 115, 117, 119, 122, 123, 124, 129, 132, 136, 140, 142, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 160, 162, 163, 164], "target_test": [29, 82, 83, 84, 85, 86, 88, 102, 103, 104, 113, 114, 115, 119, 122, 123, 124, 129, 132, 136, 140, 142, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 163], "scatter": [29, 78, 109, 112, 114, 117, 123, 141, 158, 160, 162, 164], "catastroph": [29, 84], "portion": 29, "time_slic": 29, "slice": 29, "2020": [29, 107], "18": [29, 36, 76, 78, 82, 92, 94, 106, 107, 119, 122, 131, 135, 138, 150, 151, 153, 154, 156, 157, 158, 162, 163], "17": [29, 76, 78, 82, 84, 94, 104, 106, 107, 108, 109, 110, 118, 119, 122, 131, 133, 135, 140, 143, 145, 146, 147, 153, 156, 157, 158], "data_test_linear_model_subset": 29, "data_test_subset": [29, 129], "target_test_subset": 29, "pm": 29, "until": [29, 119, 142], "accur": [29, 111, 133, 142], "motiv": [33, 120], "known": [33, 76, 108, 109, 133, 134, 140, 142, 145, 150, 157], "caveat": [33, 126, 129, 152, 165], "practic": [33, 60, 76, 79, 82, 83, 86, 93, 99, 101, 102, 104, 119, 121, 133, 141, 142, 143, 145, 146, 152, 153, 154], "magic": [34, 103], "tool": [34, 36, 79, 88, 112, 140, 152, 154], "margin": [34, 97, 110], "gain": [34, 36, 49, 66, 76, 79, 81, 82, 83, 84, 86, 87, 88, 98, 113, 122, 126, 127, 129, 140, 145, 150, 151, 154], "tackl": [34, 49, 60, 128], "selector": [34, 87, 88, 89, 90, 91, 92, 126, 129, 148, 150, 152, 154, 155], "recurs": 34, "main": [35, 49, 79, 84, 90, 92, 119, 127, 138, 156, 165], "advantag": [35, 79, 127], "fine": [35, 40, 88, 92, 152, 156, 182], "noisi": [35, 63, 105, 110, 112, 141, 156, 161], "teach": [36, 52], "beginn": 36, "strong": [36, 110, 136, 156], "background": 36, "bring": 36, "vast": 36, "busi": 36, "intellig": 36, "industri": 36, "scientif": [36, 121], "discoveri": 36, "pillar": 36, "modern": 36, "field": [36, 76, 185], "central": 36, "easili": [36, 76, 83, 84, 87, 161], "yet": [36, 75, 88, 90, 92, 133, 138], "dovetail": 36, "ecosystem": 36, "languag": 36, "step": [36, 49, 62, 76, 82, 83, 84, 88, 93, 119, 121, 127, 128, 131, 133, 135, 138, 141, 144, 147, 150, 151, 152, 154, 185], "lesson": [36, 151], "fundament": [36, 58, 100, 145], "stone": 36, "artifici": 36, "mine": 36, "cookbook": 36, "failur": [36, 58], "session": [36, 152, 154], "octob": 36, "2022": 36, "month": [36, 108, 142], "enrol": 36, "quizz": 36, "execut": [36, 131, 135, 148, 154, 155, 179], "platform": 36, "purpos": [36, 87, 88, 99, 101, 103, 104, 105, 114, 123, 126, 127, 129, 133, 142, 151, 177], "educ": [36, 49, 76, 82, 87, 88, 89, 90, 91, 92, 121, 140, 148, 150, 152, 154, 155], "write": [36, 77, 80, 81, 89, 90, 92, 95, 96, 97, 113, 114, 115, 116, 126, 130, 131, 132, 143, 144, 148, 149, 155, 159, 160], "prior": [36, 73], "matplotlib": [36, 73, 76, 84, 94, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 136, 137, 139, 140, 141, 142, 145, 146, 157, 161, 162, 163, 164], "librari": [36, 73, 76, 156], "quick": [36, 73, 76, 106, 109, 118, 158], "publicli": 36, "cite": 36, "project": [36, 153], "zenodo": 36, "archiv": [36, 93, 97], "doi": 36, "5281": 36, "7220306": 36, "repositori": [36, 104, 109], "inria": 36, "publish": [36, 104, 109], "static": 36, "rocket": 36, "top": [36, 76, 142, 153, 154, 160, 161, 164], "interact": [36, 76, 107, 131, 133, 135, 138, 153, 154, 156, 179], "cell": [36, 76, 80, 82, 84, 85, 88, 93, 99, 104, 111, 117, 118, 133, 137, 138, 141, 142, 150, 152, 154, 157, 162, 163, 164], "binder": 36, "servic": [36, 88], "video": [36, 93, 172], "youtub": 36, "playlist": 36, "channel": 36, "www": [36, 76, 83, 104, 109], "pl2oka_2qdj": 36, "m44koooi7x8tu85wr4ez4f": 36, "version": [36, 84, 106, 118, 120, 140, 154, 157, 162, 163], "host": [36, 154], "fun": 36, "infer": [37, 107, 127, 139, 182], "importance_permut": 37, "correl": [37, 49, 76, 108, 110, 121, 127, 133, 138], "divid": [37, 84, 94, 97, 105, 134, 142, 152, 154], "receiv": [37, 142], "cardin": [37, 87, 110], "independ": [37, 87, 97, 99, 103, 112, 118, 119, 133, 142, 145, 151, 154], "could": [37, 62, 75, 76, 82, 83, 84, 86, 87, 88, 94, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 118, 120, 121, 125, 127, 129, 130, 133, 134, 137, 138, 139, 141, 142, 143, 145, 146, 151, 152, 153, 156, 161], "m4": [38, 41, 47, 165], "parametr": [39, 130, 134, 137, 139, 154, 157, 162, 164, 171], "implic": 39, "dimension": [39, 68, 73, 76, 97, 126, 129, 131, 135, 140, 150, 153, 157], "effect": [39, 45, 49, 61, 62, 84, 95, 99, 100, 109, 110, 112, 119, 120, 121, 132, 136, 162, 165], "relationship": [39, 41, 76, 82, 87, 88, 103, 110, 112, 133, 139, 142, 150, 152, 154, 158, 165], "adjust": [40, 60, 87, 150, 153], "successfulli": [40, 101, 117], "scale": [40, 45, 49, 62, 74, 75, 84, 87, 88, 95, 97, 100, 104, 112, 118, 145, 150, 151, 154, 156, 177, 183, 185], "approxim": [40, 62, 79, 83, 84, 92, 94, 97, 101, 112, 124, 133, 156, 185], "dynam": 40, "linearli": [40, 42, 45, 82, 138, 141], "extra": [40, 107, 143, 146, 152], "beyond": [41, 76, 138, 145, 147, 165], "Is": [42, 44, 81, 86, 106], "linearregress": [43, 45, 133, 135, 137, 138, 145, 147, 162, 164, 177], "coef_": [43, 44, 49, 109, 110, 128, 133, 136, 137, 138, 140, 151, 182], "intercept_": [43, 44, 137, 138], "boundari": [43, 132, 136, 140, 141, 157, 159, 161, 162, 163], "extract": [44, 79, 97, 107, 110, 112, 133, 150, 154, 185], "straight": [44, 88, 138, 140, 141, 162], "float": [44, 49, 107, 109, 118, 154], "robust": [45, 92, 104, 110, 120, 133], "outlier": [45, 94, 109, 133, 147, 161], "wide": [45, 82], "forc": [45, 84, 90, 92, 111, 118, 121, 133, 137], "penal": [45, 133], "scientist": [45, 99], "prepar": 45, "plan": 45, "strength": [45, 49, 132, 133, 136, 154], "penalti": [46, 49, 110, 132, 136], "magnitud": [46, 49, 110, 132, 133, 136, 172], "l2": [46, 132, 136], "l1": [46, 110], "ames_housing_no_miss": [49, 75, 106, 133, 177], "ames_h": [49, 75, 93, 106, 133, 144, 145, 147, 177], "salepric": [49, 75, 93, 106, 133, 144, 145, 147, 177], "numerical_featur": [49, 75, 106, 177], "lotfrontag": [49, 75, 93, 106, 133, 177], "lotarea": [49, 75, 93, 106, 133, 177], "masvnrarea": [49, 75, 106, 177], "bsmtfinsf1": [49, 75, 106, 177], "bsmtfinsf2": [49, 75, 106, 177], "bsmtunfsf": [49, 75, 106, 177], "totalbsmtsf": [49, 75, 106, 177], "1stflrsf": [49, 75, 106, 177], "2ndflrsf": [49, 75, 106, 177], "lowqualfinsf": [49, 75, 106, 177], "grlivarea": [49, 75, 106, 177], "bedroomabvgr": [49, 75, 106, 177], "kitchenabvgr": [49, 75, 106, 177], "totrmsabvgrd": [49, 75, 106, 177], "fireplac": [49, 75, 106, 177], "garagecar": [49, 75, 106, 177], "garagearea": [49, 75, 106, 177], "wooddecksf": [49, 75, 106, 177], "openporchsf": [49, 75, 106, 177], "enclosedporch": [49, 75, 106, 177], "3ssnporch": [49, 75, 106, 177], "screenporch": [49, 75, 93, 106, 177], "poolarea": [49, 75, 93, 106, 133, 177], "miscval": [49, 75, 93, 106, 177], "data_numer": [49, 79, 81, 82, 84, 86, 177], "argument": [49, 62, 80, 84, 85, 87, 89, 91, 107, 157, 162, 163, 185], "largest": [49, 109], "1e0": 49, "000": [49, 51, 75, 91, 94, 102, 104, 109, 117, 118, 126, 129, 140, 145, 155, 156], "1e5": 49, "larger": [49, 84, 87, 105, 119, 124, 138, 139, 148, 149, 152, 155, 156, 174], "express": [49, 63, 75, 92, 95, 100, 104, 109, 110, 117, 131, 135, 138, 141, 153, 156, 161, 179], "notat": 49, "box": [49, 99, 109, 116, 125, 127, 128, 133, 143, 146, 185], "garag": 49, "just": [49, 91, 103, 104, 105, 107, 110, 111, 112, 115, 119, 121, 124, 133, 138, 142], "logspac": [49, 95, 100, 109, 133, 149, 156], "num": [49, 76, 82, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 100, 101, 109, 112, 117, 121, 123, 130, 133, 134, 137, 139, 148, 149, 150, 152, 154, 155, 156], "101": [49, 185], "alpha_": [49, 133], "fall": [49, 104, 145, 154], "snippet": [49, 112, 179], "adult_censu": [49, 66, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 101, 121, 148, 150, 151, 152, 153, 154, 155], "select_dtyp": [49, 75, 106, 144, 145, 147], "dummyclassifi": [49, 62, 81, 86, 91, 96, 101, 142], "frequent": [49, 86, 91, 96, 101, 106, 154, 174], "loss": [49, 76, 79, 81, 82, 83, 84, 86, 87, 88, 145, 147, 150, 151, 154], "week": [49, 76, 79, 81, 82, 83, 84, 86, 87, 88, 150, 151, 154], "hot": [49, 71, 87, 88], "preprocessor": [49, 88, 89, 90, 91, 92, 93, 97, 106, 121, 148, 150, 151, 152, 154, 155, 177, 185], "named_transformers_": 49, "onehotencod": [49, 74, 75, 87, 88, 89, 90, 91, 92, 93, 133], "get_feature_names_out": 49, "categorical_column": [49, 76, 87, 88, 89, 90, 91, 92, 150, 152, 154], "tolist": [49, 106], "numerical_column": [49, 76, 79, 81, 82, 84, 86, 88, 90, 92, 151], "There": [49, 78, 84, 104, 108], "pair": [49, 84, 107, 108, 109, 130, 134, 153], "rel": [49, 91, 96, 101, 104, 120, 128, 138, 142, 145], "country_columbia": 49, "workclass_": [49, 87], "native_country_": 49, "education_doctor": 49, "varianc": [49, 53, 58, 60, 97, 105, 110, 145, 165], "influenc": [49, 98, 105, 110, 133, 138, 145, 154, 170], "studi": [51, 62, 76, 95, 97, 100, 104, 141, 185], "apart": [51, 110], "estat": [51, 104], "thousand": [51, 104, 109, 110], "entertain": 51, "spaciou": 51, "updat": [51, 93, 185], "bedroom": [51, 104, 109, 110], "bathroom": 51, "lakeview": 51, "97630": 51, "1st": [51, 76, 87], "nightlif": 51, "privat": [51, 76, 82, 87, 88, 150, 154], "backyard": 51, "buyer": 51, "market": 51, "kind": [51, 76, 88, 92, 110, 124, 138, 145, 172, 185], "sub": [52, 99, 100, 157], "vocabulari": 52, "low": [55, 66, 76, 78, 82, 86, 97, 107, 109, 110, 112, 119, 142, 157, 161, 179], "littl": [55, 82, 97, 102, 153], "reduct": [55, 110], "steadi": 55, "label": [55, 60, 71, 78, 82, 87, 88, 91, 101, 102, 103, 111, 112, 117, 123, 134, 139, 140, 142, 143, 146, 162, 164], "slow": [55, 92, 119], "tradeoff": [55, 60, 105], "m2": [57, 59, 61, 165], "trade": [58, 60, 79, 161, 165, 170, 172], "off": [58, 60, 76, 79, 94, 106, 142, 161, 165, 170, 172], "character": [58, 110, 142], "why": [58, 62, 68, 76, 88, 96, 101, 107, 110, 136, 147, 179], "aris": [58, 76], "Then": [58, 73, 79, 84, 88, 94, 104, 112, 116, 120, 125, 126, 127, 128, 129, 138, 143, 144, 145, 146, 147, 152, 154, 157], "quantifi": [58, 76, 105, 110, 130, 134, 185], "contrast": [58, 76, 87, 104, 117, 139, 162], "importantli": 58, "emphas": [58, 120], "happen": [60, 68, 76, 89, 91, 121, 132, 135, 136, 157], "suffer": [60, 84, 108], "lack": 60, "captur": [60, 76, 105, 110, 133], "neither": [60, 102], "nor": 60, "still": [60, 79, 84, 87, 88, 92, 105, 109, 110, 111, 113, 122, 133, 138, 145, 153, 154, 161], "variat": [60, 79, 104, 105, 110, 112, 133, 145], "fulli": [60, 87, 104, 115, 119, 124], "determin": [60, 87, 95, 100, 142, 145], "irreduc": 60, "decompos": 60, "chapter": [60, 185], "diagnos": 60, "blood_transfus": [62, 95, 100, 108, 142, 143, 146], "propos": [62, 185], "multiclass": [62, 185], "proport": [62, 98, 101, 108, 142, 145, 185], "twice": [62, 142, 185], "value_count": [62, 76, 77, 78, 86, 87, 102, 106, 108, 142, 185], "most_frequ": [62, 86, 91, 101, 106, 142], "balanced_accuraci": [62, 142, 143, 146, 185], "remaind": [62, 87, 88, 90, 92, 121, 148, 150, 152, 154, 155], "add": [62, 107, 110, 117, 118, 127, 131, 133, 135, 139, 142, 143, 146, 160, 164], "faster": [62, 68, 76, 84, 119, 148, 155], "distanc": [62, 84, 156], "normal": [62, 84, 93, 97, 106, 107, 108, 109, 110, 118, 142, 145, 149, 150, 156], "irrelev": 62, "make_pipelin": [62, 68, 79, 84, 87, 88, 89, 90, 91, 92, 97, 100, 101, 102, 106, 109, 110, 112, 118, 121, 126, 127, 128, 129, 131, 132, 133, 135, 136, 138, 140, 141, 156], "get_param": [62, 95, 100, 113, 122, 151, 181, 185], "n_neighbor": [62, 80, 85, 149, 156, 182, 185], "clearli": [62, 86, 98, 100], "param_rang": [62, 100, 105, 115, 124], "affirm": 62, "highli": [63, 76], "much": [63, 76, 91, 92, 94, 101, 104, 105, 110, 118, 119, 121, 122, 127, 179], "m1": [65, 67, 70, 165], "comma": [66, 76, 106, 107, 108], "file": [66, 76, 82, 83, 106, 107, 108, 143, 146, 157, 162, 163, 185], "alreadi": [66, 76, 82, 83, 84, 100, 110, 119, 121, 133, 149, 154, 156], "packag": [66, 76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "survei": 66, "incom": [66, 76, 82, 86, 94, 104, 109, 110], "seaborn": [66, 76, 77, 78, 84, 107, 108, 109, 110, 111, 112, 117, 123, 134, 136, 137, 138, 139, 140, 141, 150, 153, 157, 158, 161, 162, 163, 164], "visual": [66, 70, 84, 87, 98, 100, 103, 104, 107, 112, 117, 130, 133, 134, 140, 142, 145, 150, 153, 158, 162, 165, 182], "scipi": [66, 119, 122, 154], "organ": [66, 163], "five": [68, 83, 88, 104], "overlap": [68, 78, 79, 112, 147, 154], "lie": 68, "fewer": [68, 145], "jupyt": [70, 82, 84, 85, 88, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164, 165], "categori": [71, 75, 76, 82, 88, 89, 91, 106, 108, 121, 133, 150, 158], "ordin": [71, 75, 88, 91, 118], "string": [71, 82, 87, 88, 89, 91, 104, 106, 143, 146, 147, 152, 185], "meaning": [71, 87, 92, 126, 128, 129, 139, 145, 150], "represent": [71, 82, 84, 85, 87, 88, 90, 92, 93, 98, 99, 104, 108, 109, 111, 118, 121, 133, 137, 141, 142, 150, 152, 154, 157, 161, 163, 164], "compani": [71, 103], "sector": 71, "construct": [71, 112, 121, 154], "retail": 71, "energi": [71, 103, 107], "insur": 71, "phone": 71, "sale": [71, 75, 88], "depart": 71, "employe": 71, "profit": 71, "quarter": [71, 103], "head": [71, 75, 76, 78, 82, 83, 87, 88, 104, 106, 107, 108, 109, 110, 131, 135, 139, 150, 151, 154, 158], "tabl": [73, 76, 119, 121, 150], "progress": [73, 149, 156], "attent": [73, 111], "extend": [73, 82], "mix": [73, 74, 76, 88, 97, 161], "unknown": [73, 87, 89, 91, 121, 145], "notabl": [74, 142], "ordinalencod": [74, 87, 88, 89, 90, 91, 92, 121, 148, 150, 152, 154, 155, 177], "200_000": [75, 93], "astyp": [75, 93, 106, 149, 154, 156, 161], "int": [75, 79, 93, 111, 154], "did": [75, 76, 84, 87, 96, 101, 103, 104, 106, 107, 119, 127, 129, 138, 142, 143, 146, 150, 151, 152, 154, 156, 159, 163, 182], "convert": [75, 104, 111, 112, 123, 156], "info": [75, 97, 106, 107, 108, 109], "examin": [75, 133], "79": [75, 106], "42": [75, 82, 84, 86, 87, 88, 106, 119, 122, 129, 141, 148, 149, 150, 152, 154, 155, 156], "make_column_selector": [75, 87, 88, 89, 90, 91, 92, 121, 148, 150, 152, 154, 155], "shown": [75, 76, 104, 117, 145, 152, 159, 163], "among": [75, 87, 88, 102, 127, 156], "quantit": [75, 82, 117, 130, 134, 137], "exclud": [75, 76, 127], "overallqu": [75, 106], "overallcond": [75, 106], "yearbuilt": [75, 106, 133], "sole": [75, 129, 145], "treat": [75, 88, 93, 133], "issu": [75, 76, 87, 88, 102, 103, 104, 107, 108, 118, 133, 138], "rare": [75, 76, 87, 88, 106, 121, 133], "handle_unknown": [75, 87, 88, 89, 90, 91, 92, 93, 121, 148, 150, 152, 154, 155], "latter": [75, 76, 84, 99, 127, 142], "place": [76, 129, 133], "workflow": 76, "1994": [76, 97], "download": [76, 104, 109], "openml": [76, 83], "webpag": 76, "1590": [76, 83], "manipul": [76, 80, 85, 95, 100, 104], "tutori": 76, "50k": [76, 81, 82, 83, 84, 85, 86, 88, 150, 154], "year": [76, 82, 106, 133, 150], "heterogen": [76, 82, 88, 106, 133], "employ": 76, "covari": 76, "workclass": [76, 82, 87, 88, 150, 152, 154], "marit": [76, 82, 87, 88, 150, 152, 154], "occup": [76, 82, 87, 88, 109, 110, 150, 152, 154], "race": [76, 82, 87, 88, 107, 150, 152, 154], "sex": [76, 82, 87, 88, 150, 152, 154], "countri": [76, 82, 87, 88, 150, 152, 154], "11th": [76, 82, 87, 150, 154], "marri": [76, 82, 87, 88, 150, 154], "op": [76, 82, 87, 150, 154], "inspct": [76, 82, 87, 150, 154], "own": [76, 82, 87, 88, 119, 150, 154], "child": [76, 82, 87, 88, 150, 154], "male": [76, 82, 87, 88, 150, 154], "lt": [76, 82, 83, 154], "hs": [76, 82, 87, 88, 150, 154], "grad": [76, 82, 87, 88, 150, 154], "civ": [76, 82, 87, 88, 150, 154], "spous": [76, 82, 87, 88, 150, 154], "farm": [76, 82, 87, 150, 154], "fish": [76, 82, 87, 150, 154], "husband": [76, 82, 87, 88, 150, 154], "white": [76, 82, 87, 88, 150, 154], "local": [76, 82, 87, 93, 108, 138, 150, 154, 157, 162, 163], "gov": [76, 82, 87, 150, 154], "assoc": [76, 82, 87, 150, 154], "acdm": [76, 82, 87, 150, 154], "protect": [76, 82, 87, 150, 154], "serv": [76, 82, 87, 90, 92, 107, 142, 150, 154], "gt": [76, 82, 154], "44": [76, 82, 94, 104, 106, 120, 122, 135, 150, 151, 154], "colleg": [76, 82, 87, 150, 154], "7688": [76, 82, 150, 151, 154], "femal": [76, 82, 87, 88, 150, 154], "revenu": [76, 86, 87, 133], "target_column": [76, 111, 132, 136, 140, 157, 158, 159, 163], "37155": [76, 86], "11687": [76, 86], "dtype": [76, 78, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 101, 104, 106, 107, 108, 109, 111, 133, 140, 142, 150, 154, 156, 157, 162, 163], "int64": [76, 78, 82, 86, 87, 106, 108, 156], "imbal": [76, 108], "special": [76, 107], "healthi": 76, "ill": [76, 133], "all_column": 76, "print": [76, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 102, 103, 104, 109, 110, 111, 112, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 133, 134, 135, 137, 138, 139, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 154, 155, 156, 157, 163], "48842": [76, 82, 87, 150, 154], "14": [76, 94, 97, 106, 107, 118, 119, 122, 142, 145, 154, 156], "subtract": [76, 84], "mayb": [76, 97, 105, 109], "peculiar": [76, 106], "malfunct": 76, "afterward": [76, 83, 110], "cap": [76, 99, 109, 125, 127, 128, 133, 146], "hist": [76, 78, 94, 97, 101, 104, 105, 106, 107, 108, 109, 140], "figsiz": [76, 78, 106, 107, 108, 109, 110, 133, 142, 145, 157, 161, 162, 163], "func": [76, 104, 109, 143, 146, 157, 162, 163], "assign": [76, 84, 101, 106, 111, 117, 138, 144, 147], "underscor": [76, 84, 151], "garbag": 76, "comment": 76, "retir": 76, "filter": [76, 87, 107, 150], "peak": 76, "ll": 76, "32650": 76, "16192": 76, "disproport": 76, "fair": [76, 99, 120], "deploi": [76, 88, 104, 152, 162], "mitig": [76, 119], "deploy": [76, 152], "compon": [76, 138, 181], "unexpect": [76, 102], "gender": 76, "15784": 76, "10878": 76, "bachelor": [76, 87, 88], "8025": 76, "master": [76, 87], "2657": 76, "voc": [76, 87], "2061": 76, "1812": 76, "1601": 76, "10th": [76, 87], "1389": 76, "7th": [76, 87], "8th": [76, 87], "955": 76, "prof": [76, 87, 88], "school": [76, 87, 97], "834": [76, 88], "9th": [76, 87], "756": 76, "12th": [76, 87], "657": 76, "doctor": [76, 87], "594": 76, "5th": [76, 87], "6th": [76, 87], "509": 76, "4th": [76, 87], "247": 76, "preschool": [76, 87], "crosstab": 76, "entri": [76, 79, 104, 106, 107, 108, 109, 116, 125, 130, 134], "lose": 76, "redund": [76, 104, 127, 131, 135, 138], "upcom": [76, 142, 151], "pairplot": [76, 77, 78, 107, 108, 109, 110, 158], "diagon": [76, 108, 142, 145, 150, 158], "reveal": [76, 104], "sn": [76, 84, 107, 108, 109, 110, 111, 112, 117, 123, 134, 136, 137, 138, 139, 140, 141, 150, 153, 157, 158, 161, 162, 163, 164], "readabl": [76, 150, 153, 179], "n_samples_to_plot": 76, "5000": [76, 108, 127, 128, 134, 139], "var": 76, "hue": [76, 78, 107, 108, 109, 111, 136, 140, 141, 153, 157, 158, 161, 163], "plot_kw": [76, 110], "height": [76, 78, 131, 135], "diag_kind": [76, 110], "diag_kw": 76, "opt": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "hostedtoolcach": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "x64": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "lib": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "python3": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "site": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "axisgrid": [76, 78, 107, 108, 109, 110, 158], "py": [76, 78, 107, 108, 109, 110, 118, 133, 140, 143, 146, 157, 158, 162, 163], "118": [76, 78, 107, 108, 109, 110, 158], "userwarn": [76, 78, 107, 108, 109, 110, 118, 143, 146, 158], "layout": [76, 78, 106, 107, 108, 109, 110, 158], "tight": [76, 78, 107, 108, 109, 110, 158], "self": [76, 78, 82, 87, 99, 107, 108, 109, 110, 143, 146, 154, 157, 158, 162, 163], "_figur": [76, 78, 107, 108, 109, 110, 158], "tight_layout": [76, 78, 107, 108, 109, 110, 158], "arg": [76, 78, 107, 108, 109, 110, 143, 146, 154, 157, 158, 162, 163], "kwarg": [76, 78, 107, 108, 109, 110, 143, 146, 154, 157, 158, 162, 163], "written": [76, 97, 109], "scatterplot": [76, 84, 109, 111, 112, 117, 123, 134, 136, 137, 138, 139, 140, 141, 153, 157, 158, 161, 162, 163, 164], "region": [76, 104, 105, 150, 154], "pyplot": [76, 84, 94, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 136, 137, 140, 141, 142, 145, 146, 157, 161, 162, 163, 164], "plt": [76, 84, 94, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 136, 137, 140, 141, 142, 145, 146, 157, 161, 162, 163, 164], "ax": [76, 84, 106, 107, 110, 111, 121, 133, 134, 138, 139, 141, 142, 145, 150, 153, 157, 161, 162, 163], "age_limit": 76, "axvlin": [76, 109, 110], "ymin": [76, 109], "ymax": [76, 109], "linestyl": [76, 109, 112, 123, 142, 162], "hours_per_week_limit": 76, "axhlin": 76, "xmin": 76, "xmax": 76, "annot": [76, 150], "fontsiz": 76, "45": [76, 83, 84, 87, 94, 104, 106, 108, 118, 122, 134, 139, 157], "AND": 76, "seem": [76, 79, 82, 85, 86, 90, 92, 100, 103, 109, 110, 119, 121, 124, 133, 134, 145, 151, 157], "complic": [76, 109, 127], "similarli": [76, 95, 96, 98, 100, 101, 103, 114, 119, 121, 123, 133, 142, 154, 164], "somewhat": [76, 112], "arbitrari": [76, 87, 88, 89, 91, 92, 93, 110], "straightforward": [76, 112], "obviou": [76, 97, 107, 141], "highlight": [76, 83, 87, 97, 99, 103, 111, 117, 126, 127, 129, 133, 142, 150, 152, 157, 162], "imagin": [77, 78, 110, 141], "feel": [77, 78, 87, 116, 119, 125, 133, 147, 185], "penguins_classif": [77, 78, 111, 132, 136, 140, 157, 158, 159, 161, 163], "adeli": [78, 132, 136, 140, 157, 158, 163], "151": [78, 87, 153], "gentoo": [78, 157, 158, 163], "123": 78, "chinstrap": [78, 132, 136, 140, 157, 158, 163], "pairplot_figur": [78, 158], "prioriti": 78, "tweak": 78, "subfigur": 78, "perfectli": [78, 92, 108, 117, 119, 138, 145, 161], "downsid": 79, "amount": [79, 97, 104, 108, 121, 133], "smaller": [79, 104, 118, 119, 124, 147, 174], "repetit": [79, 97, 150], "aggreg": [79, 109, 116, 125, 133, 142], "partit": [79, 143, 146, 157, 159, 161, 162, 163], "clone": [79, 112], "earlier": [79, 88, 109, 120, 142, 157], "computation": [79, 118, 138, 150, 179], "intens": [79, 101, 179], "cv_result": [79, 87, 88, 90, 91, 92, 93, 100, 104, 105, 109, 119, 120, 122, 127, 128, 133, 135, 147, 150, 151, 152, 153, 154, 156, 179], "cpu": [79, 88, 105, 117, 120, 150, 154], "722": 79, "ms": [79, 88, 105, 120, 150, 154], "sy": [79, 88, 105, 120, 150, 154], "total": [79, 88, 97, 103, 104, 105, 106, 107, 108, 109, 110, 120, 142, 150, 154, 156], "922": 79, "wall": [79, 88, 105, 120, 150, 154], "523": [79, 120, 134], "fit_tim": [79, 87, 88, 100, 104, 117, 118, 127, 146, 152], "07796741": 79, "07318211": 79, "07471371": 79, "07412338": 79, "07449055": 79, "score_tim": [79, 87, 88, 100, 104, 117, 118, 127, 146, 152], "01660872": 79, "01667738": 79, "01672268": 79, "0165453": 79, "01718903": 79, "79557785": 79, "80049135": 79, "79965192": 79, "79873055": 79, "80436118": 79, "iii": 79, "distinct": [79, 82, 99, 102], "match": [79, 80, 85, 99, 138], "stabil": [79, 110], "discard": [79, 104, 109, 111, 157], "round": [79, 96, 101, 111], "themselv": 79, "3f": [79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 102, 109, 117, 118, 120, 121, 123, 125, 129, 130, 134, 135, 140, 142, 145, 146, 147, 151, 152, 155, 157], "std": [79, 82, 84, 87, 88, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 109, 110, 112, 117, 118, 120, 121, 125, 131, 133, 135, 146, 147, 151, 152], "800": [79, 151], "crucial": [79, 110, 119], "bar": [79, 102, 106, 110, 133, 157], "decim": 79, "trustworthi": [79, 99], "compat": [79, 152], "familiar": [80, 85, 109, 116, 125, 144, 147], "conveni": [80, 85, 133], "directli": [80, 83, 85, 88, 110, 117, 138, 147, 157], "insid": [80, 85, 87, 106, 143, 146, 177], "pager": [80, 85], "roughli": [81, 86, 112, 124, 139], "simplest": [81, 86], "irrespect": [81, 86, 101, 179, 185], "train_test_split": [81, 82, 84, 86, 88, 103, 104, 110, 113, 114, 115, 119, 122, 123, 124, 126, 129, 132, 136, 140, 142, 145, 148, 149, 150, 152, 154, 155, 156, 157, 159, 163], "behavior": [81, 86, 133, 141, 162], "oversimplifi": 82, "exclus": 82, "helper": [82, 84, 87, 88, 130, 134, 143, 146], "duplic": [82, 87, 88, 112, 150, 154], "48837": [82, 87, 150, 154], "48838": [82, 87, 150, 154], "48839": [82, 87, 150, 154], "48840": [82, 87, 150, 154], "48841": [82, 87, 150, 154], "explicit": [82, 83, 104, 138, 144, 147], "At": [82, 99, 102, 104, 112, 142, 163], "moreov": 82, "o": 82, "explanatori": [82, 103], "000000": [82, 84, 94, 107, 109], "643585": 82, "710510": 82, "min": [82, 84, 94, 107, 109, 112, 130, 133, 134, 137, 139, 161, 162, 164, 174], "max": [82, 84, 94, 107, 109, 112, 130, 133, 134, 137, 138, 139, 155, 161, 162, 164, 174, 179], "float64": [82, 94, 101, 104, 106, 107, 108, 109], "unusu": 82, "memori": [82, 103, 106, 107, 108, 109, 151, 152], "test_siz": [82, 94, 98, 101, 104, 105, 113, 115, 122, 124, 142, 152], "determinist": [82, 101, 138], "specifi": [82, 87, 88, 106, 107, 121, 139, 152, 154, 182], "remain": [82, 83, 102, 103, 110, 127, 133, 141, 154], "quickli": [82, 106, 109, 110, 119, 138, 140, 142, 153, 154], "got": [82, 116, 125, 141, 157, 162, 163, 164], "1f": [82, 112, 147], "12211": 82, "36631": [82, 84], "cours": [82, 87, 106, 127, 130, 134, 138, 143, 146, 159, 163], "environ": [82, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "pleas": [82, 84, 85, 88, 93, 96, 99, 101, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164, 177, 185], "rerun": [82, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "unabl": [82, 84, 85, 88, 93, 99, 102, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "render": [82, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "nbviewer": [82, 84, 85, 88, 93, 99, 104, 111, 133, 137, 141, 142, 150, 152, 154, 157, 163, 164], "logisticregressionlogisticregress": [82, 84, 88, 93, 142, 157], "807": [82, 84], "fraction": [82, 105, 119, 142, 145], "correctli": [82, 92, 93, 102, 111, 142], "fed": 83, "41": [83, 104, 106, 109, 110, 122], "3273": 83, "side": [83, 94, 121, 124, 152, 162], "39068": 83, "39069": 83, "39070": 83, "39071": 83, "39072": 83, "39073": 83, "linger": [83, 87, 97, 104], "denomin": 83, "major": [83, 86, 101], "seldom": 83, "target_predict": [83, 103, 104, 111, 122, 123, 130, 134, 138, 142, 145, 161, 162], "sake": [83, 93, 96, 101, 119, 138, 141, 152, 177], "simplic": [83, 93, 96, 101, 138, 141, 177], "agre": [83, 124], "bool": [83, 106, 142], "mistak": [83, 111, 129, 142, 161], "success": [83, 84, 117, 163], "8242776341719346": 83, "harder": [83, 127], "conclud": [83, 89, 91, 101, 112, 157], "ones": [83, 87, 150, 151, 154], "adult_census_test": [83, 85], "9769": 83, "manual": [83, 87, 88, 112, 117, 126, 129, 138, 142, 151, 157, 165, 182], "deal": [83, 87, 88, 92, 102, 103, 108, 126, 129, 135, 138, 140, 147, 158, 177], "model_nam": [83, 84, 151], "__class__": [83, 84], "__name__": [83, 84], "804": 83, "underli": [83, 84, 87, 97, 111, 117, 142], "wrongli": [83, 88], "held": [83, 94, 115, 119, 124, 152], "642352": 84, "1087": 84, "077721": 84, "665311": 84, "431247": 84, "725748": 84, "7522": 84, "692939": 84, "407": 84, "110175": 84, "423952": 84, "99999": 84, "4356": 84, "99": 84, "span": [84, 133], "assumpt": [84, 87, 91, 103, 128, 141, 161, 162], "address": 84, "solver": [84, 133, 147], "descent": [84, 107, 147], "scaler": [84, 93, 151, 156, 179, 181, 185], "standardscalerstandardscal": [84, 88, 93, 141], "wherea": [84, 119, 132, 136, 147, 149, 156], "fashion": 84, "mean_": 84, "64235211": 84, "07772106": 84, "6653108": 84, "43124676": 84, "scale_": 84, "72556083": 84, "59025606": 84, "10461772": 84, "42378265": 84, "data_train_sc": 84, "17177061": 84, "14450843": 84, "71188483": 84, "28845333": 84, "02605707": 84, "22025127": 84, "27618374": 84, "33822677": 84, "77019645": 84, "77536738": 84, "03471139": 84, "53605445": 84, "48319243": 84, "69090725": 84, "perspect": [84, 90, 92, 105], "predefin": 84, "shorthand": 84, "preserv": [84, 102, 141, 150], "set_output": [84, 87, 133], "behaviour": [84, 103, 119, 128, 157], "663100e": 84, "273364e": 84, "530310e": 84, "840667e": 84, "844684e": 84, "000014e": 84, "576792e": 84, "445084e": 84, "202513e": 84, "173852e": 84, "753674e": 84, "471139e": 84, "196565e": 84, "817680e": 84, "677425e": 84, "741752e": 84, "314865e": 84, "047970e": 84, "714245e": 84, "jointplot": 84, "clearer": 84, "num_points_to_plot": 84, "300": [84, 107, 112, 117, 119, 123, 130, 134, 137, 139, 161], "marginal_kw": 84, "dict": [84, 151], "suptitl": [84, 142, 145], "nbefor": 84, "nafter": 84, "x27": [84, 88, 93, 99, 111, 133, 141, 150, 152, 154], "pipelinepipelin": [84, 88, 93, 133, 141, 150, 152, 154], "named_step": 84, "expos": [84, 87, 121, 142], "predict_proba": [84, 140, 142, 147, 150, 157], "decision_funct": 84, "elapsed_tim": [84, 90, 92], "predicted_target": 84, "n_iter_": [84, 125], "072": 84, "145": [84, 117], "scenario": [84, 88, 133, 145], "kneighborsclassifierkneighborsclassifi": 85, "first_data_valu": 85, "first_predict": 85, "first_target_valu": 85, "number_of_correct_predict": 85, "number_of_predict": 85, "len": [85, 104, 110, 111, 118, 119], "8290379545978042": 85, "8177909714402702": 85, "data_numeric_train": 86, "data_numeric_test": 86, "class_to_predict": 86, "high_revenue_clf": 86, "234": 86, "low_revenue_clf": 86, "766": 86, "7607182343065395": 86, "appear": [86, 112], "most_freq_revenue_clf": 86, "76": [86, 100, 106, 108, 142, 146], "reassur": [86, 124, 152], "arithmet": 87, "instruct": 87, "taken": [87, 110, 121, 139], "symbol": [87, 103], "sort_index": 87, "857": [87, 155], "cambodia": 87, "canada": 87, "182": 87, "china": 87, "122": [87, 104, 109, 110], "columbia": 87, "85": [87, 93, 104, 109, 110, 150, 179], "cuba": 87, "138": 87, "dominican": 87, "republ": 87, "103": [87, 107, 147, 157], "ecuador": 87, "el": 87, "salvador": 87, "155": [87, 154], "england": 87, "127": 87, "franc": 87, "germani": 87, "206": [87, 157, 162, 163], "greec": 87, "guatemala": 87, "haiti": 87, "holand": 87, "netherland": 87, "hondura": 87, "hong": 87, "hungari": 87, "india": 87, "iran": 87, "ireland": 87, "itali": 87, "jamaica": 87, "japan": 87, "lao": 87, "mexico": 87, "951": 87, "nicaragua": 87, "outli": 87, "guam": 87, "usvi": 87, "peru": 87, "philippin": 87, "295": 87, "poland": 87, "87": [87, 119, 150], "portug": 87, "67": [87, 106, 107, 110, 154], "puerto": 87, "rico": 87, "184": [87, 143, 146], "scotland": 87, "south": [87, 110], "115": [87, 104, 146], "taiwan": 87, "thailand": 87, "trinadad": 87, "tobago": 87, "43832": 87, "vietnam": 87, "86": [87, 93, 104, 109, 110, 153], "yugoslavia": 87, "recogn": [87, 97], "li": [87, 112], "categorical_columns_selector": [87, 88, 89, 90, 91, 92, 150, 152, 154], "dtype_includ": [87, 88, 89, 90, 91, 92, 121, 148, 150, 152, 154, 155], "unwant": [87, 109], "data_categor": [87, 89, 91], "education_column": 87, "education_encod": 87, "map": [87, 91, 133, 156], "categories_": 87, "data_encod": 87, "downstream": 87, "lexicograph": 87, "meaningless": [87, 112, 162], "l": [87, 97], "xl": 87, "alphabet": 87, "accept": [87, 104], "constructor": 87, "explicitli": [87, 143, 146, 154, 156], "mislead": [87, 92, 110], "altern": [87, 154, 161], "sparse_output": [87, 90, 92], "education_": 87, "spars": [87, 90, 92, 104, 109], "effici": [87, 111, 118, 121, 133, 138], "won": [87, 110], "becam": 87, "feder": 87, "emp": 87, "inc": 87, "country_": 87, "amp": 87, "102": [87, 107, 154], "violat": [87, 103], "realli": [87, 97, 103, 105, 107, 111, 142], "misord": 87, "misus": 87, "ineffici": 87, "integr": [87, 118, 133], "abl": [87, 88, 100, 107, 112, 113, 117, 118, 121, 122, 138, 141, 142, 143, 146, 153, 157, 160, 162, 164, 171, 182, 185], "bypass": 87, "keyword": 87, "min_frequ": 87, "collaps": 87, "rarest": 87, "enabl": [87, 185], "infrequent_if_exist": 87, "sandbox": [87, 179], "use_encoded_valu": [87, 88, 89, 90, 91, 92, 121, 148, 150, 152, 154, 155], "unknown_valu": [87, 88, 89, 90, 91, 92, 121, 148, 150, 152, 154, 155], "silenc": 87, "convergencewarn": 87, "73278785": 87, "66065407": 87, "67217898": 87, "66898918": 87, "66140175": 87, "0302465": 87, "03047562": 87, "03039312": 87, "03205228": 87, "03018856": 87, "83222438": 87, "83560242": 87, "82872645": 87, "83312858": 87, "83466421": 87, "833": [87, 91], "002": [87, 90, 91, 92, 151], "decoupl": [88, 142], "numerical_columns_selector": [88, 90, 92], "dtype_exclud": [88, 90, 92], "properli": [88, 99, 107, 115, 124, 141, 161], "format": [88, 103, 107, 134, 139], "elaps": [88, 127], "introspect": [88, 185], "send": 88, "columntransfom": 88, "categorical_preprocessor": [88, 90, 92, 148, 150, 152, 154, 155], "numerical_preprocessor": 88, "associ": [88, 97, 107, 109, 133, 142, 145, 150], "standard_scal": 88, "concaten": [88, 96, 97, 101, 102, 138, 141, 152, 161], "columntransformercolumntransform": [88, 93, 150, 152, 154], "onehotencoderonehotencod": [88, 93], "prefer": 88, "raw": [88, 133, 145, 185], "7762": 88, "divorc": 88, "unmarri": 88, "23881": 88, "transport": 88, "30507": 88, "43": [88, 94, 97, 104, 106, 107, 118], "specialti": 88, "14344": 88, "28911": 88, "19484": 88, "wife": 88, "8575055278028008": 88, "usabl": 88, "85050869": 88, "88440132": 88, "79591179": 88, "85398197": 88, "85532165": 88, "03758216": 88, "03639221": 88, "03812361": 88, "03813863": 88, "03641152": 88, "8512642": 88, "8498311": 88, "84756347": 88, "8523751": 88, "85524161": 88, "851": [88, 121], "compound": 88, "isol": [88, 104, 119], "nice": [88, 111], "fast": [88, 92, 117], "passthrough": [88, 90, 92, 121, 148, 150, 152, 154, 155], "850": 88, "849": 88, "8798624191302924": 88, "significantli": [88, 105, 110], "whenev": [88, 107], "popular": [88, 121], "datasci": 88, "practition": 88, "outperform": 88, "assembl": [89, 91, 117, 119], "rais": [89, 91, 111, 112, 121, 123, 143, 146, 157, 162, 163], "warn": [89, 91, 111, 112, 118, 123, 133, 143, 146], "nan": [89, 91, 93, 102, 106, 143, 146], "traceback": [89, 91, 143, 146, 157, 162, 163], "error_scor": [89, 91], "awai": [89, 91, 92, 112, 145, 165], "handi": [89, 91, 104, 107, 143, 146], "empir": [90, 92, 104], "util": [90, 92, 93, 101, 106, 143, 146, 157, 162, 163], "873": [90, 92], "150": [90, 107, 111], "detriment": [90, 92, 119, 121, 133], "dens": [90, 92], "workaround": [90, 92], "755": 91, "anyth": [91, 103, 126, 129, 142], "constantli": [91, 96, 101], "761": 91, "messag": [91, 92], "152": 92, "022": 92, "signific": [92, 110, 119, 127, 133, 152], "useless": [92, 124], "007": 92, "view": [92, 152], "longer": [92, 133, 139, 151, 158], "current": [92, 124, 177], "implement": [92, 102, 111, 112, 118, 137, 140, 143, 146, 150, 153], "incomplet": 92, "yield": [92, 119, 137], "unnecessari": [92, 115, 124], "unless": 92, "long": [92, 106, 107, 109, 131, 135, 151], "reproduc": [93, 107, 152], "script": 93, "event": 93, "rerecord": 93, "ui": 93, "releas": 93, "house_pric": [93, 106, 144, 145, 147], "na_valu": [93, 106], "id": [93, 97, 106], "mssubclass": [93, 106], "mszone": [93, 106], "street": [93, 106], "allei": [93, 106], "lotshap": [93, 106], "landcontour": [93, 106], "poolqc": [93, 106], "fenc": [93, 106], "miscfeatur": [93, 106], "mosold": [93, 106], "yrsold": [93, 106, 133], "saletyp": [93, 106], "salecondit": [93, 106], "rl": [93, 106], "8450": [93, 106], "pave": [93, 106], "reg": [93, 106, 110], "lvl": [93, 106], "allpub": [93, 106], "2008": [93, 106], "wd": [93, 106], "9600": [93, 106], "2007": [93, 106], "11250": [93, 106], "ir1": [93, 106], "9550": [93, 106], "2006": [93, 106], "abnorml": [93, 106], "14260": [93, 106], "1455": 93, "1456": 93, "7917": 93, "1457": 93, "13175": 93, "mnprv": [93, 106], "2010": 93, "1458": 93, "66": [93, 106, 107], "9042": 93, "gdprv": 93, "shed": [93, 106], "2500": 93, "1459": [93, 106], "9717": 93, "1460": [93, 106], "9937": 93, "cherri": 93, "retain": [93, 133], "numeric_featur": 93, "fullbath": [93, 106], "halfbath": [93, 106], "categorical_featur": [93, 106], "neighborhood": [93, 94, 106, 110], "housestyl": [93, 106], "imput": [93, 106], "simpleimput": [93, 106], "numeric_transform": 93, "categorical_transform": 93, "join": [93, 157, 162, 163], "simpleimputersimpleimput": 93, "859": [93, 155], "018": 93, "dollar": [93, 94, 104, 109, 133], "necessarili": [93, 104, 105, 120, 133, 147, 150, 182], "richer": [93, 138], "level": [93, 99, 101, 119, 121, 126, 127, 129, 142, 159, 160, 161, 163, 164, 177], "probabl": [93, 104, 109, 110, 111, 140, 147, 157, 163, 179], "coars": 93, "dummyregressor": [94, 145], "overview": [94, 95, 98, 100, 104, 105, 109, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 157, 159, 160, 161, 162, 163, 164, 165], "fetch_california_h": [94, 98, 104, 105, 109, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 149, 156], "return_x_i": [94, 99, 102, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 149, 156, 179], "as_fram": [94, 98, 102, 104, 105, 109, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 149, 156], "rescal": [94, 98, 105, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 133, 145, 149, 151, 156], "splitter": 94, "cv_results_tree_regressor": 94, "n_job": [94, 97, 98, 99, 100, 101, 103, 105, 109, 110, 117, 118, 119, 120, 121, 122, 124, 125, 127, 129, 133, 135, 150, 152, 154, 156], "errors_tree_regressor": 94, "688588": 94, "154770": 94, "304351": 94, "719450": 94, "727268": 94, "626309": 94, "830423": 94, "result_dummi": 94, "errors_dummy_regressor": 94, "140009": 94, "821140": 94, "757566": 94, "543652": 94, "034555": 94, "979007": 94, "477244": 94, "all_error": 94, "concat": [94, 101, 102, 110, 125, 127, 128, 136], "058812": 94, "713153": 94, "877710": 94, "539353": 94, "398153": 94, "941912": 94, "140641": 94, "213912": 94, "015862": 94, "273149": 94, "542490": 94, "858806": 94, "630975": 94, "054327": 94, "947952": 94, "480271": 94, "991373": 94, "644907": 94, "023571": 94, "198778": 94, "556965": 94, "814307": 94, "539567": 94, "281560": 94, "185225": 94, "142603": 94, "298971": 94, "436741": 94, "084639": 94, "835414": 94, "984471": 94, "858300": 94, "981744": 94, "984875": 94, "547140": 94, "874775": 94, "820219": 94, "768721": 94, "702388": 94, "305556": 94, "752148": 94, "503017": 94, "570512": 94, "147974": 94, "24": [94, 104, 106, 107, 108, 109, 110, 142, 147, 154], "603993": 94, "386320": 94, "261358": 94, "815660": 94, "616231": 94, "216574": 94, "239211": 94, "107460": 94, "362271": 94, "620318": 94, "569641": 94, "165331": 94, "linspac": [94, 98, 100, 101, 112, 117, 123, 130, 134, 137, 139, 153], "edgecolor": [94, 97, 101, 104, 105, 106, 107, 108, 109, 153], "legend": [94, 97, 101, 102, 103, 107, 109, 111, 112, 117, 123, 134, 136, 140, 142, 153, 157, 161, 162, 163, 164], "bbox_to_anchor": [94, 97, 101, 102, 103, 107, 109, 111, 112, 117, 123, 134, 136, 142, 153, 157, 161, 163], "loc": [94, 97, 101, 102, 103, 107, 109, 111, 112, 117, 123, 132, 134, 136, 140, 142, 153, 157, 161, 163], "upper": [94, 97, 101, 102, 103, 107, 109, 110, 112, 117, 123, 136, 142, 157, 161, 163], "xlabel": [94, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 124, 125, 127, 128, 133, 140, 142], "Such": [94, 133], "onlin": [94, 96, 101], "extrem": [94, 99, 108, 109, 126, 129, 133], "gamma": [95, 99, 100, 141], "svm": [95, 99, 100, 138, 141], "form": [95, 97, 99, 100, 110, 130, 131, 134, 135, 137, 139, 145, 151], "kernel": [95, 100, 138, 141], "accomplish": [95, 100], "rbf": [95, 100, 141], "svc": [95, 99, 100, 141], "scheme": [95, 100, 103, 111, 162], "validationcurvedisplai": [95, 100, 105, 124], "10e": [95, 100], "10e2": [95, 100], "logarithm": [95, 100], "svc__gamma": [95, 100], "retriev": [95, 100, 104, 110, 133], "learningcurvedisplai": [95, 98, 100], "half": [96, 101, 141, 142], "uniform": [96, 101, 109, 112, 154], "handwritten": 97, "digit": 97, "load_digit": 97, "recreat": 97, "minmaxscal": [97, 112, 133, 185], "kfold": [97, 99, 102, 125, 144, 147, 152], "test_score_no_shuffl": 97, "931": 97, "026": 97, "test_score_with_shuffl": 97, "968": 97, "015": [97, 110], "all_scor": [97, 99], "xlim": [97, 110, 117, 142], "impos": [97, 119, 154], "94166667": 97, "89722222": 97, "94986072": 97, "9637883": 97, "90250696": 97, "ship": 97, "descr": [97, 104, 109], "_digits_dataset": 97, "optic": 97, "recognit": 97, "characterist": [97, 104, 109, 142], "1797": 97, "64": [97, 106, 107, 146, 154], "8x8": 97, "pixel": 97, "creator": 97, "alpaydin": 97, "boun": 97, "edu": 97, "tr": 97, "juli": 97, "1998": 97, "copi": [97, 104, 107, 110, 130, 134, 179], "uci": 97, "ic": 97, "nist": 97, "bitmap": 97, "preprint": 97, "32x32": 97, "nonoverlap": 97, "block": [97, 103, 104, 109, 110, 118], "4x4": 97, "invari": 97, "distort": 97, "garri": 97, "j": 97, "candela": 97, "dimmick": 97, "geist": 97, "grother": 97, "janet": 97, "wilson": 97, "handprint": 97, "nistir": 97, "5469": 97, "kaynak": 97, "1995": 97, "Their": 97, "msc": 97, "thesi": 97, "institut": 97, "graduat": 97, "bogazici": 97, "univers": 97, "cascad": 97, "kybernetika": 97, "ken": 97, "tang": 97, "ponnuthurai": 97, "n": [97, 99, 100, 109, 112, 118, 122, 125, 130, 133, 134, 136, 140, 142, 151, 152, 155, 157], "suganthan": 97, "xi": 97, "yao": 97, "kai": 97, "qin": 97, "dimensionalityreduct": 97, "lda": 97, "electr": [97, 106], "electron": 97, "nanyang": 97, "2005": 97, "claudio": 97, "gentil": 97, "nip": 97, "2000": 97, "writer": 97, "wrote": 97, "ensur": [97, 99, 102, 119], "certain": [97, 125], "130": [97, 118], "hypothesi": [97, 103, 133], "itertool": [97, 106], "bound": [97, 142, 145], "writer_boundari": 97, "256": [97, 118, 119, 154], "386": 97, "516": 97, "646": 97, "776": 97, "915": [97, 117], "1029": 97, "1157": 97, "1287": 97, "1415": 97, "1545": 97, "1667": 97, "zeros_lik": [97, 111], "lower_bound": 97, "upper_bound": 97, "group_id": 97, "lb": 97, "zip": [97, 107, 117, 130, 134], "ytick": [97, 102], "xtick": 97, "ylabel": [97, 102, 103, 105, 124, 125, 133, 142, 157], "groupkfold": 97, "928": 97, "014": [97, 99], "realiti": 97, "synthet": [98, 112, 117, 127, 142, 160, 161, 162, 164], "train_siz": [98, 100, 148, 155], "endpoint": 98, "325": [98, 107], "775": 98, "displai": [98, 114, 123, 140, 142, 153, 179], "from_estim": [98, 100, 105, 111, 124, 132, 136, 140, 141, 142, 157, 161, 163], "score_typ": [98, 100], "negate_scor": [98, 105, 124], "neg_": [98, 104, 147], "score_nam": [98, 100], "std_display_styl": [98, 100, 105, 124], "errorbar": [98, 100, 105, 124, 133], "ax_": [98, 100, 105, 124, 142], "xscale": [98, 133], "log": [98, 133, 145, 153, 154], "alon": 98, "anymor": [98, 101, 103, 104, 119, 141], "bay": 98, "especi": [98, 133], "report": [98, 99, 104], "problemat": [99, 133, 154], "underestim": 99, "philosoph": 99, "breast": 99, "cancer": 99, "load_breast_canc": 99, "param_grid": [99, 120, 122, 150, 152, 161, 179, 185], "model_to_tun": 99, "gridsearchcvgridsearchcv": [99, 150, 152], "svcsvc": [99, 141], "best_params_": [99, 125, 149, 150, 152, 154, 156, 161, 179, 185], "best_score_": 99, "627": 99, "stage": [99, 102, 118, 126, 127, 129, 138, 142, 163], "misinterpret": 99, "forget": 99, "pitfal": 99, "emb": [99, 152], "dedic": [99, 145], "declar": 99, "inner_cv": 99, "outer_cv": 99, "trial": 99, "test_score_not_nest": 99, "test_score_nest": 99, "n_trial": 99, "non_nest": 99, "append": [99, 102, 110, 112, 123, 125, 136, 147], "merg": [99, 127], "whisker": [99, 109, 125, 127, 128, 133, 146], "vert": [99, 109, 125, 127, 128, 133, 146], "highest": [99, 111, 126, 127, 129, 142, 145, 153, 154], "lure": 99, "overli": [99, 104], "020656": 100, "003953": 100, "680000": 100, "020348": 100, "003983": 100, "746667": 100, "019538": 100, "003799": 100, "786667": 100, "018166": 100, "003765": 100, "800000": 100, "019757": 100, "003880": 100, "019412": 100, "003759": 100, "018477": 100, "003844": 100, "017556": 100, "003660": 100, "826667": 100, "018033": 100, "003648": 100, "018154": 100, "003594": 100, "733333": 100, "765": 100, "043": 100, "param_nam": [100, 105, 124, 150, 153, 154, 157, 162, 163, 179, 185], "disp": [100, 105, 124, 142], "errorbar_kw": 100, "transpar": 100, "regim": 100, "oscil": 100, "donat": [100, 108, 142, 143, 146], "simplist": 100, "imposs": [100, 141], "cv_results_logistic_regress": 101, "test_score_logistic_regress": 101, "815937": 101, "813849": 101, "815036": 101, "815569": 101, "810982": 101, "814709": 101, "813112": 101, "810327": 101, "812416": 101, "816388": 101, "most_frequent_classifi": 101, "cv_results_most_frequ": 101, "test_score_most_frequ": 101, "760329": 101, "756808": 101, "759142": 101, "760739": 101, "761681": 101, "761885": 101, "757463": 101, "757176": 101, "763114": 101, "all_test_scor": 101, "stratified_dummi": 101, "cv_results_stratifi": 101, "test_score_dummy_stratifi": 101, "uniform_dummi": 101, "cv_results_uniform": 101, "test_score_dummy_uniform": 101, "wrong": [101, 126, 129, 153], "henc": [101, 110, 117, 133, 154], "uniformli": [101, 112], "weakest": 101, "argu": 101, "chanc": [101, 104, 112, 126, 129, 142], "permutation_test_scor": 101, "permut": [101, 179], "quit": [101, 102, 103, 105, 107, 118, 140], "strongest": 101, "load_iri": [102, 179], "toi": [102, 138, 141], "nine": 102, "data_random": 102, "randn": [102, 112, 117, 126, 129, 138], "train_index": 102, "test_index": 102, "six": 102, "train_cv_count": 102, "test_cv_count": 102, "fold_idx": 102, "train_idx": 102, "test_idx": 102, "enumer": [102, 111, 112, 123, 125, 127, 130, 134, 152], "idx": [102, 127], "953": 102, "009": [102, 118], "frequenc": [102, 108, 142], "stratifiedkfold": [102, 143, 146], "960": 102, "016": 102, "past": [103, 108, 130, 134, 142], "acronym": 103, "ident": [103, 104, 118, 142, 152], "financi": 103, "quotat": 103, "tot": 103, "xom": 103, "exxon": 103, "cvx": 103, "chevron": 103, "cop": 103, "conocophillip": 103, "vlo": 103, "valero": 103, "template_nam": 103, "quot": 103, "stock": 103, "2f": [103, 104, 119, 122, 124, 130, 133, 134, 136, 137, 138, 139, 142, 150, 154, 157, 163], "surprisingli": [103, 104, 109, 129], "outstand": 103, "eas": [103, 104, 138, 141], "r2_score": 103, "verifi": [103, 115, 124, 138], "doesn": 103, "proper": [103, 109, 138, 152], "to_period": 103, "q": 103, "forecast": 103, "ulterior": 103, "timeseriessplit": 103, "nuniqu": [103, 107, 161, 185], "shelv": 103, "absurd": 103, "intend": [104, 108, 177], "dive": 104, "area": [104, 105, 106, 112, 141, 142, 161], "geograph": [104, 109, 120], "_california_housing_dataset": [104, 109], "20640": [104, 109], "medinc": [104, 109, 110], "houseag": [104, 109, 110], "averoom": [104, 109, 110, 156], "household": [104, 109], "avebedrm": [104, 109, 110], "aveoccup": [104, 109, 110], "member": [104, 109], "latitud": [104, 109, 110], "longitud": [104, 109, 110], "statlib": [104, 109], "dcc": [104, 109], "fc": [104, 109], "pt": [104, 109], "ltorgo": [104, 109], "cal_hous": [104, 109], "district": [104, 109, 110, 120], "hundr": [104, 109, 127], "deriv": [104, 107, 109, 131, 135, 138], "1990": [104, 109], "u": [104, 109], "smallest": [104, 109, 118, 133], "bureau": [104, 109], "600": [104, 109], "resid": [104, 109], "home": [104, 109], "empti": [104, 109], "vacat": [104, 109], "resort": [104, 109], "pace": [104, 109], "kellei": [104, 109], "ronald": [104, 109], "barri": [104, 109], "spatial": [104, 109], "autoregress": [104, 109], "33": [104, 106, 109, 119, 153], "1997": [104, 109], "291": [104, 109], "297": [104, 109], "3252": [104, 109, 110], "984127": [104, 109, 110], "023810": [104, 109, 110], "322": [104, 109, 110], "555556": [104, 109, 110], "3014": [104, 109, 110], "238137": [104, 109, 110], "971880": [104, 109, 110], "2401": [104, 109, 110], "109842": [104, 109, 110], "2574": [104, 109, 110], "288136": [104, 109, 110], "073446": [104, 109, 110], "496": [104, 109, 110, 153, 154], "802260": [104, 109, 110], "6431": [104, 109, 110], "817352": [104, 109, 110], "073059": [104, 109, 110], "558": [104, 109, 110], "547945": [104, 109, 110], "8462": [104, 109, 110], "281853": [104, 109, 110], "081081": [104, 109, 110], "565": [104, 109, 110], "181467": [104, 109, 110], "452": 104, "358": 104, "352": 104, "341": 104, "342": 104, "medhousev": [104, 109, 110], "decisiontreeregressordecisiontreeregressor": [104, 164], "mean_absolute_error": [104, 115, 122, 123, 124, 137, 145], "grown": [104, 115, 119, 124], "leaf": [104, 119, 150, 154, 155, 161, 163, 173, 174], "node": [104, 119, 121, 150, 155, 161, 163, 172, 173, 174], "phenomena": 104, "unstabl": [104, 133], "wouldn": 104, "unlimit": [104, 119], "lucki": 104, "easiest": 104, "variant": 104, "190235": 104, "003906": 104, "909797": 104, "189156": 104, "004097": 104, "421170": 104, "187413": 104, "003920": 104, "411089": 104, "188942": 104, "004108": 104, "319824": 104, "185820": 104, "004198": 104, "607875": 104, "front": 104, "revert": 104, "negat": 104, "test_error": [104, 133], "188412": 104, "901300": 104, "189270": 104, "003851": 104, "572767": 104, "189273": 104, "003853": 104, "194585": 104, "189334": 104, "004142": 104, "590236": 104, "190132": 104, "004295": 104, "727998": 104, "furthermor": [104, 133, 140], "percentag": [104, 112, 145], "tag": [104, 130, 134], "expert": [104, 138, 141], "21935081": 104, "21590948": 104, "21539354": 104, "22223997": 104, "21578121": 104, "00311136": 104, "00302935": 104, "00314355": 104, "00298238": 104, "00304508": 104, "26291527": 104, "41947109": 104, "44492564": 104, "23357874": 104, "40788361": 104, "overal": [104, 115, 119, 120, 124, 133, 142, 161], "fluctuat": [105, 150], "hopefulli": [105, 119, 137], "376": 105, "411": 105, "harm": 105, "matter": [105, 128, 152], "compromis": [105, 142], "dispers": [105, 118], "directori": [106, 107, 108], "charact": 106, "marker": [106, 111, 142], "pars": [106, 107], "lotconfig": 106, "208500": 106, "fr2": 106, "181500": 106, "223500": 106, "corner": [106, 142], "140000": 106, "250000": 106, "nin": 106, "tail": [106, 107, 109], "coupl": [106, 107, 109, 118, 119, 133, 154], "core": [106, 107, 108, 109, 117, 118], "rangeindex": [106, 107, 108, 109], "null": [106, 107, 108, 109, 140], "1201": 106, "landslop": 106, "condition1": 106, "condition2": 106, "bldgtype": 106, "yearremodadd": 106, "roofstyl": 106, "roofmatl": 106, "exterior1st": 106, "exterior2nd": 106, "masvnrtyp": 106, "588": 106, "1452": 106, "exterqu": 106, "extercond": 106, "foundat": 106, "bsmtqual": 106, "1423": 106, "bsmtcond": 106, "bsmtexposur": 106, "1422": 106, "bsmtfintype1": 106, "bsmtfintype2": 106, "heat": 106, "heatingqc": 106, "centralair": 106, "bsmtfullbath": 106, "bsmthalfbath": 106, "kitchenqu": 106, "fireplacequ": 106, "770": 106, "garagetyp": 106, "1379": 106, "garageyrblt": 106, "garagefinish": 106, "61": [106, 119, 133, 154], "garagequ": 106, "63": [106, 112, 154], "garagecond": 106, "paveddr": 106, "72": 106, "281": 106, "78": [106, 142], "901": 106, "kb": [106, 108], "numerical_data": 106, "410": 106, "subplots_adjust": [106, 107, 109, 110], "hspace": [106, 107, 109], "wspace": [106, 109], "criterion": [106, 110, 157], "swim": 106, "pool": [106, 129], "string_data": 106, "490": 106, "ceil": 106, "zip_longest": 106, "n_string_featur": 106, "nrow": [106, 142], "ncol": [106, 134, 142, 145], "fig": [106, 110, 133, 142, 145, 153, 156, 157, 158, 179], "subplot": [106, 110, 133, 142, 145, 157, 161, 162, 163], "ravel": [106, 107, 134], "barh": [106, 108, 110, 136, 140, 142], "set_titl": [106, 138, 139, 142], "databas": [106, 156], "grvl": 106, "gd": 106, "make_column_transform": [106, 121], "most_frequent_imput": 106, "mean_imput": 106, "ames_housing_preprocess": 106, "timestamp": 107, "0880": 107, "033870": 107, "161": [107, 118, 157], "336": 107, "0842": 107, "033571": 107, "163": 107, "409": 107, "0234": 107, "033223": 107, "156": 107, "445": 107, "0016": 107, "032908": 107, "148": 107, "441": 107, "1144": 107, "38254": 107, "38253": 107, "mb": [107, 109], "str": [107, 157, 162, 163], "datetim": 107, "direct": [107, 154], "reopen": 107, "explan": [107, 158], "soup": 107, "blender": 107, "blend": 107, "veget": 107, "instantan": 107, "profession": 107, "calibr": 107, "track": 107, "spent": [107, 127], "food": 107, "uranium": 107, "petrol": 107, "ga": 107, "coal": 107, "plant": 107, "400": 107, "cheaper": [107, 110], "w": [107, 145], "deliv": 107, "breakout": 107, "kilomet": 107, "costli": [107, 149, 150, 156], "cruis": 107, "datetime64": 107, "ns": 107, "freq": 107, "august": 107, "septemb": 107, "date_first_rid": 107, "cycling_rid": 107, "data_rid": 107, "target_rid": 107, "tempor": 107, "resolut": [107, 154], "smoother": [107, 112], "set_xlabel": [107, 145], "extremum": 107, "rng": [107, 109, 110, 112, 117, 129, 138], "randomst": [107, 109, 110, 112, 117, 129, 138], "arang": [107, 109, 110, 112, 161, 162, 164], "quantiz": [107, 109], "midpoint": [107, 109], "interv": [107, 109, 112, 114, 117, 123, 160, 162, 164], "qcut": [107, 109], "retbin": [107, 109], "lambda": [107, 109, 153, 179], "mid": [107, 109], "palett": [107, 109, 111, 136, 140, 141, 157, 161, 163], "viridi": [107, 109, 153, 179], "uphil": 107, "physiolog": 107, "stimuli": 107, "recenc": [108, 142], "monetari": [108, 142], "12500": 108, "3250": [108, 139], "4000": 108, "6000": 108, "748": 108, "747": 108, "noth": [108, 112], "shock": 108, "her": 108, "762032": 108, "237968": 108, "strike": 108, "fetch": 109, "internet": 109, "california_h": 109, "526": 109, "585": 109, "521": [109, 142], "413": [109, 154], "422": [109, 142], "demographi": 109, "granular": [109, 142], "20639": 109, "640": 109, "unnotic": 109, "features_of_interest": [109, 133], "429000": 109, "096675": 109, "070655": 109, "1425": 109, "476744": 109, "474173": 109, "473911": 109, "386050": 109, "1132": 109, "462122": 109, "846154": 109, "333333": 109, "692308": 109, "440716": 109, "006079": 109, "429741": 109, "787": [109, 151], "229129": 109, "048780": 109, "818116": 109, "1166": 109, "052381": 109, "099526": 109, "282261": 109, "1725": 109, "141": 109, "909091": 109, "066667": 109, "1243": 109, "35682": 109, "huge": 109, "datapoint": 109, "coast": 109, "big": [109, 145], "citi": [109, 145], "san": 109, "diego": 109, "lo": 109, "angel": 109, "jose": 109, "francisco": 109, "columns_drop": 109, "distinguish": 109, "curiou": [109, 141, 185], "553": [109, 142], "062": 109, "coef": [109, 110, 133, 136, 140], "est": [109, 133], "spot": [109, 133], "10000": 110, "100k": 110, "assert": [110, 119, 185], "un": [110, 133], "bin_var": 110, "randint": [110, 122, 126, 129], "rnd_bin": 110, "num_var": 110, "rnd_num": 110, "x_with_rnd_feat": 110, "x_train": 110, "x_test": 110, "y_train": [110, 174], "y_test": 110, "train_dataset": 110, "insert": 110, "kde": 110, "scatter_kw": 110, "x_i": 110, "versu": [110, 145, 165], "6013466090490024": 110, "5975757793803438": 110, "Its": 110, "somehow": 110, "rest": [110, 138], "worth": 110, "habit": 110, "nb": 110, "outcom": [110, 140, 142, 156], "shall": [110, 112], "rise": 110, "80k": 110, "gaug": 110, "decad": 110, "visibl": [110, 145], "dev": 110, "6013157556102924": 110, "5972410717953726": 110, "safe": 110, "perturb": 110, "repeatedkfold": 110, "cv_model": 110, "n_repeat": [110, 127, 128], "boxplot": 110, "cyan": 110, "satur": 110, "pretti": 110, "5899811014945939": 110, "5769786920519312": 110, "partli": 110, "multivari": 110, "instabl": 110, "teas": 110, "inher": 110, "9799566281436841": 110, "8480906087487957": 110, "formal": 110, "brought": 110, "argsort": [110, 127], "set_ytick": 110, "set_yticklabel": 110, "979674165215708": 110, "8471877132928255": 110, "def": [110, 112, 117, 130, 134, 139, 150, 153, 154, 161, 179], "get_score_after_permut": 110, "curr_feat": 110, "x_permut": 110, "col_idx": 110, "permuted_scor": 110, "get_feature_import": 110, "baseline_score_train": 110, "permuted_score_train": 110, "feature_import": 110, "662": 110, "list_feature_import": 110, "n_round": 110, "678": 110, "0123": 110, "heavili": 110, "permutation_import": 110, "calcul": [110, 111, 142], "importances_mean": 110, "importances_std": 110, "plot_feature_import": 110, "perm_importance_result": 110, "feat_nam": 110, "xerr": 110, "perm_importance_result_train": 110, "realist": [110, 140], "unclear": 110, "culmen_column": [111, 132, 136, 140, 157, 158, 159, 163], "purposefulli": 111, "unlik": [111, 115, 124, 157], "misclassifi": 111, "decisiontreeclassifi": [111, 121, 143, 146, 157, 161, 163], "tab": [111, 112, 117, 136, 140, 141, 142, 157, 161, 162, 163], "decisiontreeclassifierdecisiontreeclassifi": [111, 157, 163], "misclassified_samples_idx": 111, "flatnonzero": 111, "data_misclassifi": 111, "decisionboundarydisplai": [111, 132, 136, 140, 141, 157, 159, 161, 163], "response_method": [111, 136, 140, 141, 157, 161, 163], "cmap": [111, 136, 140, 141, 150, 157, 161, 163], "rdbu": [111, 141, 157, 161, 163], "center": [111, 134, 153, 156, 161], "nwith": [111, 117], "misclassif": [111, 142], "sample_weight": 111, "trick": [111, 141], "drastic": 111, "qualit": [111, 112, 130, 134, 163], "newly_misclassified_samples_idx": 111, "remaining_misclassified_samples_idx": 111, "intersect1d": 111, "ensemble_weight": 111, "935672514619883": 111, "6929824561403509": 111, "adaboostclassifi": 111, "samm": 111, "adaboostclassifieradaboostclassifi": 111, "boosting_round": 111, "estimators_": [111, 112, 114, 123], "to_numpi": [111, 112, 123, 142], "640x480": 111, "estimator_weights_": 111, "58351894": 111, "46901998": 111, "03303773": 111, "estimator_errors_": 111, "05263158": 111, "05864198": 111, "08787269": 111, "sens": [111, 164], "stand": [112, 179], "generate_data": [112, 117], "x_min": [112, 117], "x_max": [112, 117], "capabl": [112, 117, 133, 142, 160, 162, 164], "y_pred": [112, 143, 145, 146], "data_bootstrap": 112, "target_bootstrap": 112, "bootstrap_sampl": 112, "bootstrap_indic": 112, "n_bootstrap": 112, "bootstrap_idx": 112, "facecolor": 112, "180": [112, 139], "linewidth": [112, 161], "darker": 112, "data_train_hug": 112, "data_test_hug": 112, "target_train_hug": 112, "100_000": 112, "data_bootstrap_sampl": 112, "target_bootstrap_sampl": 112, "ratio_unique_sampl": 112, "bag_of_tre": 112, "tree_idx": [112, 123], "tree_predict": [112, 123], "feed": 112, "bag_predict": 112, "unbroken": [112, 117], "whole": [112, 114, 119, 121, 123, 133, 138], "meta": 112, "wrap": [112, 133, 165], "smooth": [112, 141], "bagged_tre": [112, 121], "bagged_trees_predict": 112, "els": [112, 157, 161, 162, 163], "opac": 112, "appreci": 112, "space": [112, 114, 116, 117, 123, 125, 129, 131, 133, 135, 140, 157, 162, 163], "polynomialfeatur": [112, 131, 133, 135, 138], "polynomial_regressor": 112, "1e": [112, 118, 151, 154], "intention": 112, "simpli": [112, 163], "regressor_predict": 112, "base_model_lin": 112, "bagging_predict": 112, "ylim": [112, 142], "shade": 112, "randomizedsearchcv": [113, 119, 122, 149, 154, 156, 179], "penguins_regress": [114, 123, 130, 134, 137, 139, 158, 160, 161, 162, 164], "evenli": [114, 123], "170": [114, 123], "230": [114, 123], "newli": [114, 123], "conduct": [115, 124, 156], "learning_r": [115, 116, 119, 124, 125, 148, 150, 153, 154, 155, 179, 181], "slower": [115, 124, 152], "offer": [115, 124, 154], "certainli": [115, 124], "n_iter_no_chang": [115, 124], "max_leaf_nod": [116, 119, 125, 148, 150, 152, 153, 154, 155, 161, 179, 181], "residu": [117, 119, 145, 154], "back": [117, 140, 142, 153, 157], "len_x": 117, "rand": [117, 138], "target_train_predict": 117, "target_test_predict": 117, "line_predict": 117, "lines_residu": 117, "edit": 117, "initi": [117, 152, 182], "tree_residu": 117, "target_train_predicted_residu": 117, "target_test_predicted_residu": 117, "manag": 117, "x_sampl": 117, "target_tru": 117, "target_true_residu": 117, "commit": [117, 145], "y_pred_first_tre": 117, "517": 117, "393": 117, "248": [117, 118], "y_pred_first_and_second_tre": 117, "gradientboostingregressor": [117, 118, 124], "gradient_boost": [117, 118], "cv_results_gbdt": [117, 118], "387": 117, "349": 117, "010": [117, 155], "random_forest": [117, 121], "cv_results_rf": 117, "396": 117, "515": 117, "480": 117, "brute": [118, 137], "overcom": [118, 120, 138], "benchmark": 118, "383": [118, 123], "908": 118, "356": 118, "kbinsdiscret": [118, 138], "n_bin": [118, 138], "quantil": [118, 141], "data_tran": 118, "_discret": 118, "313": [118, 137], "249": 118, "231": 118, "162": 118, "203": [118, 157, 162, 163], "242": 118, "160": 118, "126": 118, "136": [118, 143, 146], "93": [118, 154, 157, 162, 163], "199": [118, 157, 162, 163], "col": 118, "253": [118, 155], "207": [118, 157, 162, 163], "235": [118, 123, 164], "786": 118, "025": 118, "373": 118, "011": 118, "histogram_gradient_boost": 118, "cv_results_hgbdt": 118, "758": 118, "694": 118, "732": 118, "063": 118, "clariti": 119, "doubl": [119, 150, 151], "max_featur": [119, 121, 122], "grow": [119, 120, 161, 179], "uncorrel": 119, "symmetr": [119, 133, 145, 161], "constraint": [119, 133, 157, 161, 162, 163], "min_samples_leaf": [119, 120, 153, 154, 161, 179], "minimum": [119, 142, 154, 160, 161, 162, 164], "branch": [119, 161], "promot": 119, "altogeth": 119, "param_distribut": [119, 154, 156], "search_cv": 119, "n_iter": [119, 122, 149, 154, 156, 179], "param_": [119, 122, 125, 150, 154], "mean_test_error": [119, 122], "std_test_error": [119, 122], "cv_results_": [119, 122, 125, 150, 152, 154, 156, 179], "mean_test_scor": [119, 122, 125, 150, 152, 153, 154, 156, 179], "std_test_scor": [119, 122, 150, 152, 153, 154], "sort_valu": [119, 122, 150, 154, 156], "param_max_featur": [119, 122], "param_max_leaf_nod": 119, "param_min_samples_leaf": 119, "837726": 119, "469978": 119, "698021": 119, "567601": 119, "364454": 119, "477058": 119, "149987": 119, "608598": 119, "428824": 119, "614502": 119, "912803": 119, "340477": 119, "219570": 119, "770384": 119, "236519": 119, "715236": 119, "845926": 119, "533355": 119, "930714": 119, "884417": 119, "role": 119, "inter": 119, "refit": [119, 148, 152, 155], "overlook": 119, "stat": [119, 122, 154], "loguniform": [119, 154], "param_max_it": 119, "param_learning_r": 119, "01864": 119, "961931": 119, "284726": 119, "047293": 119, "956461": 119, "344678": 119, "176656": 119, "595743": 119, "302709": 119, "215543": 119, "994402": 119, "395205": 119, "297739": 119, "102438": 119, "572886": 119, "083745": 119, "141387": 119, "390749": 119, "067503": 119, "711630": 119, "451641": 119, "05929": 119, "905287": 119, "408489": 119, "160519": 119, "316506": 119, "391175": 119, "125207": 119, "774847": 119, "512391": 119, "054511": 119, "257351": 119, "644847": 119, "906226": 119, "904808": 119, "631837": 119, "248463": 119, "046127": 119, "660900": 119, "061034": 119, "572496": 119, "596634": 119, "079415": 119, "508378": 119, "934735": 119, "0351": 119, "547120": 119, "970037": 119, "019923": 119, "638637": 119, "084263": 119, "039361": 119, "794655": 119, "063414": 119, "019351": 119, "369705": 119, "103442": 119, "01724": 119, "911113": 119, "043453": 119, "rank": [119, 125, 185], "hgbt": 119, "hassl": 120, "354": 120, "087": 120, "min_samples_split": [120, 161], "107": 120, "bagging_regressor": 120, "642": 120, "083": 120, "decent": [120, 153, 154], "modif": 121, "inject": 121, "decorrel": 121, "categorical_encod": 121, "scores_tre": 121, "820": 121, "006": [121, 125], "scores_bagged_tre": 121, "846": 121, "005": 121, "randomforestclassifi": [121, 127, 128], "scores_random_forest": 121, "004": 121, "disabl": 121, "sqrt": 121, "literatur": 121, "agnost": 121, "param": [122, 125, 150, 153, 157, 162, 163], "bootstrap_featur": 122, "estimator__ccp_alpha": 122, "estimator__criterion": 122, "estimator__max_depth": 122, "estimator__max_featur": 122, "estimator__max_leaf_nod": 122, "estimator__min_impurity_decreas": 122, "estimator__min_samples_leaf": 122, "estimator__min_samples_split": 122, "estimator__min_weight_fraction_leaf": 122, "estimator__random_st": 122, "estimator__splitt": 122, "max_sampl": 122, "oob_scor": 122, "verbos": [122, 151, 154, 156, 181], "warm_start": 122, "param_n_estim": 122, "param_max_sampl": 122, "param_estimator__max_depth": 122, "746446": 122, "068060": 122, "961699": 122, "040923": 122, "792709": 122, "092924": 122, "861086": 122, "304345": 122, "805968": 122, "197870": 122, "957667": 122, "082714": 122, "343613": 122, "046704": 122, "381896": 122, "975940": 122, "780524": 122, "950337": 122, "364255": 122, "206704": 122, "439890": 122, "610861": 122, "442906": 122, "214250": 122, "561948": 122, "827893": 122, "116793": 122, "845387": 122, "618483": 122, "197056": 122, "761730": 122, "191009": 122, "478907": 122, "270749": 122, "240020": 122, "732932": 122, "025871": 122, "919746": 122, "360681": 122, "596572": 122, "gram": [123, 131, 135, 137], "215": [123, 156], "data_rang": 123, "forest_predict": 123, "n_estimators_": 124, "169": 124, "hist_gbdt": 125, "839": 125, "best_estimator_": 125, "528": 125, "447": 125, "576": 125, "290": 125, "414": 125, "index_column": 125, "inner_cv_result": 125, "cv_idx": 125, "search_cv_result": 125, "set_index": [125, 132, 136, 140, 147], "renam": [125, 150, 153, 154, 156, 179], "coincid": [125, 142], "bioinformat": [126, 129], "rna": [126, 129], "seq": [126, 129], "ten": [126, 129], "anova": [126, 127, 129], "feature_select": [126, 127, 128, 129], "selectkbest": [126, 127, 129], "f_classif": [126, 127, 129], "pre": [126, 129], "princip": 127, "make_classif": [127, 128], "n_inform": [127, 128], "n_redund": [127, 128], "univari": 127, "model_without_select": [127, 128], "model_with_select": [127, 128], "score_func": [127, 129], "cv_results_without_select": [127, 128], "incorpor": 127, "cv_results_with_select": [127, 128], "analyz": [127, 133, 179], "swap": 127, "swaplevel": [127, 128], "Of": 127, "scores_": 127, "percentil": 127, "alien": 127, "primari": 127, "feature_importances_": 128, "suffici": 128, "class_sep": 128, "selectfrommodel": 128, "feature_selector": [128, 129], "overestim": 128, "100000": 129, "550": 129, "data_subset": 129, "940": 129, "succeed": 129, "legit": 129, "leak": 129, "data_train_subset": 129, "520": 129, "460": 129, "boilerpl": 129, "linear_model_flipper_mass": [130, 134, 139], "flipper_length": [130, 134, 139], "weight_flipper_length": [130, 134, 137, 139], "intercept_body_mass": [130, 134, 137, 139], "body_mass": [130, 134, 139], "flipper_length_rang": [130, 134, 137, 139], "goodness_fit_measur": [130, 134], "true_valu": [130, 134], "scalar": [130, 134], "model_idx": [130, 134], "x1": [131, 135, 140], "x2": [131, 135], "x3": [131, 135], "penguins_non_miss": [131, 135, 185], "181": [131, 135, 139], "186": [131, 135, 139], "195": [131, 135, 139], "193": [131, 135, 139], "190": [131, 135, 139], "interaction_onli": [131, 135], "infinit": [132, 136], "yourself": [132, 136], "penguins_train": [132, 136, 140], "penguins_test": [132, 136, 140], "candid": [132, 136, 154, 156, 157], "cs": [132, 136], "augment": [133, 141], "linear_regress": [133, 135, 137, 138, 164], "include_bia": [133, 135, 138], "train_error": 133, "2e": 133, "85e": 133, "63e": 133, "69e": 133, "47e": 133, "fortun": 133, "feature_names_in_": 133, "model_first_fold": 133, "polynomialfeaturespolynomialfeatur": 133, "linearregressionlinearregress": [133, 137], "queri": 133, "weights_linear_regress": 133, "symlog": 133, "homogen": 133, "choleski": 133, "_ridg": 133, "211": [133, 143, 146], "linalgwarn": 133, "rcond": 133, "59923e": 133, "linalg": 133, "xy": 133, "assume_a": 133, "po": 133, "overwrite_a": 133, "59556e": 133, "59609e": 133, "11828e": 133, "06109e": 133, "60121e": 133, "61694e": 133, "59735e": 133, "59566e": 133, "72304e": 133, "60047e": 133, "59824e": 133, "59593e": 133, "59564e": 133, "5959e": 133, "59553e": 133, "59686e": 133, "60737e": 133, "5957e": 133, "60243e": 133, "90e": 133, "56e": 133, "55e": 133, "68e": 133, "weights_ridg": [133, 136], "shrunk": 133, "worst": [133, 142], "saga": 133, "lsqr": 133, "re": [133, 177, 185], "attempt": 133, "resolv": 133, "omit": 133, "annual": 133, "neutral": 133, "ahead": 133, "scaled_ridg": 133, "78e": 133, "21e": 133, "83e": 133, "17e": 133, "sweet": 133, "regardless": 133, "weights_ridge_scaled_data": 133, "ridge_large_alpha": 133, "1_000_000": 133, "unpredict": 133, "occurr": 133, "presenc": [133, 147], "divis": 133, "beforehand": 133, "store_cv_valu": 133, "12e": 133, "25e": 133, "50e": 133, "40e": 133, "mse_alpha": 133, "cv_values_": 133, "cv_alpha": 133, "000000e": 133, "841881e": 133, "347783e": 133, "321941e": 133, "837563e": 133, "343115e": 133, "747528e": 133, "831866e": 133, "336956e": 133, "310130e": 133, "824352e": 133, "328835e": 133, "053856e": 133, "814452e": 133, "318133e": 133, "274549e": 133, "319038e": 133, "337394e": 133, "328761e": 133, "324503e": 133, "338181e": 133, "722368e": 133, "328652e": 133, "338778e": 133, "564633e": 133, "331799e": 133, "339232e": 133, "334185e": 133, "339576e": 133, "yerr": 133, "yscale": 133, "salt": 133, "cook": 133, "best_alpha": 133, "11497569953977356": 133, "35111917342151344": 133, "1519911082952933": 133, "4641588833612782": 133, "08697490026177834": 133, "6135907273413176": 133, "stem": [133, 145], "summari": 133, "wasn": 133, "disproportion": 133, "15000": 134, "14000": 134, "predicted_body_mass": [134, 137, 139], "misleadingli": 134, "mse": [134, 138, 145, 147], "ab": [134, 138], "2764": 134, "854": 134, "338": 134, "573": 134, "041": 134, "337": 135, "071": 135, "868": 135, "poly_featur": 135, "linear_regression_interact": 135, "301": 135, "790": 135, "340": 135, "spread": [135, 153, 179], "enrich": 135, "set_param": [136, 151, 155, 181, 185], "logisticregression__c": [136, 179, 181], "rdbu_r": [136, 140], "invers": 136, "perpendicular": [136, 157], "lowest": [137, 145], "68556640610011": 137, "5780": 137, "831358077066": 137, "mean_squared_error": [137, 138, 145], "inferred_body_mass": 137, "model_error": 137, "154546": 137, "data_max": 138, "data_min": 138, "len_data": 138, "sort": 138, "full_data": 138, "input_featur": 138, "reshap": [138, 145], "global": 138, "cubic": [138, 174], "expans": [138, 141], "data_expand": 138, "polynomial_regress": 138, "440892098500626e": 138, "encourag": [138, 145], "svr": 138, "poli": 138, "medium": 138, "10_000": [138, 157], "nystroem": 138, "binned_regress": 138, "kernel_approxim": 138, "nystroem_regress": 138, "n_compon": 138, "expand": 138, "3750": 139, "3800": 139, "3450": 139, "3650": 139, "formul": 139, "2700": 139, "6300": 139, "heavier": [139, 158], "formula": 139, "shorter": 139, "13000": 139, "millimet": 139, "body_mass_180": 139, "body_mass_181": 139, "7200": 139, "7240": 139, "goe": [139, 142], "170mm": 139, "230mm": 139, "redefin": 139, "groupbi": 140, "_oldcor": [140, 157, 162, 163], "1498": [140, 157, 162, 163], "futurewarn": [140, 157, 162, 163], "is_categorical_dtyp": [140, 157, 162, 163], "deprec": [140, 157, 162, 163], "isinst": [140, 157, 162, 163], "categoricaldtyp": [140, 157, 162, 163], "obliqu": [140, 157], "horizont": [140, 161], "vertic": 140, "coordin": [140, 152, 153, 156, 179], "inclin": 140, "coef0": 140, "x0": 140, "coef1": 140, "hold": [141, 145, 153, 156, 179, 185], "interlac": [141, 161], "make_moon": 141, "moon": 141, "newaxi": [141, 161], "data_moon": 141, "target_moon": 141, "depict": [141, 158], "push": 141, "surround": 141, "make_gaussian_quantil": 141, "n_class": 141, "gauss": 141, "data_gauss": 141, "target_gauss": 141, "gaussian": 141, "radial": 141, "basi": 141, "kernel_model": 141, "donor": 142, "ago": 142, "new_donor": 142, "That": [142, 147, 150, 152], "258": 142, "505": 142, "665": 142, "615": 142, "743": 142, "374": 142, "7780748663101604": 142, "accuracy_scor": 142, "778": 142, "finer": 142, "confusionmatrixdisplai": 142, "incorrect": 142, "erron": 142, "tp": 142, "tn": 142, "fn": 142, "fp": 142, "precision_scor": [142, 143, 146], "recall_scor": 142, "pos_label": [142, 143, 146], "688": 142, "124": [142, 154], "mislabel": 142, "ratio": 142, "dummy_classifi": 142, "762": 142, "balanced_accuracy_scor": 142, "haven": 142, "confid": 142, "target_proba_predict": 142, "classes_": [142, 157, 163, 181], "271820": 142, "728180": 142, "451764": 142, "548236": 142, "445211": 142, "554789": 142, "441577": 142, "558423": 142, "870583": 142, "129417": 142, "equivalence_pred_proba": 142, "idxmax": 142, "graph": 142, "precisionrecalldisplai": 142, "tpr": 142, "ppv": 142, "ap": 142, "preval": 142, "discrimin": 142, "roccurvedisplai": 142, "dash": 142, "plot_chance_level": 142, "pr": 142, "chance_level_kw": 142, "ambigu": [143, 146], "valueerror": [143, 146], "exc": [143, 146], "_valid": [143, 146], "842": [143, 146, 155], "recent": [143, 146, 157, 162, 163], "_scorer": [143, 146], "__call__": [143, 146], "scorer": [143, 144, 146, 147], "_score": [143, 146], "355": [143, 146], "_sign": [143, 146], "_score_func": [143, 146], "y_true": [143, 145, 146], "scoring_kwarg": [143, 146], "_param_valid": [143, 146, 157, 162, 163], "wrapper": [143, 146, 157, 162, 163], "_classif": [143, 146], "2127": [143, 146], "precision_recall_fscore_support": [143, 146], "1721": [143, 146], "_check_set_wise_label": [143, 146], "1507": [143, 146], "catch": [143, 146], "make_scor": [143, 146], "syntax": [144, 147], "iowa": 145, "intro": [145, 165], "said": [145, 147], "996": 145, "902": 145, "2064": 145, "736": 145, "6872520581075487": 145, "dummy_regressor": 145, "608": 145, "disadvantag": 145, "median_absolute_error": 145, "137": 145, "mean_absolute_percentage_error": 145, "574": 145, "obsev": 145, "unobserv": 145, "extern": [145, 152], "cloud": 145, "against": 145, "exhibit": 145, "predictionerrordisplai": 145, "from_predict": 145, "actual_vs_predict": 145, "scatter_kwarg": 145, "set_ylabel": 145, "residual_vs_predict": 145, "nwithout": 145, "banana": 145, "smile": 145, "clue": 145, "monoton": 145, "quantiletransform": [145, 185], "transformedtargetregressor": 145, "n_quantil": [145, 185], "900": 145, "output_distribut": 145, "model_transformed_target": 145, "ntransform": 145, "406": 145, "327": [145, 154], "disapprov": 145, "statistician": 145, "justifi": 145, "poissonregressor": 145, "tweedieregressor": 145, "docstr": 145, "reachabl": 145, "625": 146, "140": [146, 153], "507": 146, "268": 146, "176": 146, "00311422": 146, "00309205": 146, "00317407": 146, "00304294": 146, "00310397": 146, "00305605": 146, "00301337": 146, "00319099": 146, "0030942": 146, "00310993": 146, "00283408": 146, "00267029": 146, "00265026": 146, "00266552": 146, "00266099": 146, "00263977": 146, "00294733": 146, "0026722": 146, "00267553": 146, "00263643": 146, "test_accuraci": 146, "29333333": 146, "53333333": 146, "73333333": 146, "77333333": 146, "63513514": 146, "75675676": 146, "test_balanced_accuraci": 146, "42105263": 146, "48391813": 146, "65204678": 146, "40643275": 146, "45906433": 146, "44736842": 146, "59649123": 146, "73684211": 146, "45356037": 146, "51186791": 146, "794": 147, "892": 147, "225": 147, "test_r2": 147, "test_neg_mean_absolute_error": 147, "848721": 147, "256799": 147, "816374": 147, "084083": 147, "813513": 147, "113367": 147, "814138": 147, "448279": 147, "637473": 147, "370341": 147, "defaultdict": 147, "loss_funct": 147, "squared_error": 147, "absolute_error": 147, "loss_func": 147, "test_neg_mean_squared_error": 147, "243": 147, "923": 147, "344": [147, 154], "evolv": 147, "discontinu": 147, "surrog": 147, "substitut": 147, "log_loss": 147, "exhaust": [148, 155, 182], "cat_preprocessor": [148, 150, 152, 154, 155], "sparse_threshold": [148, 150, 152, 154, 155], "kneighborsregressor": [149, 156], "int32": [149, 156, 161], "with_mean": [149, 156], "with_std": [149, 156], "reload": [150, 154], "dealt": 150, "ordinalencoderordinalencod": [150, 152, 154], "remainderpassthroughpassthroughhistgradientboostingclassifierhistgradientboostingclassifi": [150, 152, 154], "classifier__learning_r": [150, 152, 154, 155], "classifier__max_leaf_nod": [150, 152, 154, 155], "model_grid_search": [150, 152], "charg": 150, "rapidli": 150, "ascend": [150, 154, 156], "mean_fit_tim": [150, 153], "std_fit_tim": [150, 153], "mean_score_tim": [150, 153], "std_score_tim": [150, 153], "param_classifier__learning_r": [150, 152, 153], "param_classifier__max_leaf_nod": [150, 152, 153], "split0_test_scor": [150, 153], "split1_test_scor": [150, 153], "rank_test_scor": [150, 152, 153, 154], "479630": 150, "043480": 150, "215447": 150, "005771": 150, "868912": 150, "867213": 150, "868063": 150, "000850": 150, "359816": 150, "000620": 150, "194027": 150, "003127": 150, "866783": 150, "866066": 150, "866425": 150, "000359": 150, "116743": 150, "002368": 150, "084079": 150, "003220": 150, "classifier__": 150, "858648": 150, "862408": [150, 152, 153], "860528": 150, "001880": 150, "132947": 150, "001960": 150, "084795": 150, "001527": 150, "859358": 150, "859514": 150, "859436": 150, "000078": 150, "121988": 150, "004921": 150, "079099": 150, "000174": 150, "855536": 150, "856129": 150, "855832": 150, "000296": 150, "shorten": 150, "param_classifier__": 150, "prefix": [150, 153], "column_result": [150, 154], "shorten_param": [150, 153, 154, 179], "__": [150, 151, 153, 154, 179], "rsplit": [150, 153, 154, 179], "853266": 150, "000515": 150, "843330": 150, "002917": 150, "817832": 150, "001124": 150, "797166": 150, "000715": 150, "288200": 150, "050539": 150, "283476": 150, "003775": 150, "262564": 150, "006326": 150, "heatmap": [150, 153], "pivoted_cv_result": 150, "pivot_t": 150, "ylgnbu": 150, "vmin": 150, "vmax": 150, "invert_yaxi": 150, "degrad": 150, "patholog": 150, "accordingli": 150, "hyperparamt": 150, "interchang": 151, "recogniz": 151, "spell": 151, "classifier__c": [151, 179, 181], "parameter_nam": 151, "middl": 151, "preprocessor__copi": 151, "preprocessor__with_mean": 151, "preprocessor__with_std": 151, "classifier__class_weight": 151, "classifier__du": 151, "classifier__fit_intercept": 151, "classifier__intercept_sc": 151, "classifier__l1_ratio": 151, "classifier__max_it": 151, "classifier__multi_class": 151, "classifier__n_job": 151, "classifier__penalti": 151, "classifier__random_st": 151, "classifier__solv": 151, "classifier__tol": 151, "classifier__verbos": 151, "classifier__warm_start": 151, "001": [151, 154], "799": 151, "520424": 152, "082227": 152, "863241": 152, "513057": 152, "083140": 152, "860784": 152, "515752": 152, "082540": 152, "860360": [152, 153], "515529": 152, "084967": 152, "519792": 152, "083101": 152, "866912": 152, "863": 152, "embed": 152, "864195": 152, "000061": 152, "870910": 152, "869743": 152, "000532": 152, "866058": 152, "001515": 152, "concern": 152, "877": 152, "schemat": 152, "green": 152, "intermedi": [152, 153], "rough": 152, "cv_test_scor": 152, "871": 152, "apprehend": 152, "cv_inner": 152, "cv_outer": 152, "greed": 152, "cv_fold": 152, "estimator_in_fold": 152, "vote": 152, "randomized_search_result": [153, 154, 179], "param_classifier__l2_regular": 153, "param_classifier__max_bin": 153, "param_classifier__min_samples_leaf": 153, "split2_test_scor": 153, "split3_test_scor": 153, "split4_test_scor": 153, "540456": 153, "062725": 153, "052069": 153, "002661": 153, "467047": 153, "550075": 153, "classifier__l2_regular": [153, 154], "4670474863": 153, "856558": 153, "862271": 153, "857767": 153, "854491": 153, "856675": 153, "857552": 153, "002586": 153, "110536": 153, "033403": 153, "074142": 153, "002165": 153, "015449": 153, "001146": 153, "0154488709": 153, "758974": 153, "758941": 153, "758947": 153, "000013": [153, 154], "323": 153, "137484": 153, "053150": 153, "092993": 153, "029005": 153, "095093": 153, "004274": 153, "0950934559": 153, "783267": 153, "776413": 153, "779143": 153, "771341": 153, "010357": 153, "311": 153, "935108": 153, "202993": 153, "118105": 153, "023658": 153, "003621": 153, "001305": 153, "164": 153, "0036210968": 153, "255219": 153, "038301": 153, "056048": 153, "016736": 153, "000081": 153, "407382": 153, "1060737427": 153, "495": 153, "452411": 153, "023006": 153, "055563": 153, "000846": 153, "000075": 153, "364373": 153, "4813767874": 153, "858332": 153, "865001": 153, "862681": 153, "860770": 153, "861429": 153, "002258": 153, "133042": 153, "014456": 153, "078186": 153, "002199": 153, "065946": 153, "001222": 153, "0659455480": 153, "497": [153, 154], "911828": 153, "017167": 153, "076563": 153, "005130": 153, "460025": 153, "044408": 153, "4600250010": 153, "839907": 153, "849713": 153, "846847": 153, "846028": 153, "844390": 153, "845377": 153, "003234": 153, "498": 153, "168120": 153, "121819": 153, "061283": 153, "000760": 153, "000068": 153, "287904": 153, "227": 153, "146": 153, "7755366885": 153, "861881": 153, "859951": 153, "861862": 153, "862221": 153, "001623": 153, "499": [153, 154], "823774": 153, "120686": 153, "060351": 153, "014958": 153, "445218": 153, "005112": 153, "4452178932": 153, "764569": 153, "765902": 153, "764947": 153, "765083": 153, "765281": 153, "000535": 153, "319": 153, "l2_regular": [153, 154, 179], "max_bin": [153, 154, 179], "score_bin": 153, "cut": [153, 161], "set_palett": 153, "ylgnbu_r": 153, "set_xscal": 153, "set_yscal": 153, "band": 153, "plotli": [153, 156, 179], "px": [153, 156, 179], "parallel_coordin": [153, 156, 179], "log10": [153, 179], "log2": [153, 179], "color_continuous_scal": [153, 156, 179], "undo": 153, "yellow": 153, "tick": 153, "invert": 153, "untract": 154, "situat": 154, "stochast": 154, "loguniform_int": 154, "__init__": 154, "_distribut": 154, "rv": 154, "processor": 154, "1e3": 154, "classifier__min_samples_leaf": 154, "classifier__max_bin": 154, "255": 154, "model_random_search": [154, 156], "559": 154, "_distn_infrastructur": 154, "rv_continuous_frozen": 154, "0x7fe872d06c10": 154, "0x7fe8720ca8e0": 154, "__main__": 154, "0x7fe8720ce220": 154, "0x7fe8720bd580": 154, "0x7fe8720ca430": 154, "randomizedsearchcvrandomizedsearchcv": 154, "pprint": 154, "6852421543879119": 154, "024891654505448717": 154, "685242": 154, "024892": 154, "865551": 154, "003517": 154, "511237": 154, "508686": 154, "864077": 154, "002927": 154, "000674": 154, "028369": 154, "855368": 154, "002500": 154, "004256": 154, "220212": 154, "845786": 154, "001304": 154, "655676": 154, "03508": 154, "839753": 154, "003216": 154, "000009": 154, "032944": 154, "109": 154, "802080": 154, "002730": 154, "003507": 154, "956109": 154, "799079": 154, "029175": 154, "000314": 154, "605655": 154, "659469": 154, "004319": 154, "004019": 154, "653724": 154, "449265": 154, "042710": 154, "259741": 154, "96267": 154, "288198": 154, "004939": 154, "to_csv": 154, "208": [154, 157, 162, 163], "011775": 154, "076653": 154, "871393": 154, "001588": 154, "343": 154, "000404": 154, "244503": 154, "229": 154, "871339": 154, "002741": 154, "994918": 154, "077047": 154, "192": 154, "870793": 154, "001993": 154, "328": 154, "036232": 154, "224702": 154, "236": 154, "869837": 154, "000808": 154, "733808": 154, "036786": 154, "241": 154, "869673": 154, "002417": 154, "232": 154, "000097": 154, "976823": 154, "448205": 154, "253714": 154, "000001": 154, "828574": 154, "144": 154, "000003": 154, "091079": 154, "000444": 154, "236325": 154, "344629": 154, "207156": 154, "357": 154, "000026": 154, "075318": 154, "241053": 154, "valuabl": 154, "allevi": 154, "best_scor": 155, "best_param": 155, "lr": 155, "mln": 155, "mean_scor": 155, "789": 155, "813": 155, "847": 155, "855": 155, "835": 155, "828": 155, "288": 155, "437": 155, "best_lr": 155, "best_mln": 155, "870": 155, "kneighborsregressor__n_neighbor": 156, "standardscaler__with_mean": 156, "standardscaler__with_std": 156, "welcom": 156, "column_name_map": 156, "param_kneighborsregressor__n_neighbor": 156, "param_standardscaler__with_mean": 156, "param_standardscaler__with_std": 156, "boolean": 156, "column_scal": 156, "687926": 156, "674812": 156, "668778": 156, "648317": 156, "629772": 156, "617295": 156, "464": 156, "567164": 156, "508809": 156, "486503": 156, "103390": 156, "061394": 156, "033122": 156, "017583": 156, "007987": 156, "002900": 156, "238830": 156, "diverg": 156, "tealros": 156, "kneighbor": 156, "plot_tre": [157, 159, 161, 162, 163], "class_nam": [157, 163], "impur": [157, 163], "invalidparametererror": [157, 162, 163], "201": [157, 162, 163], "validate_param": [157, 162, 163], "decor": [157, 162, 163], "198": [157, 162, 163], "to_ignor": [157, 162, 163], "cl": [157, 162, 163], "v": [157, 162, 163], "item": [157, 162, 163], "validate_parameter_constraint": [157, 162, 163], "202": [157, 162, 163], "parameter_constraint": [157, 162, 163], "caller_nam": [157, 162, 163], "__qualname__": [157, 162, 163], "205": [157, 162, 163], "config_context": [157, 162, 163], "skip_parameter_valid": [157, 162, 163], "prefer_skip_nested_valid": [157, 162, 163], "global_skip_valid": [157, 162, 163], "209": [157, 162, 163], "210": [157, 162, 163], "constraints_str": [157, 162, 163], "param_v": [157, 162, 163], "inferior": 157, "superior": 157, "settabl": 157, "45mm": 157, "sample_1": 157, "sample_2": 157, "y_pred_proba": 157, "y_proba_class_0": 157, "adelie_proba": 157, "chinstrap_proba": 157, "gentoo_proba": 157, "disregard": 157, "moment": 157, "sample_3": 157, "fairli": 157, "palmer": 158, "anatom": 158, "set_size_inch": 158, "deduc": 158, "extrapol": [160, 164, 171], "superimpos": [160, 164], "data_clf_column": 161, "target_clf_column": 161, "data_clf": 161, "data_reg_column": 161, "target_reg_column": 161, "data_reg": 161, "fit_and_plot_classif": 161, "fit_and_plot_regress": 161, "tree_clf": 161, "tree_reg": 161, "adequ": 161, "asymmetri": 161, "make_blob": 161, "blob": 161, "x_1": 161, "y_1": 161, "x_2": 161, "y_2": 161, "min_impurity_decreas": 161, "asymmetr": 161, "priori": 162, "3698": 162, "5032": 162, "target_predicted_linear_regress": 164, "target_predicted_tre": 164, "interpol": 164, "offset": 164, "175": 164, "shortest": 164, "longest": 164, "m3": [165, 178, 180], "m5": [165, 167, 168, 169, 176], "glossari": 165, "acknowledg": 165, "prune": 171, "children": 172, "increment": 173, "refin": 173, "author": 177, "circular": 179, "budget": [179, 183], "badli": 179, "histgradientbosstingclassifi": 181, "get_paramet": 181, "anim": 185, "param_valu": 185, "powertransform": 185, "all_preprocessor": 185, "cox": 185, "classifier__n_neighbor": 185, "forgot": 185}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"acknowledg": 0, "figur": 0, "attribut": [0, 3], "The": [1, 6, 76, 79, 106, 107, 108, 109, 142, 158, 165], "adult": [1, 76], "censu": [1, 76], "dataset": [1, 2, 6, 76, 82, 83, 93, 106, 107, 108, 109, 110, 152, 158], "descript": 2, "glossari": 3, "main": [3, 14, 23, 34, 40, 60, 74, 130, 134, 171, 183], "term": 3, "us": [3, 6, 11, 79, 88, 127, 128, 137, 150, 154], "thi": [3, 6], "cours": [3, 36], "classif": [3, 30, 140, 141, 142, 157, 158, 167], "classifi": [3, 142], "cross": [3, 20, 21, 79, 88, 98, 99, 104], "valid": [3, 6, 20, 21, 61, 69, 79, 88, 98, 99, 104, 105], "data": [3, 6, 65, 67, 70, 76, 79, 82, 83, 84, 87, 88, 103, 130, 134], "matrix": [3, 142], "input": 3, "earli": 3, "stop": 3, "estim": [3, 104], "featur": [3, 32, 41, 84, 87, 90, 92, 110, 127, 128, 133, 138, 165], "variabl": [3, 76, 87, 88, 90, 92, 110], "descriptor": 3, "covari": 3, "gener": [3, 105, 161], "perform": [3, 94, 165], "predict": [3, 6, 83, 87, 142, 150, 152, 154, 165], "statist": 3, "hyperparamet": [3, 12, 119, 121, 150, 151, 152, 153, 154, 161, 165, 168, 184], "infer": 3, "learn": [3, 6, 13, 22, 33, 36, 39, 52, 58, 61, 67, 72, 73, 83, 93, 98, 110, 112, 137, 139, 151, 165, 170, 182], "paramet": [3, 133, 161], "meta": 3, "model": [3, 6, 8, 9, 19, 38, 41, 47, 48, 50, 67, 69, 79, 83, 84, 88, 93, 94, 110, 120, 128, 130, 133, 134, 140, 150, 152, 154, 165, 166, 169], "overfit": [3, 59, 64, 105], "predictor": 3, "regress": [3, 31, 133, 137, 138, 139, 145, 158, 162, 176], "regressor": 3, "regular": [3, 47, 50, 133], "penal": 3, "sampl": [3, 97, 98], "instanc": 3, "observ": 3, "supervis": 3, "target": [3, 83, 138], "label": [3, 6], "annot": 3, "test": [3, 56, 82, 83, 104], "set": [3, 151], "train": [3, 56, 82, 83, 104], "fit": [3, 67, 83, 84, 88], "transform": 3, "underfit": [3, 59, 64, 105], "unsupervis": 3, "other": [3, 161], "notebook": [4, 76, 79, 82, 83, 138], "time": [4, 6, 13, 22, 33, 39, 58, 73, 170, 182], "tabl": [5, 165], "content": [5, 165], "conclud": [6, 7, 165], "remark": [6, 7, 165], "last": 6, "lesson": [6, 110], "goal": 6, "big": 6, "messag": 6, "mooc": [6, 36], "1": [6, 75, 110], "machin": [6, 52, 165], "pipelin": [6, 72, 87, 90, 92, 93, 112, 165], "2": [6, 62, 110], "adapt": [6, 111], "complex": [6, 112], "3": [6, 110, 185], "specif": [6, 88], "go": [6, 14, 23, 34, 40, 60, 74, 171, 183], "further": [6, 14, 23, 34, 40, 60, 74, 171, 183], "more": [6, 88, 104], "about": [6, 121], "scikit": [6, 36, 67, 72, 83, 93, 112, 137, 139, 151], "we": [6, 93], "ar": 6, "an": [6, 87], "open": 6, "sourc": 6, "commun": 6, "topic": 6, "have": 6, "cover": 6, "studi": 6, "bring": 6, "valu": 6, "bigger": 6, "pictur": 6, "beyond": [6, 141], "evalu": [6, 79, 87, 88, 142, 152, 165], "matter": 6, "small": 6, "part": 6, "problem": 6, "most": 6, "technic": 6, "craft": 6, "all": 6, "how": 6, "choic": [6, 20], "output": 6, "bias": 6, "versu": [6, 54, 57], "causal": 6, "societ": 6, "impact": 6, "intuit": [8, 9, 38, 48, 50, 166, 169], "ensembl": [8, 9, 10, 11, 12, 120, 165], "bag": [8, 112], "boost": [9, 10, 111, 117, 118, 119], "base": [10, 87, 88, 166, 169], "method": [11, 12], "bootstrap": [11, 112], "tune": [12, 119, 133, 150, 152, 154, 165, 178, 180], "modul": [13, 22, 33, 39, 58, 73, 170, 182], "overview": [13, 22, 33, 39, 58, 73, 170, 182], "what": [13, 22, 33, 39, 58, 73, 170, 182], "you": [13, 22, 33, 39, 58, 73, 170, 182], "befor": [13, 22, 33, 39, 58, 73, 170, 182], "get": [13, 22, 33, 39, 58, 73, 151, 170, 182], "start": [13, 22, 33, 39, 58, 73, 170, 182], "object": [13, 22, 33, 39, 58, 73, 170, 182], "schedul": [13, 22, 33, 39, 58, 73, 170, 182], "take": [14, 23, 34, 40, 60, 74, 110, 171, 183], "awai": [14, 23, 34, 40, 60, 74, 110, 171, 183], "wrap": [14, 18, 23, 29, 34, 40, 49, 60, 62, 74, 75, 171, 177, 183, 185], "up": [14, 18, 23, 29, 34, 40, 49, 60, 62, 74, 75, 118, 171, 177, 183, 185], "To": [14, 23, 34, 40, 60, 74, 171, 183], "quiz": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 172, 173, 174, 175, 177, 179, 181, 185], "m6": [15, 16, 17, 113, 114, 115, 116, 122, 123, 124, 125], "01": [15, 24, 42, 51, 63, 66, 77, 78, 95, 96, 100, 101, 113, 122, 126, 129, 130, 134, 148, 155, 159, 163, 172, 181], "question": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 172, 173, 174, 175, 177, 179, 181, 185], "02": [16, 25, 43, 55, 68, 80, 85, 114, 123, 131, 135, 143, 146, 149, 156, 160, 164, 173, 179], "03": [17, 26, 44, 53, 71, 81, 86, 115, 124, 132, 136, 144, 147, 174], "6": 18, "compar": [19, 56, 94], "simpl": [19, 94], "baselin": [19, 94, 142], "nest": [21, 99], "m7": [24, 25, 26, 27, 28, 96, 101, 143, 144, 146, 147], "04": [27, 45, 89, 91, 116, 125, 175], "05": [28, 46, 90, 92], "7": 29, "metric": [30, 31, 142], "caveat": 32, "select": [32, 87, 88, 127, 128, 165], "introduct": 36, "present": [36, 110], "welcom": 36, "follow": 36, "prerequisit": [36, 130, 134], "materi": 36, "social": 36, "network": 36, "linear": [38, 41, 47, 48, 50, 110, 133, 137, 138, 139, 140, 141, 165], "non": [41, 103, 138], "engin": 41, "m4": [42, 43, 44, 45, 46, 130, 131, 132, 134, 135, 136], "4": 49, "intro": 51, "introduc": 52, "concept": [52, 165], "m2": [53, 55, 63, 95, 100], "bia": [54, 57], "varianc": [54, 57], "error": [56, 104], "trade": 57, "off": 57, "curv": [61, 98, 105], "tabular": 65, "explor": 65, "m1": [66, 68, 71, 77, 78, 80, 81, 85, 86, 89, 90, 91, 92], "numer": [67, 82, 84, 88, 90, 92], "handl": 70, "categor": [70, 87, 88, 90, 92], "visual": [72, 76, 93], "jupyt": [72, 93], "first": [76, 83, 93], "look": [76, 121], "our": [76, 87, 150, 152, 154], "load": [76, 82, 83, 93, 130, 134, 152], "column": [76, 88], "inspect": [76, 110], "creat": [76, 93, 161], "decis": [76, 117, 119, 157, 161, 162, 165, 167, 168, 176], "rule": 76, "hand": 76, "recap": [76, 79, 82, 83, 138], "exercis": [77, 78, 80, 81, 85, 86, 89, 90, 91, 92, 95, 96, 100, 101, 113, 114, 115, 116, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 143, 144, 146, 147, 148, 149, 155, 156, 159, 160, 163, 164], "solut": [78, 85, 86, 91, 92, 100, 101, 122, 123, 124, 125, 129, 134, 135, 136, 146, 147, 155, 156, 163, 164], "prepar": [79, 84], "need": 79, "work": 82, "entir": 82, "identifi": [82, 87], "split": [82, 83], "panda": 83, "separ": [83, 141], "make": 83, "preprocess": 84, "encod": [87, 90, 92], "type": [87, 88], "strategi": 87, "categori": [87, 90, 92], "ordin": 87, "nomin": 87, "without": [87, 139, 152], "assum": 87, "ani": 87, "order": 87, "choos": 87, "togeth": 88, "dispatch": 88, "processor": 88, "power": 88, "refer": [90, 92], "scale": [90, 92, 110, 133], "integ": [90, 92], "code": [90, 92], "One": [90, 92], "hot": [90, 92], "analysi": [92, 153, 184], "Then": 93, "final": 93, "score": 93, "group": 97, "effect": [98, 133, 161], "size": 98, "summari": [98, 104, 105], "stratif": 102, "i": 103, "d": 103, "framework": 104, "vs": [104, 105], "stabil": 104, "detail": [104, 121], "regard": 104, "cross_valid": 104, "am": 106, "hous": [106, 109], "bike": 107, "ride": 107, "blood": 108, "transfus": 108, "california": 109, "import": [110, 161], "0": 110, "sign": 110, "coeffici": 110, "A": [110, 121], "surpris": 110, "associ": 110, "check": 110, "spars": 110, "lasso": 110, "randomforest": 110, "feature_importances_": 110, "permut": 110, "discuss": 110, "adaboost": 111, "resampl": 112, "aggreg": 112, "gradient": [117, 118, 119], "tree": [117, 119, 157, 161, 162, 165, 166, 167, 168, 169, 176], "gbdt": 117, "speed": 118, "random": [119, 121, 154], "forest": [119, 121], "histogram": 119, "introductori": 120, "exampl": 120, "default": 121, "benefit": 127, "limit": 128, "definit": [130, 134], "relationship": 138, "accuraci": 142, "confus": 142, "deriv": 142, "issu": 142, "class": 142, "imbal": 142, "differ": 142, "probabl": 142, "threshold": 142, "m3": [148, 149, 155, 156, 179, 181], "grid": 150, "search": [150, 153, 154, 184], "With": 152, "result": [153, 184], "build": 157, "penguin": 158, "m5": [159, 160, 163, 164, 172, 173, 174, 175], "helper": 161, "function": 161, "max_depth": 161, "best": 165, "appendix": 165, "interpret": 165, "5": 177, "autom": 178, "manual": 180}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})